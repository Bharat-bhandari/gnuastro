\input texinfo @c -*-texinfo-*-
@c %**start of header
@setfilename gnuastro.info
@settitle GNU Astronomy Utilities
@documentencoding UTF-8
@allowcodebreaks false
@c@afourpaper

@c %**end of header
@include version.texi
@include formath.texi
@include subpackageversions.texi

@c So dashes and underscores can be used in HTMLs
@allowcodebreaks true

@c Use section titles in cross references, not node titles.
@xrefautomaticsectiontitle on

@c For the indexes:
@syncodeindex fn cp
@syncodeindex vr cp
@syncodeindex pg cp

@c Copyright information:
@copying
This manual documents version @value{VERSION} of the GNU Astronomy
Utilities, providing various individual tools with similar user
interface for astronomical data manipulation and  analysis.

Copyright @copyright{} 2015 Free Software Foundation, Inc.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with no
Invariant Sections, with no Front-Cover Texts, and with no Back-Cover
Texts.  A copy of the license is included in the section entitled
``GNU Free Documentation License''.
@end quotation
@end copying

@c To include in the info directory.
@dircategory Astronomy
@direntry
* Gnuastro: (gnuastro).       GNU Astronomy Utilities.

* ConvertType: (gnuastro)ConvertType. Convert different file types.
* astconvertt: (gnuastro)Invoking astconvertt. Options to ConvertType.

* Convolve: (gnuastro)Convolve. Convolve an input file with kernel.
* astconvolve: (gnuastro)Invoking astconvolve. Options to Convolve.

* Header: (gnuastro)Header. Print and manipulate data header info.
* astheader: (gnuastro)Invoking astheader. Options to Header.

* ImageCrop: (gnuastro)ImageCrop. Crop region(s) from image(s).
* astimgcrop: (gnuastro)Invoking astimgcrop. Options to ImageCrop.

* ImageStatistics: (gnuastro)ImageStatistics. Get image Statistics.
* astimgstat: (gnuastro)Invoking astimgstat. Options to ImageStatistics.

* ImageWarp: (gnuastro)ImageWarp. Warp an image to a new grid.
* astimgwarp: (gnuastro)Invoking astimgwarp. Options to ImageWarp.

* MakeNoise: (gnuastro)MakeNoise. Make (add) noise to an image.
* astmknoise: (gnuastro)Invoking astmkprof. Options to MakeNoise.

* MakeProfiles: (gnuastro)MakeProfiles. Make mock profiles.
* astmkprof: (gnuastro)Invoking astmkprof. Options to MakeProfiles.

* SubtractSky: (gnuastro)SubtractSky. Find and subtract the sky value.
* astmkprof: (gnuastro)Invoking astsubtractsky. Options to SubtractSky.

@end direntry




















@c Print title information:
@titlepage
@title GNU Astronomy Utilities
@subtitle Astronomical data manipulation and analysis
@subtitle for version @value{VERSION}, @value{UPDATED}
@author Mohammad Akhlaghi

@page
@vskip 0pt plus 1filll
@insertcopying

@page
@quotation
@*
@*
@*
@*
@*
@*
@*
@*
@*
For myself, I am interested in science and in philosophy only because
I want to learn something about the riddle of the world in which we
live, and the riddle of man’s knowledge of that world. And I believe
that only a revival of interest in these riddles can save the sciences
and philosophy from narrow specialization and from an obscurantist
faith in the expert’s special skill, and in his personal knowledge and
authority; a faith that so well fits our ‘post-rationalist’ and
‘post-critical’ age, proudly dedicated to the destruction of the
tradition of rational philosophy, and of rational thought itself.
@author Karl Popper. The logic of scientific discovery. 1959.
@end quotation

@end titlepage

@shortcontents
@contents











@c Online version top information.
@ifnottex
@node Top, Introduction, (dir), (dir)
@top GNU Astronomy Utilities

@insertcopying

@ifhtml
To navigate easily in this web page, you can use the @code{Next},
@code{Previous}, @code{Up} and @code{Contents} links in the top and
bottom of each page. @code{Next} and @code{Previous} will take you to
the next or previous topic in the same level, for example from chapter
1 to chapter 2 or vice versa. To go to the sections or subsections,
you have to click on the menu entries that are there when ever a
sub-component to a title is present.
@end ifhtml

@end ifnottex

@menu
* Introduction::                General introduction.
* Tutorials::                   Tutorials or Cookbooks.
* Installation::                Requirements and installation.
* Common behavior::             Common behavior in all programs.
* Files::                       File information and type conversion.
* Image manipulation::          Tools for basic image manipulation.
* Image analysis::              Analyze images.
* Modeling and fittings::       Make and fit models.
* Table manipulation::          Read/Write tables.
* Developing::                  The development environment.
* Other useful software::       Installing other useful software.
* GNU Free Documentation License::  Full FDL text.
* Index::                       Index of terms

@detailmenu
 --- The Detailed Node Listing ---

Introduction

* Naming convention::           About names of programs in Gnuastro.
* Quick start::                 A quick start to installation.
* GNU Astronomy Utilities list::  List of program in Gnuastro.
* Science and its tools::       Some philosophy and history.
* Your rights::                 User rights.
* Version numbering::           Understanding version numbers.
* New to GNU/Linux?::           Suggested GNU/Linux distribution.
* Report a bug::                Search and report the bug you found.
* Suggest new feature::         How to suggest a new feature.
* Announcements::               How to stay up to date with Gnuastro.
* Conventions::                 Conventions used in this manual.
* Acknowledgments::             People who helped in the production.

Version numbering

* GNU Astronomy Utilities 1.0::  Plans for version 1.0 release

Tutorials

* Hubble visually checks and classifies his catalog::  Check a catalog.
* Sufi simulates a detection::  Simulating a detection.

Installation

* Requirements::                Gnuastro requirements.
* Optional requirements::       Optional Gnuastro requirements.
* Installing Gnuastro::         Installing Gnuastro.

Requirements

* GNU Scientific Library::      Installing GSL.
* CFITSIO::                     C interface to the FITS standard.
* WCSLIB::                      C interface to the WCS standard of FITS.

Optional requirements

* libjpeg::                     Used for JPEG image input/output.
* GPL Ghostscript::             Used for compiling PDF images.

Installing GNU Astronomy Utilities

* Configuring::                 Configure Gnuastro
* Tests::                       Run tests to see if it is working.
* A4 print manual::             Customize the print manual.
* Known issues::                Issues you might encounter.

Configuring

* GNU Astronomy Utilities configure options::  Configure options particular to Gnuastro.
* Installation directory::      Specify the directory to install.
* Executable names::            Changing executable names.

Common behavior

* Command line::                How to use the command line.
* Configuration files::         Values for unspecified variables.
* Threads in GNU Astronomy Utilities::  How threads are managed in Gnuastro.
* Final parameter values::      The final set of used parameters.
* Automatic output::            About automatic output names.
* Getting help::                Getting more information on the go.
* Output headers::              Common headers to all FITS outputs.

Command line

* Arguments and options::       Basics of options and arguments.
* Arguments::                   Treatment of arguments.
* Options::                     How to use GNU style options.
* Common options::              Common options to all Gnuastro programs.

Common options

* Input output::                Common input/output options.
* Operating modes::             Common operating mode options.

Configuration files

* Configuration file format::   ASCII format of configuration file.
* Configuration file precedence::  Precedence of configuration files.
* Current directory and User wide::  Local and user configuration files.
* System wide::                 System wide configuration files.

Threads in GNU Astronomy Utilities

* A note on threads::           Caution and suggestion on using threads.

Getting help

* --usage::                     View option names and value formats.
* --help::                      List all options with description.
* Man pages::                   Man pages generated from --help.
* Info::                        View complete manual in terminal.
* help-gnuastro mailing list::  Contacting experienced users.

Files

* Header::                      Print and manipulate data file header.
* ConvertType::                 Convert data to various formats.

Header

* Invoking astheader::          Arguments and options to Header.

ConvertType

* Recognized file types::       Recognized file types
* Color::                       Some explanations on color.
* Invoking astconvertt::        Options and arguments to ConvertType.

Image manipulation

* ImageCrop::                   Crop region(s) from FITS image(s).
* Convolve::                    Convolve an image with a kernel.
* ImageWarp::                   Warp/Transform an image to a different grid.
* SubtractSky::                 Find the sky and subtract it from image.

ImageCrop

* ImageCrop modes::             Basic ImageCrop modes.
* Crop section syntax::         How to define a section to crop.
* Blank pixels::                Pixels with no value.
* Invoking astimgcrop::         Calling ImageCrop on the command line

Invoking ImageCrop

* astimgcrop options::          A list of all the options with explanation.
* astimgcrop output::           The outputs of ImageCrop.

Convolve

* Convolution process::         More basic explanations.
* Convolution on the edges::    Dealing with the edges of an image.
* Spatial vs. Frequency domain::  Comparison of the two domains.
* Invoking astconvolve::        Options and arguments to Convolve.

ImageWarp

* Warping basics::              Basics of coordinate transformation.
* Merging multiple warpings::   How to merge multiple matrices.
* Resampling::                  Warping an image is re-sampling it.
* Invoking astimgwarp::         Arguments and options for ImageWarp.

SubtractSky

* Sky value::                   Definition of the sky value.
* Tiling an image::             Defining a mesh grid on the image.
* Sky value interpolation::     How blank grid elements are filled.
* Invoking astsubtractsky::     Options and arguments to SubtractSky.

Sky value

* Finding the sky value::       How SubtractSky finds the sky value.
* Sky value misconceptions::    Sky value misconceptions and wrong approaches.

Image analysis

* ImageStatistics::             Calculate main image statistics.

ImageStatistics

* Invoking astimgstat::         Arguments and options to ImageStatistics

Modeling and fitting

* MakeProfiles::                Making mock galaxies and stars.
* MakeNoise::                   Make (add) noise to an image.

MakeProfiles

* Modeling basics::             Astronomical modeling basics.
* If convolving afterwards::    Considerations for convolving later.
* Profile total magnitude::     Definition of total profile magnitude.
* Magnitude to flux conversion::  Converting magnitude to flux.
* Invoking astmkprof::          Inputs and Options for MakeProfiles.

Modeling basics

* Defining an ellipse::         Defining an ellipse in 2D.
* PSF::                         Radial profiles for the PSF.
* Stars::                       Making mock star profiles.
* Galaxies::                    Radial profiles for galaxies.
* Sampling from a function::    Sample a function on a pixelated canvas.
* Oversampling::                Oversampling the model.

Invoking MakeProfiles

* MakeProfiles catalog::        Required catalog properties.
* MakeProfiles options::        Full list of MakeProfiles options.
* MakeProfiles output::         The generated outputs.

MakeNoise

* Noise basics::                Noise concepts and definitions.
* Invoking astmknoise::         Options and arguments to MakeNoise.

Noise basics

* Photon counting noise::       Poisson noise
* Instrumental noise::          Readout, dark current and other sources.
* Final noised pixel value::    How the final noised value is calculated.
* Generating random numbers::   How random numbers are generated.

Developing

* Why C::                       Why Gnuastro is designed in C.
* Design philosophy::           General ideas behind the package structure.
* Gnuastro project webpage::    Central hub for Gnuastro activities.
* Version controlled source::   How to get and prepare the VCSed code.
* Internal libraries::          Internal static (not installed) libraries.
* Header files::                Library and common headers.
* Program source::              Conventions for the code.
* Test scripts::                Understanding the test scripts.
* Building::                    Explanations on building.
* After making changes::        What to do after you have finished you changes.

Program source

* Mandatory source code files::  How the source files of each program are managed.
* Coding conventions::          Basic conventions for coding structure.
* Multithreaded programming::   Gnuastro's multithreaded programming style.
* Documentation::               Documentation is an integral part of Gnuastro.

Mandatory source code files

* Coding conventions::          Conventions used for coding
* Multithreaded programming::   Gnuastro uses POSIX threads.

Other useful software

* SAO ds9::                     Viewing FITS images.
* PGPLOT::                      Plotting directly in C

SAO ds9

* Viewing multiextension FITS::  Configure SAO ds9 for multiextension images.

@end detailmenu
@end menu

@node Introduction, Tutorials, Top, Top
@chapter Introduction

@cindex GNU coding standards
@cindex GNU Astronomy Utilities (Gnuastro) @value{VERSION}
The GNU Astronomy Utilities (Gnuastro) is an official GNU package
consisting of separate programs for the manipulation and analysis of
astronomical data. All the various utilities share the same basic
command line user interface for the comfort of both the users and
developers. GNU Astronomy Utilities is written to comply fully with
the GNU coding standards so it integrates finely with the GNU/Linux
operating system. This also enables astronomers to expect a fully
familiar experience in the source code, building, installing and
command line user interaction that they have seen in all the other GNU
software that they use.

For users who are new to the GNU/Linux environment, unless otherwise
specified most of the topics in chapters 2 and 3 are common to all GNU
software, for example installation, managing command line options or
getting help. So if you are new to this environment, we encourage you
to go through these chapters carefully. They can be a starting point
from which you can continue to learn more from each program's own
manual and fully enjoy this wonderful environment. This manual is
written so someone who is completely new to GNU/Linux can get going
very soon, see @ref{New to GNU/Linux?}.

Finally it must be mentioned that in Gnuastro, no change to any
program will be released before it has been fully documented in this
manual first. As discussed in @ref{Science and its tools} this is the
founding basis of the GNU Astronomy Utilities.

@menu
* Naming convention::           About names of programs in Gnuastro.
* Quick start::                 A quick start to installation.
* GNU Astronomy Utilities list::  List of program in Gnuastro.
* Science and its tools::       Some philosophy and history.
* Your rights::                 User rights.
* Version numbering::           Understanding version numbers.
* New to GNU/Linux?::           Suggested GNU/Linux distribution.
* Report a bug::                Search and report the bug you found.
* Suggest new feature::         How to suggest a new feature.
* Announcements::               How to stay up to date with Gnuastro.
* Conventions::                 Conventions used in this manual.
* Acknowledgments::             People who helped in the production.
@end menu

@node Naming convention, Quick start, Introduction, Introduction
@section Naming convention

@cindex Names, programs
@cindex Program names
GNU Astronomy Utilities is a package of independent utilities or
programs. Each utility has an official name which consists of one or
two words, describing what they do. The latter are printed with no
space, for example NoiseChisel or ImageCrop. On the command line, you
can run them with their executable names which start with an
@file{ast} and might be an abbreviation of the official name, for
example @file{astnoisechisel} or @file{astimgcrop}, see
@ref{Executable names}.

@pindex ProgramName
@pindex @file{astprogname}
We will use ``ProgramName'' for a generic official program name and
@file{astprogname} for a generic executable name. In this manual, the
programs are classified based on what they do and thoroughly
explained. An alphabetical list of the utilities that are installed on
your system with this installation are given in @ref{GNU Astronomy
Utilities list}. That list also contains the executable names and
version numbers along with a one line description.

@node Quick start, GNU Astronomy Utilities list, Naming convention, Introduction
@section Quick start

@cindex Uncompress source
@cindex Source, uncompress
@cindex Build
@cindex Compile
@cindex Check
@cindex Test
Let's assume you have just downloaded the
@file{gnuastro-@value{VERSION}.tar.gz} in the @file{DOWLD} directory
and you already have the requirements (see
@ref{Requirements}). Running the following commands will unpack,
compile, check and install all the GNU Astronomy Utilities so you can
use them anywhere in your system.

@example
$ cd DOWLD
$ tar -zxvf gnuastro-@value{VERSION}.tar.gz
$ cd gnuastro-@value{VERSION}
$ ./configure
$ make
$ make check
$ sudo make install
$ cd ../
$ rm -rf gnuastro-@value{VERSION} gnuastro-@value{VERSION}.tar.gz
@end example

@noindent

See @ref{Known issues} if you confront any complications.  For each
program there is an `Invoke ProgramName' sub-section in this manual
which explains how the programs should be run on the command line. It
can be read on the command line by running the command @command{$ info
astprogname}, see @ref{Naming convention} and @ref{Getting help}. The
`Invoke ProgramName' sub-section starts with a few examples of each
program and goes on to explain the invocation details. In
@ref{Tutorials} some real life examples of how these programs might be
used is given.





@node GNU Astronomy Utilities list, Science and its tools, Quick start, Introduction
@section GNU Astronomy Utilities list

GNU Astronomy Utilities @value{VERSION}, contains the following
programs. They are sorted in alphabetical order and followed by their
executable names along with a short description, see @ref{Naming
convention}. Throughout this manual, they are discussed based on their
context, see the manual contents for contextual ordering.

@itemize

@item
@ref{ConvertType} (@file{astconvertt}) @value{CONVERTT_VERSION}:
Convert data files.
@item
@ref{Convolve} (@file{astconvolve}) @value{CONVOLVE_VERSION}: Convolve
(blur) data with a kernel.
@item
@ref{Header} (@file{astheader}) @value{HEADER_VERSION}: Print and
manipulate data header.
@item
@ref{ImageCrop} (@file{astimgcrop}) @value{IMGCROP_VERSION}: Crop
region(s) from image(s).
@item
@ref{ImageStatistics} (@file{astimgstat}) @value{IMGSTAT_VERSION}: Get pixel statistics.
@item
@ref{ImageWarp} (@file{astimgwarp}) @value{IMGWARP_VERSION}: Warp
image to new pixel grid.
@item
@ref{MakeNoise} (@file{astmknoise}) @value{MKNOISE_VERSION}: Make
(add) noise to an image.
@item
@ref{MakeProfiles} (@file{astmkprof}) @value{MKPROF_VERSION}: Make
mock profiles in image.
@item
@ref{SubtractSky} (@file{astsubtractsky}) @value{SUBTRACTSKY_VERSION}:
Find and subtract sky value.

@end itemize





@node Science and its tools, Your rights, GNU Astronomy Utilities list, Introduction
@section Science and its tools

History of science indicates that there are always inevitably unseen
faults, hidden assumptions, simplifications and approximations in all
our theoretical models, data acquisition and analysis techniques. It is
precisely these that will ultimately allow future generations to
advance the existing experimental and theoretical knowledge through
their new solutions and corrections.

In the past, scientists would gather data and process them
individually to achieve an analysis thus having a much more intricate
knowledge of the data and analysis. The theoretical models also
required little (if any) simulations to compare with the data. Today
both methods are becoming increasingly more dependent on pre-written
software. Scientists are dissociating themselves from the intricacies
of reducing raw observational data in experimentation or from bringing
the theoretical models to life in simulations. These `intricacies'
are precisely those unseen faults, hidden assumptions, simplifications
and approximations that define scientific progress.

@quotation
@cindex Anscombe F. J.
Unfortunately, most persons who have recourse to a computer for
statistical analysis of data are not much interested either in
computer programming or in statistical method, being primarily
concerned with their own proper business. Hence the common use of
library programs and various statistical packages. ... It's time that
was changed.
@author F. J. Anscombe. The American Statistician, Vol. 27, No. 1. 1973
@end quotation

@cindex Anscombe's quartet
@cindex Good statistical analysis
@cindex Statistical analysis, good
Anscombe's quartet
@footnote{@url{http://en.wikipedia.org/wiki/Anscombe%27s_quartet}}
demonstrates how four data sets with widely different shapes (when
plotted) give nearly identical output from standard regression
techniques.  Anscombe argues that ``Good statistical analysis is not a
purely routine matter, and generally calls for more than one pass
through the computer''. Anscombe's quartet can be generalized to say
that users of a software cannot claim to understand how it works only
based on the experience they have gained by frequently using it. This
kind of subjective experience is prone to very serious
mis-understandings about what it really does behind the scenes and can
be misleading. This attitude is further encouraged through non-free
software@footnote{@url{https://www.gnu.org/philosophy/free-sw.html}}.
This approach to scientific software only helps in producing dogmas
and an ``obscurantist faith in the expert’s special skill, and in his
personal knowledge and authority''@footnote{Karl Popper. The logic of
scientific discovery. 1959. Larger quote is given at the start of the
PDF manual.}.

It is obviously impractical for any one human being to gain the
intricate knowledge explained above for every step of an analysis. On
the other hand, scientific data can be very large and numerous, for
example images produced by telescopes in astronomy. This requires very
efficient algorithms. To make things worse, natural scientists have
generally not been trained in the advanced software techniques,
paradigms and architecture that is taught in computer science or
engineering courses and thus used in most software. The GNU Astronomy
Utilities are an effort to tackle this issue. GNU Astronomy Utilities
are built on the basis of the GNU general public license (GPL), giving
the users complete ``freedom'' over them, see @ref{Your rights}. We
further add the requirement (on the authors of Gnuastro) that an
astronomer, who is not necessarily trained in computer science or
engineering, will need minimal requirements and preparations to
understand and modify any step if they feel the need to do so, see
@ref{Why C} and @ref{Design philosophy}.

@cindex Galileo, G.
Imagine if Galileo did not have the technical knowledge to build a
telescope. Astronomical objects could not be seen with the Dutch
military design of the telescope. In the beginning of his ``The
Sidereal Messenger'' (1610) he cautions the readers on this issue and
instructs them on how to build a suitable instrument. Before he
actually saw the moons of Jupiter, the mountains or the Moon or the
crescent of Venus, he was an anti-Copernican and was “evasive” to
Kepler@footnote{Galileo G. (Translated by Maurice
A. Finocchiaro). @emph{The essential Galileo}. Hackett publishing
company, first edition, 2008.}. Science is not independent of its
tools.

@cindex Ken Thomson
@cindex Stroustrup, Bjarne
Bjarne Stroustrup (creator of the C++ language) says: ``Without
understanding software, you are reduced to believing in magic''.  Ken
Thomson (the designer or the Unix operating system) says ``I abhor a
system designed for the `user' if that word is a coded pejorative
meaning `stupid and unsophisticated'.'' Certainly no scientist (user
of a scientific software) would want to be considered as such. Roughly
5 years before special relativity and about two decades before quantum
mechanics fundamentally changed Physics, Kelvin is quoted as
saying@footnote{Another such quote is from Albert. A. Michelson's
speech at the dedication of Ryerson Physics Lab, U. of Chicago 1894
saying: ``The more important fundamental laws and facts of physical
science have all been discovered, and these are now so firmly
established that the possibility of their ever being supplanted in
consequence of new discoveries is exceedingly remote.... Our future
discoveries must be looked for in the sixth place of decimals.''.}:

@quotation
@cindex Lord Kelvin
@cindex William Thomson
There is nothing new to be discovered in physics now. All that remains
is more and more precise measurement.
@author William Thomson (Lord Kelvin), 1900
@end quotation

@cindex Puzzle solving scientist
@cindex Scientist, puzzle solver
If scientists are considered to be more than mere ``puzzle
solvers''@footnote{Thomas S. Kuhn. @emph{The Structure of Scientific
Revolutions}, University of Chicago Press, 1962.}, they cannot just
passively sit back and wait for others to build the tools that form
the basis of all their interpretations and working paradigms. Today
there is a wealth of raw telescope images ready (mostly for free) at
the finger tips of anyone who is interested with a fast enough
internet connection to download them.  The only thing lacking is new
ways to analyze them and dig out the treasure that is lying hidden in
them to existing methods and techniques.

@quotation
@cindex Jaynes E. T.
New data that we insist on analyzing in terms of old ideas (that is,
old models which are not questioned) cannot lead us out of the old
ideas. However many data we record and analyze, we may just keep
repeating the same old errors, missing the same crucially important
things that the experiment was competent to find.
@author E. T. Jaynes, Probability theory, the logic of science. 2003.
@end quotation




@node Your rights, Version numbering, Science and its tools, Introduction
@section Your rights

@cindex GNU Texinfo
The paragraphs below, in this section, belong to the GNU
Texinfo@footnote{Texinfo is the GNU documentation system. It is used
to create this manual in all the various formats.} manual and are not
written by us! The name ``Texinfo'' is just changed to ``GNU Astronomy
Utilities'' or ``Gnuastro'' because they are released under the same
licenses and it is beautifully written to inform you of your rights.

@cindex Free software
@cindex Copyright
@cindex Public domain
GNU Astronomy Utilities is ``free software''; this means that everyone
is free to use it and free to redistribute it on certain
conditions. Gnuastro is not in the public domain; it is copyrighted
and there are restrictions on its distribution, but these restrictions
are designed to permit everything that a good cooperating citizen
would want to do.  What is not allowed is to try to prevent others
from further sharing any version of Gnuastro that they might get from
you.

Specifically, we want to make sure that you have the right to give
away copies of the programs that relate to Gnuastro, that you receive
the source code or else can get it if you want it, that you can change
these programs or use pieces of them in new free programs, and that
you know you can do these things.

To make sure that everyone has such rights, we have to forbid you to
deprive anyone else of these rights.  For example, if you distribute
copies of the Gnuastro related programs, you must give the recipients
all the rights that you have.  You must make sure that they, too,
receive or can get the source code.  And you must tell them their
rights.

Also, for our own protection, we must make certain that everyone finds
out that there is no warranty for the programs that relate to Gnuastro.
If these programs are modified by someone else and passed on, we want
their recipients to know that what they have is not what we distributed,
so that any problems introduced by others will not reflect on our
reputation.

@cindex GNU General Public License
@cindex GNU Free Documentation License
The precise conditions of the licenses for the programs currently
being distributed that relate to Gnuastro are found in the
@url{http://www.gnu.org/copyleft/gpl.html, GNU General Public license}
that accompany them.  This manual is covered by the
@url{http://www.gnu.org/copyleft/fdl.html, GNU Free Documentation
License}.



@node Version numbering, New to GNU/Linux?, Your rights, Introduction
@section Version numbering

@cindex Version number
@cindex Number, version
@cindex Major version number
@cindex Minor version number
The general Gnuastro package has a version number. It contains
various programs and each of those also has its own version
number. The version numbers for both are two numbers with a point
(@file{.}) between them. The left number is the major version number
while the right one is the minor version number. Note that the numbers
are not decimals, so version 2.34 of a program is much more recent
than version 2.5, which is not equal to 2.50!

The current version of Gnuastro is @value{VERSION} and the version
numbers of its various components are shown in @ref{GNU Astronomy
Utilities list}. To see the version of a program you are using, you
can use the @option{--version} option, see @ref{Common options}.

GNU Astronomy Utilities and all programs within it start with version
number 0.1. For the programs, the minor version number is increased
with any few bug fixes or small improvements which the developers
decide is significant for a public release. So minor releases can be
viewed as ad-hoc improvements. The major version number is set by a
major goal which is defined by the developers of that particular
program before hand.

For Gnuastro, its minor version number increases by 1 on every release
(which contains an arbitrary number of updated version numbers for the
programs or the general package). You can see the details from the
@file{NEWS} file that comes with that distribution and is also
available online to view before you download.

@menu
* GNU Astronomy Utilities 1.0::  Plans for version 1.0 release
@end menu

@node GNU Astronomy Utilities 1.0,  , Version numbering, Version numbering
@subsection GNU Astronomy Utilities 1.0
@cindex Gnuastro major version number
The major version number of Gnuastro is increased similar to that of
each program. Currently (prior to Gnuastro 1.0), the aim is to have a
complete system for data manipulation and analysis at least similar to
IRAF@footnote{@url{http://iraf.noao.edu/}}. So an astronomer can take
all the standard data analysis steps (starting from raw data to the
final reduced product and standard post-reduction tools) with the
various programs in Gnuastro.

@cindex Shell script
The maintainers of each camera or detector on a telescope can provide
a completely transparent shell script to the observer for data
analysis. This script can set configuration files for all the required
programs to work with that particular camera. The script can then run
the proper programs in the proper sequence. The user/observer can
easily follow the standard shell script to understand (and modify)
each step and the parameters used easily. Bash (or other modern
GNU/Linux shell scripts) are very powerful and made for this gluing
job. This will simultaneously improve performance and transparency.

In order to achieve this and allow maximal creativity with the shell,
the various programs have to be very low level programs and completely
independent. Something like the GNU Coreutils.





@node New to GNU/Linux?, Report a bug, Version numbering, Introduction
@section New to GNU/Linux?

Some astronomers initially install and use the GNU/Linux operating
systems because their research software can only be run in this
environment. This is how the founder of Gnuastro started using
GNU/Linux at least! If this is not the case for you, you can skip this
section. @ref{Tutorials} is a complete chapter with some real world
example applications of Gnuastro making good use of GNU/Linux
capabilities written for newcomers to this environment. It is fully
explained and is easy and entertaining to read, we hope you enjoy it.

@cindex GNU/Linux
@cindex Linux
You might have already noticed that we are not using the name
``Linux'', but ``GNU/Linux''. Please take the time to have a look at
the following essays and FAQs for a complete understanding of this
very important distinction.

@itemize

@item
@url{https://www.gnu.org/gnu/gnu-users-never-heard-of-gnu.html}

@item
@url{https://www.gnu.org/gnu/linux-and-gnu.html}

@item
@url{https://www.gnu.org/gnu/why-gnu-linux.html}

@item
@url{https://www.gnu.org/gnu/gnu-linux-faq.html}

@end itemize

@cindex Shell
@cindex Graphic user interface
@cindex Command line user interface
@cindex GUI: graphic user interface
@cindex CLI: command line user interface
Another thing you will notice is that Gnuastro only has a command line
user interface (CLI) or the `shell' as it is referred to in
Unix-like systems. This might be contrary to your mostly graphical
user interface (GUI) experience with proprietary operating systems. To
a first time user, the command line does appear much more complicated
and adapting to it might not be easy.

@cindex GNOME 3
Through GNOME 3@footnote{@url{http://www.gnome.org/}}, most GNU/Linux
based operating systems now have a very advanced and useful GUI. Since
the GUI was created long after the command line, some wrongly consider
the command line to be obsolete. Both interfaces are very useful for
different tasks (for example you can't view an image, video or web
page on the command line!). Therefore they should not be regarded as
rivals but as complementary, here we will outline how the CLI can be
useful in scientific programs.

You can think of the GUI as a veneer over the CLI to facilitate a
small subset of all the possible CLI operations. Each click you do on
the GUI, can be thought of as internally running a different
command. So asymptotically (if a good designer can design a GUI which
is able to show you all the possibilities to click on) the GUI is only
as powerful as the command line. In practice, such designers are very
hard to come by for every program, so the GUI operations are always a
subset of the internal CLI commands. For programs that are only made
for the GUI, this results in not including lots of potentially useful
operations. It also results in `interface design' to be a crucially
important part of any GUI program. Scientists don't usually have
enough resources to hire a graphical designer, also the complexity of
the GUI code is far more than CLI code, which is harmful for a
scientific software, see @ref{Science and its tools}.

@cindex GUI: repeating operations
For those operations with a GUI, one action on the GUI might be more
efficient. However, if you have to repeat that same action more than
once, it will soon become very frustrating and prone to errors. Unless
the designers of a particular program decided to design such a system
for a particular GUI action, there is no general way to run everything
automatically on the GUI.

@cindex GNU Bash
@cindex Reproducible results
@cindex CLI: repeating operations
On the command line, with one command you can run numerous actions
which can come from various CLI capable programs you have decided your
self in any possible permutation with one command@footnote{By writing
a shell script and running it, for example see the tutorials in
@ref{Tutorials}.}. This allows for much more creativity than that
offered to a GUI user. For technical and scientific operations, where
the same operation (using various programs) has to be done on a large
set of data files, this is crucially important. It also allows exact
reproducability which is a foundation principle for scientific
results. The most common CLI (which is also known as a shell) in
GNU/Linux is GNU Bash, we strongly encourage you to put aside several
hours and go through this beautifully explained web page:
@url{https://flossmanuals.net/command-line/}. You don't need to read
or even fully understand the whole thing, only a general knowledge of
the first few chapters are enough to get you going.

Since the operations in the GUI are very limited and they are visible,
reading a manual is not that important in the GUI (most programs don't
even have any!). However, to give you the creative power explained
above, with a CLI program, it is best if you first read the manual of
any program you are using. You don't need to memorize any details,
only an understanding of the generalities is needed. Once you start
working, there are more easier ways to remember a particular option or
operation detail, see @ref{Getting help}.

@cindex Virtual console
To experience the command line in its full glory and not in the GUI
terminal emulator, press the following keys together:
@key{CTRL+ALT+F4}@footnote{Instead of @key{F4}, you can use any of the
keys from @key{F2} to @key{F6} for different virtual consoles. You can
also run a separate GUI from within this console.} to access the
virtual console. To return back to your GUI, press the same keys above
replacing @key{F4} with @key{F1}. In the virtual console, the GUI,
with all its distracting colors and information, is gone. Enabling you
to focus more accurately on your actual work.

@cindex Resource heavy operations
For operations that use a lot of your system's resources (processing a
large number of large astronomical images for example), the virtual
console is the place to run them. This is because the GUI is not
competing with your research work for your system's RAM and CPU. Since
the virtual consoles are completely independent, you can even log out
of your GUI environment to give even more of your hardware resources
to the programs you are running and thus reduce the operating time.

@cindex Secure shell
@cindex SSH
@cindex Remote operation
Since it uses far less system resources, the CLI is also very
convenient for remote access to your computer. Using secure shell
(SSH) you can log in securely to your system (similar to the virtual
console) from anywhere even if the connection speeds are low. There
are apps for smart phones and tablets which allow you to do this.





@node Report a bug, Suggest new feature, New to GNU/Linux?, Introduction
@section Report a bug

@cindex Bug
@cindex Wrong output
@cindex Software bug
@cindex Output, wrong
@cindex Wrong results
@cindex Results, wrong
@cindex Halted program
@cindex Program crashing
@cindex Inconsistent results
According to Wikipedia ``a software bug is an error, flaw, failure, or
fault in a computer program or system that causes it to produce an
incorrect or unexpected result, or to behave in unintended ways''. So
when you see that a program is crashing, not reading your input
correctly, giving the wrong results, or not writing your output
correctly, you have found a bug. In such cases, it is best if you
report the bug to the developers. If it is an immediate issue, the
developers will work hard to correct it as soon as possible.

@cindex Bug reporting
@cindex Version control
Prior to actually filing a bug, it is best to search previous
reports. The issue might have already been found and even
solved. Recently corrected bugs are probably not yet publicly released
because they are scheduled for the next Gnuastro stable release. If
the bug is solved but not yet released and it is an urgent issue for
you, you can get the version controlled source and compile that, see
@ref{Version controlled source}. There are generally two ways to
inform us of bugs:

@itemize
@cindex Mailing list archives
@cindex Mailing list: bug-gnuastro
@cindex @code{bug-gnuastro@@gnu.org}
@item
Send a mail to @code{bug-gnuastro@@gnu.org}. Any mail you send to this
address will be distributed through the bug-gnuastro mailing
list. This is the simplest and preferred way to send bug reports. The
archives of this mailing list can be found at
@url{http://lists.gnu.org/archive/html/bug-gnuastro/}.

@cindex Gnuastro project page
@cindex Support request manager
@cindex Submit new tracker item
@cindex Anonymous bug submission
@item
``Submit a new item'' to the ``Communication tools'' section of the
@url{https://savannah.gnu.org/projects/gnuastro/, Gnuastro project
webpage}
@footnote{@url{https://savannah.gnu.org/projects/gnuastro/}}. All the
bug reports that are sent for Gnuastro (including the mailing list)
are ultimately stored and managed in the Gnuastro project Bugs tracker
@footnote{@url{https://savannah.gnu.org/bugs/?group=gnuastro}}. Users
can also initiate a bug report from the project webpage directly
through the @clicksequence{``Support''@click{}``Submit new''} links on
the top of the page or the ``Submit a new item'' link under the ``Tech
Support Manager'' section (with a red question mark beside it) of the
main Gnuastro project page. You can browse or submit a new item to
this list anonymously. See @ref{Gnuastro project webpage} for more
information about the central management hub of Gnuastro.
@end itemize

@cindex Tracker
@cindex Bug tracker
@cindex Task tracker
@cindex Viewing trackers
Once the items have been gathered from the mailing list or webpage,
the developers will add it to either the ``Bug Tracker'' or ``Task
Manager'' trackers of the Gnuastro project webpage. These two trackers
can only be edited by the Gnuastro project members, but they can be
browsed by anyone. So prior to filing a bug report please browse and
search these two trackers to see if the issue has already been solved
or is being solved.

@cartouche
@noindent
@strong{Individual and independent bug reports:} If you have found
multiple bugs, please send them as separate (and independent) mails as
much as possible. This will significantly help us in managing and
resolving them sooner.
@end cartouche

@cartouche
@cindex Reproducible bug reports
@noindent
@strong{Reproducible bug reports:} If we cannot reproduce your bug,
then it is very hard to resolve it. So please send us a Minimal
working
example@footnote{@url{http://en.wikipedia.org/wiki/Minimal_Working_Example}}
along with the description. For example in running a program, please
send us the full command line text and the output with the @option{-P}
option, see @ref{Final parameter values}. If it is caused only for a
certain input, also send us that input file. In case the input FITS is
large, please use ImageCrop to only crop the problematic section and
make it as small as possible so it can easily be uploaded and
downloaded and not waste the archive's storage, see @ref{ImageCrop}.
@end cartouche


@node Suggest new feature, Announcements, Report a bug, Introduction
@section Suggest new feature

@cindex Feature requests
@cindex Additions to Gnuastro
We would always be very happy to hear of suggested new features. For
every program there are already lists of feautures that we are
planning to add. You can see the current list of plans from the
Gnuastro project webpage at
@url{https://savannah.gnu.org/projects/gnuastro/} and following
@clicksequence{``Tasks''@click{}``Browse''} at the top of the page. If
you want to request a feature to an existing program, click on the
``Display Criteria'' above the list and under ``Category'', choose
that particular program. Under ``Category'' you can also see the
existing suggestions for new utilities or other cases like
installation.

If the feature you want to suggest is not already listed in the task
manager, then inform us through the @code{bug-gnuastro@@gnu.org}
mailing list or submitting an issue through the Gnuastro project
webpage, see @ref{Report a bug}. Please have in mind that the
developers are all very busy with their own astronomical research, and
implementing existing ``task''s to add or resolving bugs. Gnuastro is
a volunteer effort and none of the developers are paid for their hard
work. So, although we will try our best, please don't not expect that
your suggested feature be immediately included (with the next release
of Gnuastro).

The best person to apply the feature is you, since you have the
motivation and need. So you can read @ref{Developing} and start
applying your desired feature. Once you have added it, you can use it
for your own work and if you feel you want others to benefit from your
labour, you can request for it to become part of Gnuastro. You can
then join the developers and start maintaining your own part (utility)
of Gnuastro. If you choose to take this path of action please contact
us before hand (@ref{Report a bug}) so we can avoid possible duplicate
activities and get interested people in contact.

@cartouche
@noindent
@strong{Gnuastro is a collection of low level programs:} As described
in @ref{Design philosophy}, a founding principle of Gnuastro is that
each program should be very basic and low-level. High level jobs
should be done by running the separate programs in succession through
a shell script, see the examples in @ref{Tutorials}. So please
consider how your desired job can best be broken into separate steps.
@end cartouche



@node Announcements, Conventions, Suggest new feature, Introduction
@section Announcements

@cindex Announcements
@cindex Mailing list: info-gnuastro
Gnuastro has a dedicated mailing list for making announcements. Anyone
that is interested can subscribe to this mailing list to stay upto
date with new releases. To subscribe to this list, please visit
@url{https://lists.gnu.org/mailman/listinfo/info-gnuastro}.




@node Conventions, Acknowledgments, Announcements, Introduction
@section Conventions
In this manual we have the following conventions:

@itemize

@item
All commands that are to be run on the shell (command line) prompt as
the user start with a @command{$}. In case they must be run as a
super-user or system administrator, they will start with a
@command{#}. If the command is in a separate line and next line
@code{is also in the code type face}, but doesn't have any of the
@command{$} or @command{#} signs, then it is the output of the command
after it is run. As a user, you don't need to type those lines.

@item
If the command becomes larger than the page width a @key{\} is
inserted in the code. If you are typing the code by hand on the
command line, you don't need to use multiple lines or add the extra
space characters, so you can omit them. If you want to copy and paste
these examples (highly discouraged!) then the @key{\} should stay.

The @key{\} character is a shell escape character which is used
commonly to make characters which have special meaning for the shell
loose that special place (the shell will not treat them specially if
there is a @key{\} behind them). When it is a last character in a line
(the next character is a new-line charactor) the new-line character
looses its meaning an the shell sees it as a simple white-space
character, enabling you to use multiple lines to write your commands.

@end itemize



@node Acknowledgments,  , Conventions, Introduction
@section Acknowledgments

GNU Astronomy Utilities has significantly benefited from the help and
support of various people and institutions. The plain text file
@file{THANKS} which is distributed along with the source code has a
full list. In particular the role of the Japanese Ministry of Science
and Technology (MEXT) scholarship should be acknowledged for the long
term scholarship of Mohammad Akhlaghi's Masters and PhD period in
Tohoku University Astronomical Insitute in Sendai city. Gnuastro would
not have been possible without the long term learning and planning
that could only be acheived with such a long term scholarship. Tohoku
University was the first institution to sign a copyright disclaimer to
the Free Software Foundation for Gnuastro, allowing it to be freely
available for the astronomical community. The very critical view
points of Professor Takashi Ichikawa (at Tohoku University) were also
instrumental in the creation of Gnuastro.

Mohammad-reza Khellat and Alan Lefor kindly studied the manual
multiple times and provided very useful suggestions. Alan and
Mohammad-reza also helped in testing Gnuastro on other operating
systems. Brandon Invergo, Karl Berry and Richard Stallman also
provided very useful suggestions during the GNU evaluation process. At
first we wanted to submit the programs as independent and individual
small programs, but thanks to their suggestions and ideas, all the
separate programs were merged into the complete system that is now
available for the astronomical community. Finally we should thank all
the anonymous developers in various online forums which patiently
answered all our small (but very important) technical questions.




















@node Tutorials, Installation, Introduction, Top
@chapter Tutorials

@cindex Tutorial
@cindex Cookbook
In this chapter we give several tutorials or cookbooks on how to use
the various tools in Gnuastro for your scientific purposes. In these
tutorials, we have intentionally avoided too many cross references to
make it more easily readable. To get more information about a
particular program, you can visit the section with the same name as
the program in this manual. Each program section starts by explaning
the general concepts behind what it does. If you only want to see an
explanation of the options and arguments of any program, see the
subsection titled `Invoking ProgramName'. See @ref{Conventions}, for
an explanation of the conventions we use in the example codes through
the manual.

The tutorials in this section use a fictional setting of some
historical figures in the history of astronomy. We have tried to show
how Gnuastro would have been helpful for them in making their
discoveries if there were GNU/Linux computers in their times! Please
excuse us for any historical inaccuracy, this is not intended to be a
historical reference. This form of presentation can make the tutorials
more pleasent and entertaining to read while also being more practical
(explaining from a user's point of view)@footnote{This form of
presenting a tutorial was influenced by the PGF/TikZ and Beamer
manuals. The first provides graphic capabilities, while with the
second you can make presentation slides in @TeX{} and @LaTeX{}. In
these manuals, Till Tantau (author of the manual) uses Euclid to
present for the tutorial. There are also some nice words of wisdom for
Unix-like systems called ``Rootless Root'':
@url{http://catb.org/esr/writings/unix-koans/}. These also have a
similar style but they use a mythical figure named Master Foo. If you
already have some experience in Unix-like systems, you will definitely
find these ``Unix Koans'' very entertaining.}. The main reference for
the historical facts mentioned in these fictional settings was
Wikipedia.

@menu
* Hubble visually checks and classifies his catalog::  Check a catalog.
* Sufi simulates a detection::  Simulating a detection.
@end menu

@node Hubble visually checks and classifies his catalog, Sufi simulates a detection, Tutorials, Tutorials
@section Hubble visually checks and classifies his catalog

@cindex Edwin Hubble
In 1924 Hubble@footnote{Edwin Powell Hubble (1889 -- 1953 A.D.) was an
American astronomer who can be considered as the father of
extragalactic astronomy, by proving that some nebulae are too distant
to be within the Galaxy. He then went on to show that the universe
appears to expand and also done a visual classification of the
galaxies that is known as the Hubble fork.} announced his discovery
that some of the known nebulous objects are too distant to be within
the the Milky Way (or Galaxy) and that they were probably distant
Galaxies@footnote{Note that at that time, ``Galaxy'' was a proper noun
used to refer to the Milky way. The concept of a galaxy as we define
it today had not yet become common. Hubble played a major role in
creating today's concept of a galaxy.} in their own right. He had also
used them to show that the redshift of the nebulae increases with
their distance. So now he wants to study them more accurately to see
what they actually are. Since they are nebulous or amorphous, they
can't be modeled (like stars that are always a point) easily. So there
is no better way to distinguish them than to visually inspect them and
see if it is possible to classify these nebulae or not.

Hubble has stored all the FITS images of the objects he wants to
visually inspect in his @file{/mnt/data/images} directory. He has also
stored his catalog of extra Galactic nebulae in
@file{/mnt/data/catalogs/extragalactic.txt}. Any normal user on his
GNU/Linux system (including himself) only has read access to the
contents of the @file{/mnt/data} directory. He has done this by
running this command as root:

@example
# chmod -R 755 /mnt/data
@end example

@noindent
Hubble has done this intentionally to avoid mistakenly deleting or
modifying the valuable images he has taken at Mount Wilson while he is
working as an ordinary user. Retaking all those images and data is
simply not an option. In fact they are also in another hard disk
(@file{/dev/sdb1}). So if the hard disk which stores his GNU/Linux
distribution suddenly malfunctions due to work load, his data is not
in harms way. That hard disk is only mounted to this directory when he
wants to use it with the command:

@example
# mount /dev/sdb1 /mnt/data
@end example

@noindent
In short, Hubble wants to keep his data safe and fortunately by
default Gnuastro allows for this.  Hubble creates a temporary
@file{visualcheck} directory in his home directory for this check. He
runs the following commands to make the directory and change to
it@footnote{The @code{pwd} command is short for ``Print Working
Directory'' and @code{ls} is short for ``list'' which shows the
contents of a directory.}:

@example
$ mkdir ~/visualcheck
$ cd ~/visualcheck
$ pwd
/home/edwin/visualcheck
$ ls
@end example

Hubble has multiple images in @file{/mnt/data/images}, some of his
targets might be on the edges of an image and so several images need
to be stitched to give a good view of them. Also his extra Galactic
targets belong to various pointings in the sky, so they are not in one
large image. Gnuastro's ImageCrop is just the utility he wants. The
catalog in @file{extragalactic.txt} is a plain text file which stores
the basic information of all his known 200 extra Galactic nebulae. In
its second column it has each object's Right Ascention (the first
column is a label he has given to each object) and in the third the
object's declination.  Having read the Gnuastro manual, he knows that
all counting is done starting from zero, so the RA and Dec columns
have number 1 and 2 respectively.

@example
$ astimgcrop --racol=1 --deccol=2 /mnt/data/images/*.fits     \
             /mnt/data/catalogs/extragalactic.txt
ImageCrop started on Tue Jun  14 10:18:11 1932
  ---- ./4_crop.fits                  1 1
  ---- ./2_crop.fits                  1 1
  ---- ./1_crop.fits                  1 1
[[[ Truncated middle of list ]]]
  ---- ./198_crop.fits                1 1
  ---- ./195_crop.fits                1 1
  - 200 images created.
  - 200 were filled in the center.
  - 0 used more than one input.
ImageCrop finished in:  2.429401 (seconds)
@end example


@cindex Asynchronous thread allocation
@noindent
Hubble already knows that thread allocation to the the CPU cores is
asynchronous, so each time you run it the order of which job gets done
first differs. When using ImageCrop the order of outputs is irrelevant
since each crop is independent of the rest. This is why the crops are
not necessarily created in the same input order. He is content with
the default width of the outputs (which he inspected by running
@code{$ astimgcrop -P}). If he wanted a different width for the
cropped images, he could do that with the @option{--wwidth} option
which accepts a value in arcseconds.  When he lists the contents of
the directory again he finds his 200 objects as separate FITS images.

@example
$ ls
1_crop.fits 2_crop.fits ... 200_crop.fits
@end example

@cindex GNU Parallel
The FITS image format was not designed for viewing, but mainly for
accurate storing of the data. So he chooses to convert the cropped
images to a more common image format to view them more quickly and
easily through standard image viewers (which load much faster than
FITS image viewer). JPEG is one of the most recognized image formats
that is supported by most image viewers. Fortuantely Gnuastro has just
such a tool to convert various types of file types to and from each
other: ConvertType. Hubble has already heard of GNU Parallel from one
of his colleagues at Mount Wilson Observatory. It allows multiple
instances of a command to be run simultaneously on the system, so he
uses it in conjuction with ConvertType to convert all the images to
JPEG.
@example
$ parallel astconvertt -ojpg ::: *_crop.fits
@end example

@pindex eog
@cindex Eye of GNOME
For his graphical user interface Hubble is using GNOME which is the
default in most distributions in GNU/Linux. The basic image viewer in
GNOME is the Eye of GNOME, which has the executable file name
@command{eog} @footnote{Eye of GNOME is only available for users of
the GNOME graphical desktop environment which is the default in most
GNU/Linux distributions. If you use another graphical desktop
environment, replace @command{eog} with any other image
viewer.}. Since he has used it before, he knows that once it opens an
image, he can use the @key{ENTER} or @key{SPACE} keys on the keyboard
to go to the next image in the directory or the @key{Backspace} key to
to go the previous image. So he opens the image of the first object
with the command below and with his cup of coffee in his other hand,
he flips through his targets very fast to get a good initial
impression of the morphologies of these extra Galactic nebulae.

@example
$ eog 1_crop.jpg
@end example

@cindex GNU Bash
@cindex GNU Emacs
@cindex Spiral galaxies
@cindex Elliptical galaxies
Hubble's cup of coffee is now finished and he also got a nice general
impression of the shapes of the nebulae. He tentatively/mentally
classified the objects into three classes while doing the visual
inspection. One group of the nebulae have a very simple elliptical
shape and seem to have no internal special structure, so he gives them
code 1. Another clearly different class are those which have spiral
arms which he associates with code 2 and finally there seems to be a
class of nebulae in between which appear to have a disk but no spiral
arms, he gives them code 3.

Now he wants to know how many of the nebulae in his extra Galactic
sample are within each class. Repeating the same process above and
writing the results on paper is very time consuming and prone to
errors. Fortunately Hubble knows the basics of GNU Bash shell
programming, so he writes the following short script with a loop to
help him with the job. After all, computers are made for us to operate
and knowing basic shell programming gives Hubble this ability to
creatively operate the computer as he wants. So using GNU
Emacs@footnote{This can be done with any text editor} (his favorite
text editor) he puts the following text in a file named
@file{classify.sh}.

@example
for name in *.jpg
do
    eog $name &
    processid=$!
    echo -n "$name belongs to class: "
    read class
    echo $name $class >> classified.txt
    kill $processid
done
@end example

@cindex Gedit
@cindex GNU Emacs
Fortunately GNU Emacs or even simpler editors like Gedit (part of the
GNOME graphical user interface) will display the variables and shell
constructs in different colors which can really help in understanding
the script. Put simply, the @code{for} loop gets the name of each JPEG
file in the directory this script is run in and puts it in
@code{name}. In the shell, the value of a variable is used by putting
a @code{$} sign before the variable name. Then Eye of GNOME is run on
the image in the background to show him that image and its process ID
is saved internally (this is necessary to close Eye of GNOME
later). The shell then prompts the user to specify a class and after
saving it in @code{class}, it prints the file name and the given class
in the next line of a file named @file{classified.txt}. To make the
script executable (so he can run it later any time he wants) he runs:

@example
$ chmod +x classify.sh
@end example

@noindent
Now he is ready to do the classification, so he runs the script:

@example
$ ./classify.sh
@end example

@noindent
In the end he can delete all the JPEG and FITS files along with
ImageCrop's log file with the following short command. The only files
remaining are the script and the result of the classification.

@example
$ rm *.jpg *.fits astimgcrop.txt
$ ls
classified.txt   classify.sh
@end example

@noindent
He can now use @file{classified.txt} as input to a plotting program to
plot the histogram of the classes and start making interpretations
about what these nebulous objects that are outside of the Galaxy are.



@node Sufi simulates a detection,  , Hubble visually checks and classifies his catalog, Tutorials
@section Sufi simulates a detection

It is the year 953 A.D.  and Sufi@footnote{Abd al-rahman Sufi (903 --
986 A.D.), also known in Latin as Azophi was an Iranian
astronomer. His manuscript ``Book of fixed stars'' contains the first
recorded observations of the Andromeda galaxy, the Large Magellanic
Cloud and seven other non-stellar or `nebulous' objects.}  is in
Shiraz as a guest astronomer. He had come there to use the advanced
123 centimeter astrolabe for his studies on the Ecliptic. However,
something was bothering him for a long time. While mapping the
constellations, there were several non-stellar objects that he had
detected in the sky, one of them was in the Andromeda
constellation. During a trip he had to Yemen, Sufi had seen another
such object in the southern skies looking over the indian ocean. He
wasn't sure if such cloud-like non-stellar objects (which he was the
first to call `Sah@={a}bi' in Arabic or `nebulous') were real
astronomical objects or if they were only the result of some bias in
his observations. Could such diffuse objects actually be detected at
all with his detection technqiue?

He still had a few hours left until nightfall (when he would continue
his studies on the ecliptic) so he decided to find an answer to this
question. He had thoroughly studied Claudius Ptolemy's (90 -- 168 A.D)
Almagest and had made lots of corrections to it, in particular in
measuring the brightness. Using his same experience, he was able to
measure a magnitude for the objects and wanted to simulate his
observation to see if a simulated object with the same brightness and
size could be detected in a simulated noise with the same detection
technique.  The general outline of the steps he wants to take are:

@enumerate

@item
Make some mock profiles in an oversampled image. The initial mock
image has to be oversampled prior to convolution or other forms of
transformation in the image. Through his experiences, Sufi knew that
this is because the image of heavenly bodies is actually transformed
by the atmosphere or other sources outside the atmosphere (for example
gravitational lenses) prior to being sampled on an image. Since that
transformation occurs on a continuous grid, to best approximate it, he
should do all the work on a finer pixel grid. In the end he can
resample the result to the initially desired grid size.

@item
Convolve the image with a PSF image that is oversampled to the same
value as the mock image. Since he wants to finish in a reasonable time
and the PSF kernel will be very large due to oversampling, he has to
use frequency domain convolution which has the side effect of dimming
the edges of the image. So in the first step above he also has to
build the image to be larger by at least half the width of the PSF
convolution kernel on each edge.

@item
With all the transformations complete, the image should be resampled
to the same size of the pixels in his detector.

@item
He should remove those extra pixels on all edges to remove frequency
domain convolution artifacts in the final product.

@item
He should add noise to the (until now, noise-less) mock image. After
all, all observations have noise associated with them.

@end enumerate

Fortunately Sufi had heard of GNU Astronomy Utilities from a colleague
in Isfahan (where he worked) and had installed it on his computer a
year before. It had tools to do all the steps above. He had used
MakeProfiles before, but wasn't sure which columns he had chosen in
his user or system wide configuration files for which parameters, see
@ref{Configuration files}. So to start his simulation, Sufi runs
MakeProfiles with the @option{-P} option to make sure what columns in
a catalog MakeProfiles currently recognizes and the output image
parameters:

@example
$ astmkprof -P
# MakeProfiles (GNU Astronomy Utilities 0.1) 0.1
# Configured on 21 September 952 at 19:37
# Written on Sat Oct  6 15:49:31 953

# Output:
 naxis1              1000
 naxis2              1000
 oversample          5

[[[ Truncated middle of list ]]]

# Catalog:
 xcol                1
 ycol                2
 fcol                3
 rcol                4
 ncol                5
 pcol                6
 qcol                7
 mcol                8
 tcol                9

[[[ Truncated rest of list ]]]
@end example

@noindent
In particular, Sufi looks at the parameters under the catalog
grouping.  Fortunately the columns are naturally numbered such that
column 0 can be an ID he specifies for each object (which MakeProfiles
ignores) and each subsequent column specifies a given
parameter. Fortunately MakeProfiles has the capability to also make
the PSF which is to be used on the mock image and using the
@option{--prepforconv} option, he can also make the mock image to be
larger by the correct amount and all the sources to be shifted by the
correct amount.

For his initial check he decides to simulate the nebula in the
Andromeda constellation. The night he was observing, the PSF had
roughly a FWHM of about 5 pixels, so as the first row, he defines the
PSF parameters and sets the radius column (@code{rcol} above, fifth
column) to @code{5.000}, he also chooses a Moffat function for its
functional form. Remembering how diffuse the nebula in the Andromeda
constellation was, he decides to simulate it with a mock S@'{e}rsic
index 1.0 profile. He wants the output to be 500 pixels by 500 pixels,
so he puts the mock profile in the center. Looking at his drawings of
it, he decides a reasonable effective radius for it would be 40 pixels
on this image pixel scale, he sets the axis ratio and position angle
to approximately correct values too and finally he sets the total
magnitude of the profile to 3.44 which he had accurately
measured. Sufi also decides to truncate both the mock profile and PSF
at 5 times the respective radius parameters. In the end he decides to
put four stars on the four corners of the image at very low magnitudes
as a visual scale.

Using all the information above, he creates the catalog of mock
profiles he wants in a file named @file{cat.txt} (short for catalog)
using his favorite text editor and stores it in a directory named
@file{simulationtest} in his home directory@footnote{The @command{cat}
command prints the contents of a file, short for concatenation.}:

@example
$ mkdir ~/simulationtest
$ cd ~/simulationtest
$ pwd
/home/rahman/simulationtest
$ emacs cat.txt
$ ls
cat.txt
$ cat cat.txt
 0  0.0000   0.0000  1  5.000  4.765  0.0000  1.000  30.000  5.000
 1  250.00   250.00  0  40.00  1.000  -25.00  0.400  3.4400  5.000
 2  50.000   50.000  3  0.000  0.000  0.0000  0.000  9.0000  0.000
 3  450.00   50.000  3  0.000  0.000  0.0000  0.000  9.2500  0.000
 4  50.000   450.00  3  0.000  0.000  0.0000  0.000  9.5000  0.000
 5  450.00   450.00  3  0.000  0.000  0.0000  0.000  9.7500  0.000
@end example

@noindent
He looked into his observation logs and found that the night he was
observing, the zeropoint magnitude was 18. Now he has all the
necessary parameters and runs MakeProfiles with the following command:

@example

$ astmkprof --prepforconv --naxis1=500 --naxis2=500         \
            --zeropoint=18.0 cat.txt
MakeProfiles started on Sat Oct  6 16:26:56 953
  - 6 profiles read from cat.txt             in 0.000209 seconds
  ---- Row 5 complete, 5 left to go.
  ---- Row 3 complete, 4 left to go.
  ---- Row 2 complete, 3 left to go.
  ---- Row 4 complete, 2 left to go.
  ---- ./0.fits created.
  ---- Row 0 complete, 1 left to go.
  ---- Row 1 complete, 0 left to go.
  - cat.fits created.                        in 0.024811 seconds
MakeProfiles finished in:  0.236629 (seconds)
$ls
0.fits  astmkprof.log  cat.fits  cat.txt
@end example

@cindex Oversample
@noindent
The file @file{0.fits} is the PSF Sufi had asked for and
@file{cat.fits} is the image containing the 5 objects. The PSF is now
available to him as a separate file for the convolution step. While he
was preparing the catalog, one of his students came up and was also
following the steps. When he opened the image, the student was
surprised to see that all the stars are only one pixel and not in the
shape of the PSF as we see when we image the sky at night. So Sufi
explained to him that the stars will take the shape of the PSF after
convolution and this is how they would look if we didn't have an
atmosphere or an aperture when we took the image. The size of the
image was also surprising for the student, instead of 500 by 500, it
was 2630 by 2630 pixels. So Sufi had to explain why oversampling is
very important for parts of the image where the flux change is
significant over a pixel. Sufi then explained to him that after
convolving we will resample the image to get our originally desired
size. To convolve the image, Sufi ran the following command:

@example
$ astconvolve --kernel=0.fits cat.fits
Convolve started on Mon Apr  6 16:35:32 953
Convolving cat.fits (hdu: 0)
 with the kernel 0.fits (hdu: 0).
 using 8 CPU threads in the frequency domain.
  - Input and Kernel images padded.          in 0.045576 seconds
  - Images converted to frequency domain.    in 10.486712 seconds
  - Multiplied in the frequency domain.      in 0.032780 seconds
  - Converted back to the spatial domain.    in 5.342335 seconds
  - Padded parts removed.                    in 0.011880 seconds
Convolve finished in:  15.972771 (seconds)
$ls
0.fits  astmkprof.log  cat_convolved.fits  cat.fits  cat.txt
@end example

@noindent
When convolution finished, Sufi opened the @file{cat_convolved.fits}
file and showed the effect of convolution to his student and explained
to him how a PSF with a larger FWHM would make the points even
wider. With the convolved image ready, they were ready to re-sample it
to the orignal pixel scale Sufi had planned. Sufi explained the basic
concepts of warping the image to his student and also the fact that
since the center of a pixel is assumed to take integer values in the
FITS standard, the transformation matrix would not be a simple scaling
but would also need translating, see @ref{Merging multiple
warpings}. Then he ran ImageWarp with the following command:

@example
$ astimgwarp cat_convolved.fits --matrix="0.2,0,0.4  0,0.2,0.4  0,0,1"
ImageWarp started on Mon Apr  6 16:51:59 953
ImageWarp finished in:  0.481421 (seconds)
$ ls
0.fits         cat_convolved.fits         cat.fits
astmkprof.log  cat_convolved_warped.fits  cat.txt
@end example

@noindent
@file{cat_convolved_warped.fits} now has the correct pixel
scale. However, the image is still larger than what we had wanted, it
is 526 (@mymath{500+13+13}) by 526 pixels. The student is slightly
confused, so Sufi also resamples the PSF with ImageWarp and the same
warping matrix and shows him that it is 27 (@mymath{2\times13+1}) by
27 pixels. Sufi goes on to explain how frequency space convolution
will dim the edges and that is why he added the @option{--prepforconv}
option to MakeProfiles, see @ref{If convolving afterwards}. Now that
convolution is done Sufi can remove those extra pixels using
ImageCrop:

@example
$ astimgcrop cat_convolved_warped.fits --section=13:*-13,13:*-13
ImageCrop started on Sat Oct  6 17:03:24 953
  - Read metadata of 1 images.               in 0.000560 seconds
  ---- cat_convolved_warped_crop.fits 1 1
ImageCrop finished in:  0.018917 (seconds)
$ls
0.fits          astmkprof.log           cat_convolved_warped.fits
0_warped.fits   cat_convolved.fits              cat.fits
astimgcrop.log  cat_convolved_warped_crop.fits  cat.txt
@end example

@noindent
Finally, the @file{cat_convolved_warped.fits} has the same
dimensionality as Sufi had asked for in the beginning. All this
trouble was certainly worth it because now there is no dimming on the
edges of the image and the profile centers are more accurately
sampled. The final step to simulate a real observation would be to add
noise to the image. Sufi set the zeropoint magnitude to the same value
that he set when making the mock profiles and looking again at his
observation log, he found that at that night the background flux near
the nebula had a magnitude of 7. So using these values he ran
MakeNoise:

@example
$ astmknoise --zeropoint=18 --background=7 --output=out.fits    \
             cat_convolved_warped_crop.fits
MakeNoise started on Mon Apr  6 17:05:06 953
  - Generator type: mt19937
  - Generator seed: 1428318100
MakeNoise finished in:  0.033491 (seconds)
$ls
0.fits          cat_convolved.fits              cat.txt
0_warped.fits   cat_convolved_warped_crop.fits  out.fits
astimgcrop.log  cat_convolved_warped.fits
astmkprof.log   cat.fits
@end example

@noindent
The @file{out.fits} file now has the noised image of the mock catalog
Sufi had asked for. Seeing how the @option{--output} option allows the
user to specify the name of the output file, the student was confused
and wanted to know why Sufi hadn't used it before? Sufi then explained
to him that for intermediate steps it is best to rely on the automatic
output, see @ref{Automatic output}. Doing so will give all the
intermediate files the same basic name structure, so in the end you
can simply remove them all with the Shell's capabilities. So Sufi
decided to show this to the student by making a shell script from the
commands he had used before.

The command line shell has the capability to read all the separate
input commands from a file. This is very useful when you want to do
the same thing multiple times, with only the names of the files or
minor parameters changing between the different instances. Using the
shell's history (by pressing the up keyboard key) Sufi reviewed all
the commands and then he retrieved the last 5 commands with the
@command{$ history 5} command. He selected all those lines he had
input and put them in a text file named @file{mymock.sh}. Then he used
some shell variables to set the two main constant parts of all the
command to generalized variables.

@example
edge=13
base=cat
rm out.fits

astmkprof --prepforconv --naxis1=500 --naxis2=500            \
          --zeropoint=18.0 "$base".txt
astconvolve --kernel=0.fits "$base".fits
astimgwarp "$base"_convolved.fits --matrix="0.2,0,0.4  0,0.2,0.4  0,0,1"
astimgcrop "$base"_convolved_warped.fits                     \
           --section=$edge:*-$edge,$edge:*-$edge
astmknoise --zeropoint=18 --background=7 --output=out.fits   \
           "$base"_convolved_warped_crop.fits
rm 0*.fits cat*.fits *.log
@end example

@cindex Gedit
@cindex GNU Emacs
Sufi then explained to the eager student that you define a variable by
giving it a name, followed by an @code{=} sign and the value you
want. Then you can reference that variable from anywhere in the script
by calling its name with a @code{$} prefix. So in the script whenever
you see @code{$base}, the value we defined for it above is used. If
you use advanced editors like GNU Emacs or even simpler ones like
Gedit (part of the GNOME graphical user interface) the variables will
become a different color which can really help in understanding the
script. We have put all the @code{$base} variables in double quotation
marks (@code{"}) so the variable name and the following text do not
get mixed, the shell is going to ignore the @code{"} after replacing
the variable value. To make the script executable, Sufi ran the
following command:

@example
$ chmod +x mymock.sh
@end example

@noindent
Then finally, Sufi ran the script, simply by calling its file name:

@example
$ ./mymock.sh
@end example

After the script finished, the only file remaining is the
@file{out.fits} file that Sufi had wanted in the beginning.  Sufi then
explained to the student how he could run this script anywhere that he
has a catalog if the script is in the same directory. The only thing
the student had to modify in the script was the name of the catalog
(the value of the @code{base} variable in the start of the script) and
the value to the @code{edge} variable if he changed the PSF size. The
student was also very happy to hear that he won't need to make it
executable again when he makes changes later, it will remain
executable unless he explicitly changes the executable flag with
@command{chmod}.

The student was really excited, since now, through simple shell
scripting, he could really speed up his work and run any command in
any fashion he likes allowing him to be much more creative in his
works. Until now he was using the graphical user interface which
doesn't have such a facility and doing repetitive things on it was
really frustrating and some times he would make mistakes. So he left
to go and try scripting on his own computer.

Sufi could now get back to his own work and see if the simulated
nebula which resembled the one in the Andromeda constellation could be
detected or not. Although it was extremely faint@footnote{The total
flux of a diffuse object is added over all its pixels to give its
final magnitude. So although the magnitude 3.44 (of the mock nebula)
is orders of magnitude brighter than 6 (of the stars), the central
galaxy is much fainter. Put another way, the flux is distributed over
a large area in the case of a nebula.}, fortunately it passed his
detection tests and he wrote it in the draft manuscript that would
later become ``Book of fixed stars''. He still had to check the other
nebula he saw from Yemen and several other such objects, but they
could wait until tomorrow (thanks to the shell script, he only has to
define a new catalog). It was nearly sunset and they had to begin
preparing for the night's measurements on the ecliptic.




















@node Installation, Common behavior, Tutorials, Top
@chapter Installation

@cindex Installation
To successfully install Gnuastro you have to have the requirements
already installed on your system. They are very basic for most
astronomical programs and you might already have them installed. To
check, try running the @command{$ ./configure} script. If you get no
errors, then you already have them and you can skip
@ref{Requirements}. You can heavily customize your install of
Gnuastro, to learn more about them, see @ref{Installing Gnuastro}. If
you encounter any problems in the installation process, it is probably
already explained in @ref{Known issues}. In @ref{Other useful
software} the installation and usage of some other free software that
are not directly required by Gnuastro but might be useful in
conjunction with it is discussed.



@menu
* Requirements::                Gnuastro requirements.
* Optional requirements::       Optional Gnuastro requirements.
* Installing Gnuastro::         Installing Gnuastro.
@end menu

@node Requirements, Optional requirements, Installation, Installation
@section Requirements

@cindex Dependencies, Gnuastro
@cindex GNU build system
GNU Astronomy Utilities @value{VERSION} have several dependencies,
they all follow the same basic GNU based build system (like that shown
in @ref{Quick start}), so even if you don't have them, installing them
should be pretty straightforward. In this section we explain each
program and any specific note that might be necessary in the
installation.

@cindex Building from source
@cindex Compiling from source
@cindex Source code building
@cindex Source code compilation
@cindex Package managers
The most basic choice is to build the packages from source your self
instead of relying on your distribution's pre-built packages. These
packages might already be available by your distribution's package
management system. You can also use those, just note the following two
issues:

@enumerate
@item
They might not be the most recent release.

@item
For each package, Gnuastro might require certain configuration options
that the your distribution's package managers didn't add for
you. Those configuration options are explained below.

@item
For the libraries, they might separate the binary file from the header
files, see @ref{Known issues}.
@end enumerate



@menu
* GNU Scientific Library::      Installing GSL.
* CFITSIO::                     C interface to the FITS standard.
* WCSLIB::                      C interface to the WCS standard of FITS.
@end menu

@node GNU Scientific Library, CFITSIO, Requirements, Requirements
@subsection GNU Scientific library

@cindex GNU Scientific Library
The GNU Scientific Library is probably already present in your
distribution's package management system. To install it from source,
you can run the following commands after you have
downloaded@footnote{@url{http://www.gnu.org/software/gsl/}}
@file{gsl-X.X.tar.gz}:

@example
$ tar -zxvf gsl-X.X.tar.gz
$ cd gsl-X.X
$ ./configure
$ make
$ make check
$ sudo make install
@end example

@node CFITSIO, WCSLIB, GNU Scientific Library, Requirements
@subsection CFITSIO

@cindex CFITSIO
@cindex FITS standard
CFITSIO is the closest you can get to the pixels in a FITS image while
remaining faithful to the FITS standard
@footnote{@url{http://fits.gsfc.nasa.gov/fits_standard.html}}. It is
written by William Pence, the author of the FITS
standard@footnote{Pence, W.D. et al. Definition of the Flexible Image
Transport System (FITS), version 3.0. (2010) Astronomy and
Astrophysics, Volume 524, id.A42, 40 pp.}, and is regularly
updated. Setting the definitions for all other software packages using
FITS images.

@vindex --enable-reentrant
@cindex Reentrancy, multiple file opening
@cindex Multiple file opening, reentrancy
Some GNU/Linux distributions have CFITSIO in their package managers,
if it is available and updated, you can use it. One problem that might
occur is that CFITSIO might not be configured with the
@option{--enable-reentrant} option by the distribution. This option
allows CFITSIO to open a file in multiple threads. If so, upon
running, any program which needs this capability will warn you and
abort if you ask for multiple threads. In such cases you can take the
following step.

The best way is that you can install CFITSIO from source. You can
download the latest version of the source code and manual from its
webpage@footnote{@url{http://heasarc.gsfc.nasa.gov/fitsio/fitsio.html}}.
We strongly recommend that you have a look through Chapter 2 (Creating
the CFITSIO library) of the CFITSIO manual and understand the options
you can pass to @command{$ ./configure} (they aren't too much). This
is a very basic package for most astronomical software and it is best
that you configure it nicely with your system. Once you download the
source and unpack it, the following configure script should be enough
for most purposes. Don't forget to read chapter two of the manual
though, for example the second option is only for 64bit systems. The
manual also explains how to check if it has been installed correctly.
@example
$ tar -vxzf cfitsio_latest.tar.gz
$ cd cfitsio
$ ./configure --prefix=/usr/local --enable-sse2 --enable-reentrant
$ make
$ sudo make install
@end example





@node WCSLIB,  , CFITSIO, Requirements
@subsection WCSLIB

@cindex WCS
@cindex WCSLIB
@cindex World Coordinate System
WCSLIB is also written and maintained by one of the authors of the
World Coordinate System (WCS) definition in the FITS
standard@footnote{Greisen E.W., Calabretta M.R. (2002) Representation
of world coordinates in FITS. Astronomy and Astrophysics, 395,
1061-1075.}, Mark Calabretta. It might be already built and ready in
your distribution's package management system. Here installation from
source is explained. To install WCSLIB you will need to have the
CFITSIO already installed. WCSLIB also has plotting capabilities which
use PGPLOT (a plotting library for C). However, if you will not be
using its plotting functions, you can configure it such that pgplot is
not required.

@vindex --without-pgplot
If you do want to make plots with WCSLIB, there is an explanation in
@ref{PGPLOT}. To disable the dependency on PGPLOT, you have to add the
@option{--without-pgplot} option to the configure script as you can
see below. You can get the most recent source code from the WCSLIB
webpage@footnote{@url{http://www.atnf.csiro.au/people/mcalabre/WCS/}}.
In the directory where you have downloaded the compressed file, you
can take the following steps (the @code{x.xx} represents the version
number):
@example
$ tar -jxvf wcslib.tar.bz2
$ cd wcslib-x.xx
$ ./configure --without-pgplot LIBS="-pthread -lm"
$ make
$ make check
$ sudo make install
@end example




@node Optional requirements, Installing Gnuastro, Requirements, Installation
@section Optional requirements

Most of the programs in Gnuastro make use of the libraries in
@ref{Requirements}, therefore if they are not available, the configure
script will complain and compiling the Gnuastro is not possible. The
libraries listed in this section are only used for very specific
applications, therefore if you don't want these operations, they do
not need to be present.

@cindex GPL Ghostscript
If the @command{./configure} script can't find these requirements, it
will warn you that they are not present and notify you of the
operation(s) you can't do due to not having them. If the output you
request from a program requires a missing library, that program is
going to warn you and abort. In the case of executables like GPL
GhostScript, if you install them at a later time, the program will
run. This is because if required libraries are not present at build
time, the executables cannot be built, but an executable is called by
the built program at run time so if it becomes available, it will be
used. If you do install an optional library later, you will have to
rebuild Gnuastro and reinstall it for it to take effect.

@menu
* libjpeg::                     Used for JPEG image input/output.
* GPL Ghostscript::             Used for compiling PDF images.
@end menu

@node libjpeg, GPL Ghostscript, Optional requirements, Optional requirements
@subsection libjpeg

@pindex libjpeg
@cindex JPEG format
libjpeg is only used by ConvertType to read from and write to JPEG
images. @url{http://www.ijg.org/, libjpeg} is a very basic library
that provides tools to read and write JPEG images, most of the
GNU/Linux graphic programs and libraries use it. Therefore you most
probably already have it installed.
@url{http://libjpeg-turbo.virtualgl.org/, libjpeg-turbo} is an
alternative to libjpeg. It uses SIMD instructions for ARM based
systems that significantly decreases the processing time of JPEG
compression and decompression algorithms.

@node GPL Ghostscript,  , libjpeg, Optional requirements
@subsection GPL Ghostscript

@cindex GPL Ghostscript
GPL Ghostscript's executable (@command{gs}) is called used by
ConvertType to compile a PDF file from a source PostScript file, see
@ref{ConvertType}. Therefore its headers (and libraries) are not
needed. With a very high probability you already have it in your
GNU/Linux distribution. Unfortunately it does not follow the standard
GNU build style so installing it is very hard. It is best to rely on
your distribution's package managers for this.







@node Installing Gnuastro,  , Optional requirements, Installation
@section Installing GNU Astronomy Utilities

This section is basically a longer explanation to the sequence of
commands given in @ref{Quick start}. If you want to have all the
programs of Gnuastro installed in your system, you don't want to
change the executable names during or after installation, you have
root access to install the programs in a system wide directory, the
Letter paper size of the print manual is fine for you or as a summary
you don't feel like going into the details when everything is working
seamlessly, you can safely skip this section. If you have any of the
above problems or you want to understand the details for a better
control over your build and install, read along.

In the following it is assumed that you have downloaded the compressed
source file, @file{gnuastro-@value{VERSION}.tar.gz}, to the
@file{DOWLD} (short for download) directory, replace this name with
the directory that you want to run the installation in. Note that
after installation, if you don't plan to re-install you no longer need
this file or the uncompressed directory, so you can safely delete
both. The first three steps in @ref{Quick start} need no extra
explanation. Once you uncompress the source file the directory
@file{DOWLD/gnuastro-@value{VERSION}} will be created.


@menu
* Configuring::                 Configure Gnuastro
* Tests::                       Run tests to see if it is working.
* A4 print manual::             Customize the print manual.
* Known issues::                Issues you might encounter.
@end menu





@node Configuring, Tests, Installing Gnuastro, Installing Gnuastro
@subsection Configuring

@pindex ./configure
@cindex Configuring
The @command{$ ./configure} step is the most important step in the
build and install process. All the required packages, libraries,
headers and environment variables are checked in this step. The
behaviors of make and make install can also be set through command
line options to this command.

@cindex Configure options
@cindex Customizing installation
@cindex Installation, customizing
The configure script accepts various arguments and options which
enable the final user to highly customize whatever she is
building. The options to configure are generally very similar to
normal program options explained in @ref{Arguments and
options}. Similar to all GNU programs, you can get a full list of the
options along with a short explanation by running

@example
$ ./configure --help
@end example

@noindent
A complete explanation is also included in the
@file{gnuastro-@value{VERSION}/INSTALL} file in plain text that comes
with the Gnuastro source. Note that this file was written by the
authors of GNU Autoconf and is common for all programs which use the
@command{$ ./configure} script for building and installing (there is a
lot of such programs). Here the most common general usages (not only
Gnuastro) are explained: when you don't have super-user access to the
system and changing the executable names. But before that a review of
the options to configure that are particular to Gnuastro are
discussed.

@menu
* GNU Astronomy Utilities configure options::  Configure options particular to Gnuastro.
* Installation directory::      Specify the directory to install.
* Executable names::            Changing executable names.
@end menu

@node GNU Astronomy Utilities configure options, Installation directory, Configuring, Configuring
@subsubsection GNU Astronomy Utilities configure options

@cindex @command{./configure} options
@cindex Configure options particular to Gnuastro
Most of the options to configure (which are to do with building) are
similar for every program which uses this script. Here the options
that are particular to Gnuastro are discussed. The next topics explain
the usage of other configure options which can be applied to any
program using the GNU build system (through the configure script).

@vtable @option

@cindex CPU threads
@cindex CPU threads, set number
@cindex Number of CPU threads to use
@item --with-numthreads
(=@code{INT}) If this option is given an integer value, that value
will be used for the default number of threads to use. If it is not
given, then the total number of threads will be read from the system,
see @ref{Threads in GNU Astronomy Utilities}. Specifying
@option{--with-numthreads=no} or @option{--without-numthreads} is
equivalent to not calling this option it at all.

@item --enable-progname
Only build and install @file{progname} along with any other program
that is enabled in this fashion. @file{progname} is the name of the
executable without the @file{ast}, for example @file{imgcrop} for
ImageCrop (with the executable name of @file{astimgcrop}). If this
option is called for any of the programs in Gnuastro, any program
which is not explicitly enabled will not be built or installed.

@item --disable-progname
@itemx --enable-progname=no
Do not build or install the program named @file{progname}. This is
very similar to the @option{--enable-progname}, but will build and
install all the other programs except this one.

@item --enable-gnulibcheck
@cindex GNU C Library
@cindex GNU Portability Library
Enable checks on the GNU Portability Library (Gnulib). Gnulib is used
by Gnuastro to enable users of non-GNU based operating systems (that
don't use GNU C Library or glibc) to compile and use the advanced
features that this library provides. We make extensive use of such
functions. If you give this option to @command{$ ./configure}, when
you run @command{$ make check}, first the functions in Gnulib will be
tested, then the Gnuastro executables. If your operating system does
not support glibc or has an older version of it and you have problems
in the build process (@command{$ make}), you can give this flag to
configure to see if the problem is caused by Gnulib not supporting
your operating system or Gnuastro, see @ref{Known issues}.


@end vtable

@cartouche
@noindent
@strong{Note:} If some programs are enabled and some are disabled, it
is equivalent to simply enabling those that were enabled. Listing the
disabled programs is redundant.
@end cartouche

Note that the tests of some programs might require other programs to
have been installed and tested. For example MakeProfiles is the first
program to be tested when you run @command{$ make check}, it provides
the inputs to all the other tests. So if you don't install
MakeProfiles, then the tests for all the other programs will be
skipped or fail. To avoid this, in one run, you can install all the
packages and run the tests but not install. If everything is working
correctly, you can run configure again with only the packages you want
but not run the tests and directly install after building.



@node Installation directory, Executable names, GNU Astronomy Utilities configure options, Configuring
@subsubsection Installation directory

@vindex --prefix
@cindex Superuser, not possible
@cindex Root access, not possible
@cindex No access to super-user install
@cindex Install with no super-user access
One of the most commonly used options to configure is the directory
that will host all the files which require installing, for example the
actual executable files for the program, the documentation and
configuration files. This is done through the @option{--prefix}
option. To demonstrate its applicability, let's assume you don't have
root access to the computer you are using which is one of the most
common usage cases.

In case you don't have super user or root access to the system, you
can't take the installation steps of the command sequence in
@ref{Quick start}. To be able to access the Gnuastro executable files
from anywhere, you have to specify a special directory in the
directories you have write access in, through the shell's environment
variables. Note that this explanation can apply to all the
requirements in @ref{Requirements} in case the system lacks them or
the system wide install was not built with the proper configuration
options. We will start with a short introduction to the shell
variables.

@cindex Shell variables
@cindex Environment variables
Shell variable values are basically treated as strings of
characters. You can define a variable and a value for it by running
@command{$ myvariable=a test value} on the command line. Then you can
see the value in the with the command @command{$ echo $myvariable}. If
a variable has no value, this command will only print an empty
line. This variable will be known as long as this shell or terminal is
running. Other terminals will have no idea it existed.  The main
advantage of shell variables is that if they are exported@footnote{By
running @command{$ export myvariable=a test value} instead of the
simpler case in the text} subsequent programs in that shell can access
their value. So by setting them to any desired value, you can change
the `environment' of the program. The shell variables which are
accessed by programs are therefore known as `environment
variables'@footnote{You can use shell variables for other actions
too, for example to temporarily keep some names or run loops on some
files.}. You can see the full list of the environment variables that
your shell currently recognizes by running:
@example
$ printenv
@end example

@vindex PATH
@pindex ./configure
@cindex Setting @code{PATH}
@cindex Default executable search directory
@cindex Search directory for executables
One of the most commonly used environment variables is @file{PATH}, it
is a list of directories to search for executable names.  The most
basic way to run an executable is to explicitly type the full file
name (including all the directory information) and run it. This is
useful for simple shell scripts or programs that you don't use too
often. However, when the program (an executable) is to be used a lot,
specifying all those directories will become a significant burden. The
@file{PATH} environment variable keeps the address of all the
directories to be searched if directory information is not explicitly
given@footnote{This is why in the sequence of commands in @ref{Quick
start} only @command{$ ./configure} has directory information. By
giving a specific directory (the current directory or @file{./}), we
are explicitly telling the shell to look in the current directory for
an executable named @file{configure} not in the directories listed in
@file{PATH}.}. When you don't have root access, you need to specify a
directory for your self and add that to the @file{PATH} environment
variable.

@cindex GNU Bash
@cindex Startup scripts
@cindex Scripts, startup
Adding your specified directory to the @file{PATH} environment
variable each time you want to run your program is again very
troubling and will not be much of an improvement compared to
explicitely calling the executbale with directory information. So
there are standard `startup files' defined by your shell.  The
commands in these files are run each time you start your system
(@file{/etc/profile} and all scripts in @file{/etc/profile.d/}), when
you log in (@file{~/.bash_profile}) or on each invocation of the shell
(the terminal, @file{~/.bashrc})@footnote{These directories are the
standard in GNU Bash, other shells might have different startup
files.}.

@cindex @file{HOME}
@cindex @file{HOME/.local/}
@cindex Environment variable, @code{HOME}
@file{HOME} is another commonly used environment variable, it is any
user's (the one that is logged in) top directory. It is used so often
that Bash has a special expansion for it: @file{~}, whenever you see
file names starting with the tilde sign, it actually represents the
value to the @file{HOME} environment variable. The standard directory
where you can keep installed files for your own user is the
@file{~/.local/}.  You can use this directory as the top directory for
installing all the programs (executables), libraries, manuals and
shared data that you need.

Let's call the directory you have chosen with @file{USRDIR} since the
standard is just a suggestion. Please replace it with any directory
name you choose. To notify the build system of the program to install
the files in this directory, you can add the following option to the
configure script. When you subsequently run @command{$ make install}
all the installable files will be put there.

@cindex Install directory
@cindex Directory, install
@example
$ ./configure --prefix=USRDIR
@end example


@cindex @file{.bashrc}
The @file{USRDIR/bin} directory is the place where the executables (or
binary files) are installed. So you have to add that to your
@command{PATH} environment variable by placing the following command
in the @file{$HOME/.bashrc} file or any of the startup files discussed
above. The directories listed in @command{$PATH} specify the locations
that the system will check to find the executable name you have asked
for. Each directory is separated by a colon (@file{:}). So through the
command below you will concatenate your directory to the already
existing list.

@example
export PATH=$PATH:USRDIR/bin
@end example

@cindex @file{INFODIR}
@cindex @file{MANPATH}
@cindex @file{LD_LIBRARY_PATH}
@cindex Library search directory
@cindex Default library search directory
In case you install libraries (like the requirements of Gnuastro) with
this method locally, you also have to notify the system to search for
shared libraries in your installed directory. To do that add
@file{USRDIR/lib} to your @command{LD_LIBRARY_PATH} environment
variable similar to the example above for @command{PATH}. If you also
want to access the Info and man pages documentations add the
@file{USRDIR/share/info} and @file{USRDIR/share/man} to your
@command{INFODIR} and @command{MANPATH} environment variables.

@cindex Search directory order
@cindex Order in search directory
A final note is that order matters in the directories that are
searched. In the example above, the new directory was added after the
system specified directories. So if the program, library or manuals
are found in the system wide directories, the user directory is no
longer searched. If you want to search your local installation first,
put the new directory before the already existing list like the
example below.

@example
export PATH=USRDIR/bin:$PATH
@end example

@noindent
This is good when a library for example CFITSIO is already present on
the system but wasn't installed with the correct configuration flags
discussed above. Since you can't re-install, with this order, the
system will first find the one you installed with the correct
configuration flags. However there are security problems, because all
system wide programs and libraries can be replaced by non-secure
versions if they also exist in @file{USRDIR}. So if you choose this
order, be sure to keep it clean from executables with the same names
as important system programs.





@node Executable names,  , Installation directory, Configuring
@subsubsection Executable names

@cindex Executable names
@cindex Names of executables
At first sight, the names of the executables for each program might
seem to be uncommonly long, for example @command{astnoisechisel} or
@command{astimgcrop}. We could have chosen terse (and cryptic) names
like most programs do. We chose this complete naming convention
(something like the commands in @TeX{}) so you don't have to spend too
much time remembering what the name of a specific program was. Such
complete names also enable you to easily search for the programs.

@cindex Shell auto-complete
@cindex Auto-complete in the shell
To facilitate typing the names in, we suggest using the shell
auto-complete. With this facility you can find the executable you want
very easily. It is very similar to file name completion in the
shell. For example, simply by typing the letters bellow (where
@key{[TAB]} stands for the Tab key on your keyboard)

@example
$ ast[TAB][TAB]
@end example

@noindent
you will get the list of all the available executables that start with
@command{ast} in your @command{PATH} environment variable
directories. So, all the Gnuastro executables installed on your system
will be listed. Typing the next letter for the specific program you
want along with a Tab, will limit this list until you get to your
desired program.

@cindex Names, customize
@cindex Customize executable names
In case all of this does not convince you and you still want to type
short names, some suggestions are given below. You should have in mind
though, that if you are writing a shell script that you might want to
pass on to others, it is best to use the standard name because other
users might not have adopted the same customizations. The long names
also serve as a form of documentation in such scripts. A similar
reasoning can be given for option names in scripts: it is good
practice to always use the long formats of the options in shell
scripts, see @ref{Options}.

@cindex Symbolic link
The simplest solution is making a symbolic link to the actual
executable. For example let's assume you want to type @file{ic} to run
ImageCrop instead of @file{astimgcrop}. Assuming you installed
Gnuastro executables in @file{/usr/local/bin} (default) you can do
this simply by running the following command as root:

@example
# ln -s /usr/local/bin/astimgcrop /usr/local/bin/ic
@end example

@noindent
In case you update Gnuastro and a new version of ImageCrop is
installed, the default executable name is the same, so your custom
symbolic link still works.

@vindex --program-prefix
@vindex --program-suffix
@vindex --program-transform-name
The installed executable names can also be set using options to
@command{$ ./configure}, see @ref{Configuring}. GNU Autoconf (which
configures Gnuastro for your particular system), allows the builder
to change the name of programs with the three options
@option{--program-prefix}, @option{--program-suffix} and
@option{--program-transform-name}. The first two are for adding a
fixed prefix or suffix to all the programs that will be installed.
This will actually make all the names longer!  You can use it to add
versions of program names to the programs in order to simultaneously
have two executable versions of a program.

@cindex SED, stream editor
@cindex Stream editor, SED
The third configure option allows you to set the executable name at
install time using the SED utility. SED is a very useful `stream
editor'. There are various resources on the internet to use it
effectively. However, we should caution that using configure options
will change the actual executable name of the installed program and on
every re-install (an update for example), you have to also add this
option to keep the old executable name updated. Also note that the
documentation or configuration files do not change from their standard
names either.

@cindex Removing @file{ast} from executables
For example, let's assume that typing @file{ast} on every invocation
of every program is really annoying you! You can remove this prefix
from all the executables at configure time by adding this option:

@example
$ ./configure --program-transform-name='s/ast/ /'
@end example



@node Tests, A4 print manual, Configuring, Installing Gnuastro
@subsection Tests

@cindex @command{make check}
@cindex @file{mock.fits}
@cindex Tests, running
@cindex Checking tests
After successfully building (compiling) the programs with the
@command{$ make} command you can check the installation before
installing. To run the tests on your newly build utilities, run

@example
$ make check
@end example

For every program some tests are designed to check some possible
operations. Running the command above will run those tests and give
you a final report. If everything is ok and you have built all the
programs, all the tests should pass. In case any of the tests fail,
please have a look at @ref{Known issues} and if that still doesn't fix
your problem, look that the @file{./tests/test-suite.log} file to see
if the source of the error is something particular to your system or
more general. If you feel it is general, please contact us because it
might be a bug. Note that the tests of some programs depend on the
outputs of other program's tests, so if you have not installed them
they might be skipped or fail. Prior to releasing every distribution
all these tests are checked. If you have a reasonably modern terminal,
the outputs of the successful tests will be colored green and the
failed ones will be colored red.

These scripts can also act as a good set of examples for you to see
how the programs are run. All the tests are in the
@file{gnuastro-@value{VERSION}/tests} directory. The tests for each
program are shell scripts (ending with @file{.sh}) in a subdirectory
of this directory with the same name as the program. See @ref{Test
scripts} for more detailed information about these scripts incase you
want to inspect them.




@node A4 print manual, Known issues, Tests, Installing Gnuastro
@subsection A4 print manual

@cindex A4 print manual
@cindex Modifying print manual
@cindex A4 paper size
@cindex US letter paper size
@cindex Paper size, A4
@cindex Paper size, US letter
The default print manual is provided in the letter paper size. If you
would like to have the print version of this manual on paper and you
are living in a country which uses A4, then you can rebuild the
manual. The great thing about the GNU build system is that the manual
source code which is in Texinfo is also distributed with the program
source code, enabling you to do such customizations (hacking).

@cindex GNU Texinfo
In order to change the paper size, you will need to have GNU Texinfo
installed. For simplicity, let's assume @file{SRCdir} is equivalent to
@file{DOWLD/gnuastro-@value{VERSION}}. Open
@file{SRCdir/doc/gnuastro.texi} with any text editor. This is the
source file that created this manual. In the first few lines you will
see this line:

@example
@@c@@afourpaper
@end example

@noindent
In Texinfo, a line is commented with @code{@@c}. Therefore, uncomment
this line by deleting the first two characters such that it changes
to:

@example
@@afourpaper
@end example

@noindent
Save the file and close it. You can now run

@example
$ make pdf
@end example

@noindent
and the new PDF manual will be available in
@file{SRCdir/doc/gnuastro.pdf}. By changing the @command{pdf} in
@command{$ make pdf} to @command{ps} or @command{dvi} you can have the
manual in those formats. Note that you can do this for any manual that
is in Texinfo format, they might not have @code{@@afourpaper} line, so
you can add it close to the top of the Texinfo source file.




@node Known issues,  , A4 print manual, Installing Gnuastro
@subsection Known issues

Depending on your operating system and the version of the compiler you
are using, you might confront some known problems during the
configuration (@command{$ ./configure}), compilation (@command{$
make}) and tests (@command{$ make check}). Here, their solutions are
discussed.

@itemize
@cindex Configuration, not finding library
@cindex Development packages
@item
@command{$ ./configure}: @emph{Configure complains about not finding a
library even though you have installed it.} The possible solution is
based on how you installed the package:

@itemize
@item
From your distribution's package manager. Most probably this is
because your distribution has separated the header files of a library
from the library parts. Please also install the `development' packages
for those libraries too. Just add a @file{-dev} or @file{-devel} to
the end of the package name and re-run the package manager. This will
not happen if you install the libraries from source. When installed
from source, the headers are also installed.

@item
@cindex @command{LDFLAGS}
From source. Then your linker is not looking where you installed the
library. If you followed the instructions in this chapter, all the
libraries will be installed in @file{/usr/local/lib}. So you have to
tell your linker to look in this directory. To do so, add
@command{LDFLAGS=-L/usr/local/lib} to the Gnuastro configure
script. If you want to use the libraries for your other programming
projects, then export this environment variable similar to the case
for @file{LD_LIBRARY_PATH} explained below.

@end itemize

@item
@cindex GNU Portability Library
@vindex --enable-gnulibcheck
@command{$ make}: @emph{Complains about an unknown function on a
non-GNU based operating system.} In this case, please run @command{$
./configure} with the @option{--enable-gnulibcheck} option to see if
the problem is from the GNU Portability Library (Gnulib) not
supporting your system or if there is a problem in Gnuastro, see
@ref{GNU Astronomy Utilities configure options}. If the problem is not
in Gnulib
and after all its tests you get the same complaint from
@command{make}, then please contact us at
@file{bug-gnuastro@@gnu.org}. The cause is probably that a function
that we have used is not supported by your operating system and we
didn't included it along with the source tar ball. If the function is
available in Gnulib, it can be fixed immediately.

@item
@cindex @command{CPPFLAGS}
@command{$ make}: @emph{Can't find the headers (.h files) of libraries
installed from source.} Similar to the case for @file{LDFLAGS}
(above), your compiler is not looking in the right place, add
@command{CPPFLAGS=-I/usr/local/include} to @command{./configure} to
re-configure Gnuastro, then re-run make.

@cindex Tests, only one passes
@cindex @file{LD_LIBRARY_PATH}
@item
@command{$ make check}: @emph{Only one (the first) test passes, all the
rest fail.}  It is highly likely that your distribution doesn't look
into the @file{/usr/local/lib} directory when searching for shared
libraries. To make sure it is added to the list of directories, run
the following command and restart your terminal: (you can ignore the
@command{\} and extra space if you type it, it is only necessary if
you copy and paste). See @ref{Installation directory} for more
details.
@example
echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib' \
     >> ~/.bashrc
@end example

@cindex GPL Ghostscript
@item
@command{$ make check}: @emph{The tests relying on external programs
(for example @file{fitstopdf.sh} fail.}) This is probably due to the
fact that the version number of the external programs is too old for
the tests we have preformed. Please update the program to a more
recent version. For example to create a PDF image, you will need GPL
Ghostscript, but older versions do not work, we have successfully
tested it on version 9.15. Older versions might cause a failure in the
test result.

@item
@cindex @TeX{}
@cindex GNU Texinfo
@command{$ make pdf}: @emph{The PDF manual cannot be made.} To make a
PDF manual, you need to have the GNU Texinfo program (like any
program, the more recent the better). A working @TeX{} program is also
necessary, which you can get from Tex
Live@footnote{@url{https://www.tug.org/texlive/}}.

@end itemize

@noindent
If your problem was not listed above, please file a bug report
(@ref{Report a bug}).



















@node Common behavior, Files, Installation, Top
@chapter Common behavior

There are some facts that are common to all the programs in Gnuastro
which are mainly to do with user interaction. In this chapter these
aspects are discussed. The most basic are the command line options
which are common in all the programs for a unified user
experience. All Gnuastro programs can use configuration files so you
don't have to specify all the parameters on the command line each time
you run a program. The manner of setting, checking and using the these
files at various levels are also explained. Finally we discuss how you
can get immediate and distraction-free (without taking your hands off
the keyboard!) help on the command line.

@menu
* Command line::                How to use the command line.
* Configuration files::         Values for unspecified variables.
* Threads in GNU Astronomy Utilities::  How threads are managed in Gnuastro.
* Final parameter values::      The final set of used parameters.
* Automatic output::            About automatic output names.
* Getting help::                Getting more information on the go.
* Output headers::              Common headers to all FITS outputs.
@end menu

@node Command line, Configuration files, Common behavior, Common behavior
@section Command line

All the programs in GNU Astronomy Utilities are customized through the
standard GNU style command line options. First a general outline of
how to make best use of these options is discussed and finally the
options that are common to all the programs in Gnuastro are listed.

@cindex Metacharacters
@cindex Token separation
@cindex Command line token separation
@cindex Separating tokens on the command line
Your full command line text is passed onto the shell as a string of
characters. That string is then broken up into separate `words' by
any `metacharacters' (like space, tab, @command{|}, @command{>} or
@command{;}) that might exist in the text. @xref{Definitions,
`metacharacters' and `words', Definitions, bash.info, the Bash
manual}, for the complete list of meta-characters and other Bash
definitions. @xref{Shell Operation, ,Shell Operation, bash.info, the
Bash manual}, for a short summary of the steps the shell takes before
passing the commands to the program you called.

@menu
* Arguments and options::       Basics of options and arguments.
* Arguments::                   Treatment of arguments.
* Options::                     How to use GNU style options.
* Common options::              Common options to all Gnuastro programs.
@end menu

@node Arguments and options, Arguments, Command line, Command line
@subsection Arguments and options

@cindex Options to programs
@cindex Command line options
@cindex Arguments to programs
@cindex Command line arguments
On the command line, the first thing you enter is the name of the
program you want to run. After that you can specify two types of
input: @emph{arguments} and @emph{options}.  Arguments are those
tokens that are not preceded by any hyphens (@command{-}), the program
is suppose to understand what they are without any help from the
user.

@vindex --help
@vindex --usage
@cindex Mandatory arguments
Arguments can be both mandatory and optional and since there is no
help from you, their order might also matter (for example in
@command{cp} which is used for copying). The outputs of
@option{--usage} and @option{--help} shows which arguments are
optional and which are mandatory, see @ref{--usage}. As their name
suggests, @emph{options} are only optional and most of the time you
don't have to worry about what order you specify them in.

@cindex Metacharacters on the command line
In case your arguments or option values contain any of the shell's
meta-characters, you have to quote them. If there is only one such
character, you can use a backslash (@command{\}) before it. If there
are multiple, it might be easier to simply put your whole argument or
option value inside of double quotes (@command{"}). In such cases,
everything inside the double quotes will be seen as one `word'.

@cindex HDU
@cindex Header data unit
For example let's say you want to specify the Header data unit (HDU) of
your FITS file using a complex expression like @command{3;
images(exposure > 100)}. If you simply add these after the
@option{--hdu} (@option{-h}) option, the programs in Gnuastro will
read the value to the HDU option as @command{3} and run. Then, Bash
will attempt to run a separate command @command{images(exposure >
100)} and complain about a syntax error. This is because the semicolon
(@command{;}) is an `end of command' character in Bash. To solve
this problem you can simply put double quotes around the whole string
you want to pass as seen below:
@example
$ astimgcrop --hdu="3; images(exposure > 100)" FITSimage.fits
@end example
Alternatively you can put a @command{\} before every metacharacter in
this string, but probably you will agree with us that the double
quotes are much more easier, elegant and readable.




@node Arguments, Options, Arguments and options, Command line
@subsection Arguments
In GNU Astronomy Utilities, the names of the input data files and
ASCII tables are mostly specified as arguments, you can generally
specify them in any order unless otherwise stated for a particular
program. Everything particular about the how a program treats
arguments, is explained under the ``Invoking ProgramName'' section for
that program.

Generally, if there is a standard file name extension for a particular
format, that filename extension is used to separate the kinds of
arguments. The list below shows what astronomical data formats are
recognized based on their file name endings. If the program doesn't
accept any other data format, any other argument that doesn't end with
the specified extentions below is considered to be a text file
(usually catalogs). For example @ref{ConvertType} accepts other data
formats.

@cindex Astronomical data suffixes
@cindex Suffixes, astronomical data
@itemize

@item
@file{.fits}: The standard file name ending of a FITS image.

@item
@file{.fits.Z}: A FITS image compressed with @command{compress}.

@item
@file{.fits.gz}: A FITS image compressed with GNU zip (gzip).

@item
@file{.imh}: IRAF format image file.

@end itemize

Through out this manual and in the command line outputs, whenever we
want to generalize all such astronomical data formats in a text place
holder, we will use @file{ASTRdata}, we will assume that the extension
is also part of this name. Any file ending with these names is
directly passed on to CFITSIO to read. Therefore you don't necessarily
have to have these files on your computer, they can also be located on
an FTP or HTTP server too, see the CFITSIO manual for more
information.

CFITSIO has its own error reporting techniques, if your input file(s)
cannot be opened, or read, those errors will be printed prior to the
final error by Gnuastro.



@node Options, Common options, Arguments, Command line
@subsection Options

@cindex GNU style options
@cindex Options, GNU style
@cindex Options, short (@option{-}) and long (@option{--})
Command line options allow configuring the behaviour of a program in
all GNU/Linux applications for each particular execution. Most options
can be called in two ways: @emph{short} or @emph{long} a small number
of options in some programs only have the latter type. In the list of
options provided in @ref{Common options} or those for each program,
both formats are shown for those which support both. First the short
is shown then the long. Short options are only one character and only
have one hyphen (for example @option{-h}) while long options have two
hyphens an can have many characters (for example @option{--hdu}).

Usually, the short options are for when you are writing on the command
line and want to save keystrokes and time. The long options are good
for shell scripts, where you don't usually have a rush and they
provide a level of documentation, since they are less cryptic. Usually
after a few months of not running a program, the short options will be
forgotten and reading your previously written script will not be easy.

@cindex On/Off options
@cindex Options, on/off
Some options need to be given a value if they are called and some
don't. You can think of the latter type of options as on/off
options. These two types of options can be distinguished using the
output of the @option{--help} and @option{--usage} options, which are
common to all GNU software, see @ref{Getting help}. The following
convention is used for the formats of the values in Gnuastro:

@vtable @option

@item INT
The value is read as an integer. If a float or a string is provided
the program will warn you and abort. In most cases, integers are used
for counting variables, so if they are negative the program will also
abort.

@item 4or8
Either the value 4 or 8, any other integer will give a
warning and abort.

@item FLT
The value is read as a float. There are generally two types, depending
on the context. If they are for fractions, they will have to be less
than or equal to unity.

@item STR
The value is read as a string of characters (for example a file name)
or other particular settings like a HDU name, see below.

@end vtable

@noindent
@cindex Values to options
@cindex Option values
To specify a value in the short format, simply put the value after the
option. Note that since the short options are only one character long,
you don't have to type anything between the option and its value. For
the long option you either need white space or an @option{=} sign, for
example @option{-h2}, @option{-h 2}, @option{--hdu 2} or
@option{--hdu=2} are all equivalent.

The short format of on/off options (those that don't need values) can
be concatenated for example these two hypothetical sequences of
options are equivalent: @option{-a -b -c4} and @option{-abc4}.  As an
example, consider the following command to run ImageCrop:
@example
$ astimgcrop -Dr3 --wwidth 3 catalog.txt --deccol=4 ASTRdata
@end example
@noindent
The @command{$} is the shell prompt, @command{astimgcrop} is the
program name. There are two arguments (@command{catalog.txt} and
@command{ASTRdata}) and four options, two of them given in short
format (@option{-D}, @option{-r}) and two in long format
(@option{--width} and @option{--deccol}). Three of them require a
value and one (@option{-D}) is an on/off option.

@vindex --printparams
@cindex Options, abbreviation
@cindex Long option abbreviation
If an abbreviation is unique between all the options of a program, the
long option names can be abbreviated. For example, instead of typing
@option{--printparams}, typing @option{--print} or maybe even
@option{--pri} will be enough, if there are conflicts, the program
will warn you and show you the alternatives. Finally, if you want the
argument parser to stop parsing arguments beyond a certain point, you
can use two dashes: @option{--}. No text on the command line beyond
these two dashes will be parsed.

@cindex Repeated options
@cindex Options, repeated
If an option with a value is repeated or called more than once, the
value of the last time it was called will be assigned to it. This very
useful in complicated sitations, for example in scripts. Let's say you
want to make a small modification to one option value. You can simply
type the option with a new value in the end of the command and see how
the script works. If you are satisfied with the change, you can remove
the original option. If the change wasn't satsifactory, you can remove
the one you just added and not worry about saving the original
value. Without this capability, you would have to memorize or save the
original value somewhere else, run the command and then change the
value again which is not at all convenient and is potentially cause
lots of bugs.

@cindex Configuration files
@cindex Default option values
When you don't call an option that requires a value, all the programs
in Gnuastro will check configuration files to find a value for that
parameter. To learn more about how folder, user and system wide
configuration files can be set, please see @ref{Configuration
files}. Another factor that is particular to Gnuastro is that it will
check the value you have given for each option to see if it is
reasonable. For example you might mistakenly give a negative, float or
string value for a FITS image extension or column number. As another
example, you might give a value larger than unity for an option that
only accepts fractions (which are always less than unity and
positive).

@cartouche
@noindent
@cindex Tilde expansion as option values
@strong{CAUTION:} In specifying a file address, if you want to use the
shell's tilde expansion (@command{~}) to specify your home directory,
leave at least one space between the option name and your value. For
example use @command{-o ~/test}, @command{--output ~/test} or
@command{--output= ~/test}. Calling them with @command{-o~/test} or
@command{--output=~/test} will disable shell expansion.
@end cartouche
@cartouche
@noindent
@strong{CAUTION:} If you forget to specify a value for an option which
requires one, and that option is the last one, Gnuastro will warn
you. But if it is in the middle of the command, it will take the text
of the next option or argument as the value which can cause undefined
behaviour.
@end cartouche
@cartouche
@noindent
@cindex Counting from zero.
@strong{NOTE:} All counting in Gnuastro starts from 0 not 1. So for
example the first FITS image extension or column in a table are noted
by 0, not 1. This is the standard in C and all languages that are
based on it (for example C++, Java and Python).
@end cartouche

@node Common options,  , Options, Command line
@subsection Common options

@cindex Options common to all utilities
@cindex Gnuastro common options
To facilitate the job of the users and developers, all the programs in
Gnuastro share some basic command line options for the same
operations where they are relevant. The list of options is provided
below. It is noteworthy that these similar options are hard-wired into
the programming of all of Gnuastro programs using GNU C Library's
argument parser merging ability.

@cindex Irrelevant options
@cindex Options, irrelevant
For some programs, some of the options, might be irrelevant for
example MakeProfiles creates FITS images based on a given
catalog. Therefore no input images (and thus HDUs) are necessary for
it. In such cases, the option is still listed and if a value is given
for it, it is completely ignored.

@menu
* Input output::                Common input/output options.
* Operating modes::             Common operating mode options.
@end menu

@node Input output, Operating modes, Common options, Common options
@subsubsection Input/Output options

These options are to do with the input and outputs of the various
programs.

@vtable @option

@cindex HDU
@cindex Header data unit
@item -h
@itemx --hdu
(@option{=STR}) The number or name of the desired Header Data Unit or
HDU in the input FITS image or images. A FITS file can store multiple
HDUs or extensions, each with either an image or a table or nothing at
all (only a header). Note that counting of the extensions starts from
0(zero), not 1(one). When specifying the name, case is not important
so @command{IMAGE}, @command{image} or @command{ImAgE} are equivalent.

A @code{#} is appended to the string you specify for the
HDU@footnote{With the @code{#} character, CFITSIO will only read the
desired HDU into your memory, not all the existing HDUs in the fits
file.} and the result is put in square brackets and appended to the
FITS file name before calling CFITSIO to read the contents of the HDU
for all the programs in Gnuastro. CFITSIO has many capabilities to
help you find the extension you want, far beyond the simple extension
number and name. See CFITSIO manual's ``HDU Location Specification''
section for a very complete explanation with several examples.

@item -o
@itemx --output
(@option{=STR}) The name of the output file or directory. With this
option the automatic output names explained in @ref{Automatic output}
are ignored.

@item -D
@itemx --dontdelete
By default, if the output file already exists, it will be silently
replaced with the output of this run of all Gnuastro programs. By
calling this option, if the output file already exists, the programs
will warn you and abort.

@item -K
@itemx --keepinputdir
In automatic output names, don't remove the directory information of
the input file names. As explained in @ref{Automatic output}, if no
output name is specified, then the output name will be made in the
existing directory based on your input. If you call this option, the
directory information of the input will be kept and the output will be
in the same directory as the input. Note that his is only relevant if
you are running the program from another directory!

@end vtable

@node Operating modes,  , Input output, Common options
@subsubsection Operating modes

Another group of options that are common to all the programs in
Gnuastro are those to do with the general operation of the
programs. The explanation for those that are not only limited to
Gnuastro but can be called in all GNU programs start with (GNU
option).

@vtable @option

@item --
(GNU option) Stop parsing the command line. This option can be useful
in scripts or when using the shell history. Suppose you have a long
list of options, and want to see if removing some of them (and using
the default values) can give a better result. If the ones you want to
remove are the last ones on the command line, you don't have to delete
them, you can just add @option{--} before them and if you don't get
what you want, you can remove the @option{--} and get the same initial
result.

@item --usage
(GNU option) Only print the options and arguments. This is very useful
for when you know the what the options do, you have just forgot their
names. See @ref{--usage}.

@item -?
@itemx --help
(GNU option) Print all options and an explanation. Adding this option
will print all the options in their short and long formats, also
displaying which ones need a value if they are called (with an
@option{=} after the long format). A short explanation is also given
for what the option is for. The program will quit immediately after
the message is printed and will not do any form of processing. See
@ref{--help}.

@item -V
@itemx --version
(GNU option) Print a short message, showing the full name, version,
copyright information and program authors. On the first line it will
print the official name (not executable name) and version number of
the program. It will also print the version of the Gnuastro that the
program was built with. Following this is a blank line and a copyright
information. The program will not run.

@item -q
@itemx --quiet
Don't report steps. All the programs in Gnuastro that have multiple
major steps will report their steps for you to follow while they are
operating. If you do not want to see these reports, you can call this
option and only error messages will be printed if the program is
aborted. If the steps are done very fast (depending on the properties
of your input) disabling these reports will also decrease running
time.

@item --cite
Print the Bib@TeX{} entry for Gnuastro and the particular program (if
that program comes with a separate paper) and abort. Citations are
vital for the continued work on Gnuastro. Gnuastro started and is
continued based on separate research projects. So if you find any of
the tools offered in Gnuastro to be useful in your research, please
use the output of this command to cite the program and Gnuastro in
your research paper. Thank you.

GNU Astronomy Utilities is still new, there is no separate paper only
devoted to Gnuastro yet. Therefore currently the paper to cite for
Gnuastro is the paper for NoiseChisel which is the first published
paper introducing Gnuastro to the astronomical community. Upon
reaching a certain point, a paper completely devoted to Gnuastro will
be published, see @ref{GNU Astronomy Utilities 1.0}.

@item -P
@itemx --printparams
Print the final values used for all the parameters and abort. See
@ref{Final parameter values} for more details.

@item -S
@itemx --setdirconf
Update the current directory configuration file from the given command
line options and quit, see @ref{Configuration files}. The values of
your options are added to the configuration file in the current
directory. If the configuration file or folder doesn't exist, it will
be created. If it exists but has different values for those options,
they will be given the new values. In any case, the program will not
run, but the contents of its updated configuration file are printed
for you to inspect.

This is the recommended method to fill the configuration file for all
future calls to one of the Gnuastro programs in a folder. It will
internally check if your values are in the correct range and type and
save them according to the configuration file format, see
@ref{Configuration file format}.

When this option is called, the otherwise mandatory arguments, for
example input image or catalog file(s), are no longer mandatory (since
the program will not run).

@item -U
@itemx --setusrconf
Update the user configuration file from the command line options and
quit. See explanation under @option{--setdirconf} for more details.

@cindex CPU threads, set number
@cindex Number of CPU threads to use
@item -N
@itemx --numthreads
(@option{=INT}) Set the number of CPU threads to use. See @ref{Threads
in GNU Astronomy Utilities}.

@end vtable






@node Configuration files, Threads in GNU Astronomy Utilities, Command line, Common behavior
@section Configuration files

@cindex @file{etc}
@cindex Configuration files
@cindex Necessary parameters
@cindex Default option values
@cindex File system Hierarchy Standard
Each program needs a certain number of parameters to run. Supplying
all the necessary parameters each time you run the program is very
frustrating and prone to errors. Therefore all the programs read the
values for the necessary options you have not given in the command
line from one of several plain text files (which you can view and edit
with any text editor). These files are known as configuration files
and are usually kept in a directory named @file{etc/} according to the
file system hierarchy
standard@footnote{@url{http://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard}}.

@vindex --output
@vindex --numthreads
@cindex CPU threads, number
@cindex Internal default value
@cindex Number of CPU threads to use
The thing to have in mind is that none of the programs in Gnuastro
keep any internal default value. All the values must either be stored
in one of the configuration files or explicitly called in the command
line. In case the necessary parameters are not given through any of
these methods, the program will list the missing necessary parameters
and abort. The only exception to this is @option{--numthreads}, whose
default value is set at @command{$ ./configure} time internally, see
@ref{Threads in GNU Astronomy Utilities}. Of course, you can still
provide a default value for the number of threads at any of the levels
below, but if you don't, the program will not abort. Also note that
through automatic output name genertion, the value to the
@option{--output} option is also not mandatory on the command line or
in the configuration files for all programs which don't rely on that
value as an input@footnote{One example of a program which uses the
value given to @option{--output} as an input is ConvertType, this
value specifies the type of the output through the value to
@option{--output}, see @ref{Invoking astconvertt}.}, see
@ref{Automatic output}.



@menu
* Configuration file format::   ASCII format of configuration file.
* Configuration file precedence::  Precedence of configuration files.
* Current directory and User wide::  Local and user configuration files.
* System wide::                 System wide configuration files.
@end menu

@node Configuration file format, Configuration file precedence, Configuration files, Configuration files
@subsection Configuration file format

@cindex Configuration file suffix
The configuration files for each program have the standard program
executable name with a @file{.conf} suffix. When you download the
source code, you can find them in the same directory as the source
code of each program, see @ref{Program source}.

@cindex White space character
@cindex Configuration file format
Any line in the configuration file whose first non-white character is
a @key{#} is considered to be a comment and is ignored. The same goes
for an empty line. The name of the parameter is the same as the long
format of the command line option for that parameter. The parameter
name and parameter value have to be separated by any number of
`white-space' characters: space, tab or vertical tab. By default
several space characters are used. If the value of an option has space
characters (most commonly for the @option{hdu} option), then double
quotes can be used to specify the full value.

Any text after the first two words (separated by the above delimiters)
in a line is ignored. If it is an option without a value in the
@option{--help} output (on/off option), then the value should be
@option{1} if it is to be `on' and @option{0} otherwise. If an
option is not recognized in the configuration file, the name of the
file and unrecognized option will be reported and the program will
abort.  If a parameter is repeated more more than once in the
configuration files and it is not set on the command line, then only
the first value will be used, the rest will be ignored.

@cindex Writing configuration files
@cindex Automatic configuration file writing
@cindex Configuration files, writing
You can build or edit any of the directories and the configuration
files your self using any text editor.  However, it is recommended to
use the @option{--setdirconf} and @option{--setusrconf} options to set
default values for the current directory or this user, see
@ref{Operating modes}. With these options, the values you give will be
checked as explained in @ref{Options} before writing in the
current directory's configuration file. They will also print a set of
commented lines guiding the reader and will also classify the options
based on their context and write them in their logical order to be
more understandable.


@node Configuration file precedence, Current directory and User wide, Configuration file format, Configuration files
@subsection Configuration file precedence

@cindex Configuration file precedence
@cindex Configuration file directories
@cindex Precedence, configuration files
The parameter values in all the programs of Gnuastro will be filled
in the following order. Such that if a parameter is assigned a value
in an earlier step, any value for that parameter in a later step will
be ignored.

@enumerate
@item
Command line options, for this particular execution.

@item
Current directory, for all executions in this directory
(@file{./.gnuastro/}).

@item
The user's home directory, for all the executions of a particular
user:@*(@file{$HOME/.local/etc/}, see below).

@item
In a system wide directory for any user on that computer
(@file{prefix/etc/}, see @ref{Installation directory} for
the value of @file{prefix}).
@end enumerate
@noindent

The basic idea behind setting this progressive state of checking for
parameter values is that separate users of a computer or separate
folders in a user's file system might need different values for some
parameters and the same values for others. For example raw telescope
images usually have their main image extension in the second FITS
extension, while processed FITS images usually only have one
extension. If your system wide default input extension is 0 (the
first), then when you want to work with the former group of data you
have to explicitly mention it to the programs every time. With this
progressive state of default values to check, you can set different
default values for the different directories that you would like to
run Gnuastro in for your different purposes, so you won't have to
worry about this issue any more.


@node Current directory and User wide, System wide, Configuration file precedence, Configuration files
@subsection Current directory and User wide

@cindex @file{HOME}
@cindex @file{./.gnuastro/}
@cindex @file{HOME/.local/etc/}
For these two directories, the configuration files are stored in a
hidden sub-directory named @file{./.gnuastro/} and
@file{HOME/.local/etc/} respectively. Unless you have changed it, the
@file{HOME} environment variable should point to your home
directory. You can check it by running @command{$ echo $HOME}. Each
time you run any of the programs in Gnuastro, this environment
variable is read and placed in the above address. So if you suddenly
see that your home configuration files are not being read, probably
you (or some other program) has changed the value of this environment
variable.

@vindex --setdirconf
@vindex --setusrconf
Although it might cause confusions like above, this dependence on the
@file{HOME} environment variable enables you to temporarily use a
different directory as your home directory. This can come in handy in
complicated situations. To set the user or current directory
configuration files based on your command line input, you can use the
@option{--setdirconf} or @option{--setusrconf}, see @ref{Operating
modes}



@node System wide,  , Current directory and User wide, Configuration files
@subsection System wide

@cindex @file{prefix/etc/}
@cindex System wide configuration files
@cindex Configuration files, system wide
When Gnuastro is installed, the configuration files that are shipped
with the distribution are copied into the (possibly system wide)
@file{prefix/etc/} directory. See @ref{Configuring} for more details
on @file{prefix} (by default it is: @file{/usr/local}). This directory
is the final place (with the lowest priority) that the programs in
Gnuastro will check to retrieve parameter values.

If you remove a parameter and its value from the files in this system
wide directory, you either have to specify it in more immediate
configuration files or set it each time in the command line. Recall
that none of the programs in Gnuastro keep any internal default
values and will abort if they don't find a value for the necessary
parameters (except the number of threads). So even though you might
never use a parameter, it still has to be at least available in this
system-wide configuration file.

In case you install Gnuastro from your distribution's repositories,
@file{prefix} will either be set to @file{/} (the root directory) or
@file{/usr}, so you can find the system wide configuration variables
in @file{/etc/} or @file{/usr/etc/}. The prefix of @file{/usr/local/}
is conventionally used for programs you install from source by your
self.





@node Threads in GNU Astronomy Utilities, Final parameter values, Configuration files, Common behavior
@section Threads in GNU Astronomy Utilities

@cindex pthread
@cindex CPU threads
@cindex Using CPU threads
@cindex POSIX threads library
@cindex CPU, using all threads
@cindex Multi-threaded programs
@cindex Using multiple CPU cores
Some of the programs benefit significantly when you use all the cores
your computer's CPU has to offer. In general, when you run an
application, the whole process is done only on one core. GNU Astronomy
Utilities uses the POSIX threads library (pthreads) for spinning off
threads when the user asks for it, see @ref{Multithreaded programming}
if you want more details.

@pindex nproc
@vindex --numthreads
@cindex GNU Coreutils
@cindex Number of threads available
@cindex Available number of threads
You can find the number of cores available to your system with the
command @command{$ nproc}, which is part of GNU Coreutils and is most
probably already available on your GNU/Linux system. If not specified
as an option at configure time, Gnuastro finds the number of cores
available to your system (and reports it along with all those other
things it checks!). It is saved internally for all the programs to use
by default. To specify the number of threads at configure time, use
the @option{--with-numthreads} option, see @ref{GNU Astronomy
Utilities configure options}. In case your system does not have GNU
Coreutils, currently the only way to proceed is to manually specify
the number of threads through this option.

@cindex Internally stored option value
The number of threads is the only parameter in Gnuastro which is
stored internally at configure time. The implication is that the only
option with a value that doesn't have to be in any of the
configuration files is this, see @ref{Configuration files}. Note that
if you do specify it, the value you provided in the most immediate
configuration file will be used, not the internal value.

@menu
* A note on threads::           Caution and suggestion on using threads.
@end menu

@node A note on threads,  , Threads in GNU Astronomy Utilities, Threads in GNU Astronomy Utilities
@subsection A note on threads

@cindex Using multiple threads
@cindex Best use of CPU threads
@cindex Efficient use of CPU threads
Spinning off threads internally is not necessarily always the most
efficient way to run an application. It is most useful when the input
data are fixed and you want the same operation to be done on parts of
it. For example one input image to ImageCrop and multiple crops from
various parts of it. In this fashion, the image is loaded into memory
once, all the crops are divided between the number of threads
internally and each thread cuts out those parts which are assigned to
it from the same image. On the other hand, if you have multiple images
and you want to crop the same region out of all of them, it is much
more efficient to set @option{--numthreads=1} (so no threads spin off)
and run ImageCrop multiple times simultaneously.

@cindex GNU Parallel
The best method to run multiple instances of a command on different
threads is to use GNU parallel. Surprisingly GNU Parallel is one of
the few GNU packages that has no Info documentation but only a Man
page, see @ref{Info}. So to see the documentation after installing it
please run

@example
$ man parallel
@end example

As an example, let's assume we want to crop a region fixed on the
pixels (500, 600) with the default width from all the FITS images in
the @file{./data} directory ending with @file{sci.fits} to the current
directory. To do this, you can run:

@example
$ parallel astimgcrop --numthreads=1 --xc=500 --yc=600 ::: \
  ./data/*sci.fits
@end example

@noindent
GNU Parallel can help in many more conditions, this is one of the
simplest, see the man page for lots of other examples. For absolute
beginners: the backslash (@command{\}) is only a line breaker to fit
nicely in the page. If you type the whole command in one line, you
should remove it.





@node Final parameter values, Automatic output, Threads in GNU Astronomy Utilities, Common behavior
@section Final parameter values, reproduce previous results

@vindex -P
@vindex --printparams
@cindex Final parameter value checking
@cindex Checking final parameter values
The input parameters can be specified in many places, either on the
command line or in at least one of several configuration files, see
@ref{Configuration files}. Therefore, it often happens that before
running a program on a certain data set, you want to see the values
for the parameters that the program will use after it has read your
command line options and all the configuration files in their correct
order. You might also want to save the list with the output so you can
reproduce the same results at a later time, this is very important
when you want to use your results in a report or paper.

If you call the @option{--printparams} option, all Gnuastro programs
will read your command line parameters and all the configuration
files. If there is no problem (like a missing parameter or a value in
the wrong format) and immediately before actually running, the
programs will print the full list of parameter names and values sorted
and grouped by context and quit. They will also report their version
number, the date they were configured on your system and the time they
were reported.

As an example, you can give your full command line options and even
the input and output file names and finally just add @option{-P} to
check if all the parameters are finely set. If everything is ok, you
can just run the same command (easily retrieved from the bash history,
with the top arrow key) and simply remove the last two characters that
showed this option.

Since no program will actually start its processing when this option
is called, the otherwise mandatory arguments for each program (for
example input image or catalog files) are no longer required when you
call this option.

@cindex Bash history
@cindex Shell redirection
@cindex Redirection of output
In case you want to store the list of parameters for later
reproduction of the same results, you can do so with the GNU Bash
re-direction tool. For example after you have produced the results you
want to store, you can save all the parameters that were used in a
file named @file{parameters.txt} in the following manner. Using shell
history you can retrieve the last command you entered and simply add
@command{-P > parameters.txt} to it, for example:

@example
$ astimgcrop --racol=2 --deccol=3 IN.fits cat.txt -P > parameters.txt
@end example

@cindex Reproducible results
@noindent
All the parameters along with the extra data explained before will be
stored in the plain text @file{parameters.txt} file through the
shell's redirection mechanism (@command{>}). The output of
@option{--printparams} conforms with the configuration file
formats@footnote{They are both written by the same function.}. By
taking the following steps, you can use this file as a configuration
file to reproduce your results at a later time.

@enumerate
@item
Set the file name based on the standard configuration file names, see
@ref{Configuration file format}.

@item
Later on (when ever you want to re-produce your results), copy the
file in the @file{./.gnuastro/} directory of your current
directory.
@end enumerate

@noindent
In this manner, this file will be read as a current directory
configuration file and since all the parameters are defined in it, no
other configuration file value will be used.






@node Automatic output, Getting help, Final parameter values, Common behavior
@section Automatic output

@cindex Automatic output file names
@cindex Output file names, automatic
@cindex Setting output file names automatically
All the programs in Gnuastro are designed such that specifying an
output file or directory (based on the program context) is optional.
The outputs of most programs are automatically found based on the
input and what the program does. For example when you are converting a
FITS image named @file{FITSimage.fits} to a JPEG image, the JPEG image
will be saved in @file{FITSimage.jpg}.

@vindex --keepinputdir
Another very important part of the automatic output generation is that
all the directory information of the input file name is stripped off
of it. This feature can be disabled with the @option{--keepinputdir}
option, see @ref{Common options}. It is the default because
astronomical data are usually very large and organized specially with
special file names. In some cases, the user might not have write
permissions in those directories. In fact, even if the data is stored
on your own computer, it is advised to only grant write permissions to
the super user or root. This way, you won't accidentally delete or
modify your valuable data!

Let's assume that we are working on a report and want to process the
FITS images from two projects (ABC and DEF), which are stored in the
sub-directories named @file{ABCproject/} and @file{DEFproject/} of our
top data directory (@file{/mnt/data}). The following shell commands
show how one image from the former is first converted to a JPEG image
through ConvertType and then the objects from an image in the latter
project are detected using NoiseChisel (which by default has two text
catalog files and one multi-extension FITS detection map file). The
text after the @command{#} sign are comments (not typed!).

@example
$ pwd                                               # Current location
/home/usrname/research/report
$ ls                                         # List directory contents
ABC01.jpg
$ ls /mnt/data/ABCproject                                  # Archive 1
ABC01.fits ABC02.fits ABC03.fits
$ ls /mnt/data/DEFproject                                  # Archive 2
DEF01.fits DEF02.fits DEF03.fits
$ astconvertt /mnt/data/ABCproject/ABC02.fits --output=jpg    # Prog 1
$ ls
ABC01.jpg ABC02.jpg
$ astnoisechisel /mnt/data/DEFproject/DEF01.fits              # Prog 2
$ ls
ABC01.jpg ABC02.jpg DEF01_c.txt DEF01_map.fits DEF01_o.txt
@end example




@node Getting help, Output headers, Automatic output, Common behavior
@section Getting help

@cindex Help
@cindex Manual formats
@cindex Remembering options
@cindex Convenient manual formats
Probably the first time you read this manual, it is either in the PDF
or HTML formats. These two formats are very convenient for when you
are not actually working, but when you are only reading. Later on,
when you start to use the programs and you are deep in the middle of
your work, some of the details will inevitably be forgotten. Going to
find the PDF file (printed or digital) or the HTML webpage is a major
distraction.

@cindex Online help
@cindex Command line help
GNU software have a very unique set of tools for aiding your memory on
the command line, where you are working, depending how much of it you
need to remember. In the past, such command line help was known as
``online'' help, because they were literally provided to you `on'
the command `line'. However, nowadays the word ``online'' refers to
something on the internet, so that term will not be used. With this
type of help, you can resume your exciting research without taking
your hands off the keyboard.

@cindex Installed help methods
Another major advantage of such command line based help routines is
that they are installed with the software in your computer, therefore
they are always in sync with the executable you are actually
running. Three of them are actually part of the executable. You don't
have to worry about the version of the manual or program. If you rely
on external help (a PDF in your personal print or digital archive or
HTML from the official webpage) you have to check to see if their
versions fit with your installed program.

If you only need to remember the short or long names of the options,
@option{--usage} is advised. If it is what the options do, then
@option{--help} is a great tool. Man pages are also provided for those
who are use to this older system of documentation. This full manual is
also available to you on the command line in Info format. If none of
these seems to resolve the problems, there is a mailing list which
enables you to get in touch with experienced Gnuastro users. In the
subsections below each of these methods are reviewed.


@menu
* --usage::                     View option names and value formats.
* --help::                      List all options with description.
* Man pages::                   Man pages generated from --help.
* Info::                        View complete manual in terminal.
* help-gnuastro mailing list::  Contacting experienced users.
@end menu

@node --usage, --help, Getting help, Getting help
@subsection @option{--usage}
@vindex --usage
@cindex Usage pattern
@cindex Mandatory arguments
@cindex Optional and mandatory tokens
If you give this option, the program will not run. It will only print
a very concise message showing the options and arguments. Everything
within square brackets (@option{[]}) is optional. For example here are
the first and last two lines of ImageCrop's @option{--usage} is shown:

@example
$ astimgcrop --usage
Usage: astimgcrop [-Do?IPqSVW] [-d INT] [-h INT] [-r INT] [-w INT]
            [-x INT] [-y INT] [-c INT] [-p STR] [-N INT] [--deccol=INT]
            ....
            [--setusrconf] [--usage] [--version] [--wcsmode]
            [ASCIIcatalog] FITSimage(s).fits
@end example

There are no explanations on the options, just their short and long
names shown separately. After the program name, the short format of
all the options that don't require a value (on/off options) is
displayed. Those that do require a value then follow in separate
brackets, each displaying the format of the input they want, see
@ref{Options}. Since all options are optional, they are shown in
square brackets, but arguments can also be optional. For example in
this example, a catalog name is optional and is only required in some
modes. This is a standard method of displaying optional arguments for
all GNU software.

@node --help, Man pages, --usage, Getting help
@subsection @option{--help}

@vindex --help
If the command line includes this option, the program will not be
run. It will print a complete list of all available options along with
a short explanation. The options are also grouped by their
context. Within each context, the options are sorted
alphabetically. Since the options are shown in detail afterwards, the
first line of the @option{--help} output shows the arguments and if
they are optional or not, similar to @ref{--usage}.

In the @option{--help} output of all programs in Gnuastro, the
options for each program are classified based on context. The first
two contexts are always options to do with the input and output
respectively. For example input image extensions or supplementary
input files for the inputs. The last class of options is also fixed in
all of Gnuastro, it shows operating mode options. Most of these
options are already explained in @ref{Operating modes}.

@cindex Long outputs
@cindex Redirection of output
@cindex Command line, long outputs
The help message will sometimes be longer than the vertical size of
your terminal. If you are using a graphical user interface terminal
emulator, you can scroll the terminal with your mouse, but we promised
no mice distractions! So here are some suggestions:

@itemize
@item
@cindex Scroll command line
@cindex Command line scroll
@cindex @key{Shift + PageUP} and @key{Shift + PageDown}
@key{Shift + PageUP} to scroll up and @key{Shift + PageDown} to scroll
down. For most help output this should be enough. The problem is that
it is limited by the number of lines that your terminal keeps in
memory and that you can't scroll by lines, only by whole screens.

@item
@cindex Pipe
@cindex @command{less}
Pipe to @command{less}. A pipe is a form of shell re-direction. The
@command{less} tool in Unix-like systems was made exactly for such
outputs of any length. You can pipe (@command{|}) the output of any
program that is longer than the screen to it and then you can scroll
through (up and down) with its many tools. For example:
@example
$ astnoisechisel --help | less
@end example
@noindent
Once you have gone through the text, you can quit @command{less} by
pressing the @key{q} key.


@item
@cindex Save output to file
@cindex Redirection of output
Redirect to a file. This is a less convenient way, because you will
then have to open the file in a text editor! You can do this with the
shell redirection tool (@command{>}):
@example
$ astnoisechisel --help > filename.txt
@end example
@end itemize

@cindex GNU Grep
@cindex Searching text
@cindex Command line searching text
In case you have a special keyword you are looking for in the help,
you don't have to go through the full list. GNU Grep is made for this
job. For example if you only want the list of options whose
@option{--help} output contains the word ``axis'' in ImageCrop, you
can run the following command:

@example
$ astimgcrop --help | grep axis
@end example

@cindex @code{ARGP_HELP_FMT}
@cindex Argp argument parser
@cindex Customize @option{--help} output
@cindex @option{--help} output customization
If the output of this option does not fit nicely within the confines
of your terminal, GNU does enable you to customize its output through
the environment variable @code{ARGP_HELP_FMT}, you can set various
parameters which specify the formatting of the help messages. For
example if your terminals are wider than 70 spaces (say 100) and you
feel there is too much empty space between the long options and the
short explanation, you can change these formats by giving values to
this environment variable before running the program with the
@option{--help} output. You can define this environment variable in
this manner:
@example
$ export ARGP_HELP_FMT=rmargin=100,opt-doc-col=20
@end example
@cindex @file{.bashrc}
This will affect all GNU programs using GNU C Library's @file{argp.h}
facilities as long as the environment variable is in memory. You can
see the full list of these formatting parameters in the ``Argp User
Customization'' part of the GNU C Library manual. If you are more
comfortable to read the @option{--help} outputs of all GNU software in
your customized format, you can add your customizations (similar to
the line above, without the @command{$} sign) to your @file{~/.bashrc}
file. This is a standard option for all GNU software.

@node Man pages, Info, --help, Getting help
@subsection Man pages
@cindex Man pages
Man pages were the Unix method of providing command line documentation
to a program. With GNU Info, see @ref{Info} the usage of this method
of documentation is highly discouraged. This is because Info provides
a much more easier to navigate and read environment.

However, some operating systems require a man page for packages that
are installed and some people are still used to this method of command
line help. So the programs in Gnuastro also have Man pages which are
automatically generated from the outputs of @option{--version} and
@option{--help} using the GNU help2man program. So if you run
@example
$ man programname
@end example
@noindent
You will be provided with a man page listing the options in the
standard manner.





@node Info, help-gnuastro mailing list, Man pages, Getting help
@subsection Info

@cindex GNU Info
@cindex Command line, viewing full manual
Info is the standard documentation format for all GNU software. It is
a very useful command line document viewing format, fully equipped
with links between the various pages and menus and search
capabilities. As explained before, the best thing about it is that it
is available for you the moment you need to refresh your memory on any
command line tool in the middle of your work without having to take
your hands off the keyboard. This complete manual is available in Info
format and can be accessed from anywhere on the command line.

To open the Info format of any installed programs or library on your
system which has an Info format manual, you can simply run the command
below (change @command{executablename} to the executable name of the
program or library):

@example
$ info executablename
@end example

@noindent
@cindex Learning GNU Info
@cindex GNU software documentation
In case you are not already familiar with it, run @command{$ info
info}. It does a fantastic job in explaining all its capabilities its
self. It is very short and you will become sufficiently fluent in
about half an hour. Since all GNU software documentation is also
provided in Info, your whole GNU/Linux life will significantly
improve.

@cindex GNU Emacs
@cindex GNU C Library
Once you've become an efficient navigator in Info, you can go to any
part of this manual or any other GNU software or library manual, no
matter how long it is, in a matter of seconds. It also blends nicely
with GNU Emacs (a text editor) and you can search manuals while you
are writing your document or programs without taking your hands off
the keyboard, this is most useful for libraries like the GNU C
library. To be able to access all the Info manuals installed in your
GNU/Linux within Emacs, type @key{Ctrl-H + i}.

To see this whole manual from the beginning in Info, you can run

@example
$ info gnuastro
@end example

@noindent
If you run Info with the particular program executable name, for
example @file{astimgcrop} or @file{astnoisechisel}:

@example
$ info astprogramname
@end example

@noindent
you will be taken to the section titled ``Invoking ProgramName'' which
explains the inputs and outputs along with the command line options
for that program. Finally, if you run Info with the official program
name, for example ImageCrop or NoiseChisel:

@example
$ info ProgramName
@end example

@noindent
you will be taken to the top section which introduces the
program. Note that in all cases, Info is not case sensitive.



@node help-gnuastro mailing list,  , Info, Getting help
@subsection help-gnuastro mailing list

@cindex help-gnuastro mailing list
@cindex Mailing list: help-gnuastro
Gnuastro maintains the help-gnuastro mailing list for users to ask any
questions related to Gnuastro. The experienced Gnuastro users and some
of its developers are subscribed to this mailing list and your email
will be sent to them immediately. However, when contacting this
mailing list please have in mind that they are possibly very busy and
might not be able to answer immediately.

@cindex Mailing list archives
@cindex @code{help-gnuastro@@gnu.org}
To ask a question from this mailing list, send a mail to
@code{help-gnuastro@@gnu.org}. Anyone can view the mailing list
archives at @url{http://lists.gnu.org/archive/html/help-gnuastro/}. It
is best that before sending a mail, you search the archives to see if
anyone has asked a question similar to yours. If you want to make a
suggestion or report a bug, please don't send a mail to this mailing
list. We have other mailing lists and tools for those purposes, see
@ref{Report a bug} or @ref{Suggest new feature}.





@node Output headers,  , Getting help, Common behavior
@section Output headers

@cindex Output FITS headers
@cindex CFITSIO version on outputs
The output FITS files created by Gnuastro will have the following two
keywords: @command{DATE} and @command{CFITSIO}. The first specifies
the time in UT of the file being created and the second specifies the
version of CFITSIO that was used to make the file. We are not aware if
WCSLIB has this capability (to give its version number), therefore it
is not included. Some basic information about Gnuastro is also
printed. The example below shows the last few keywords of one of the
outputs of ImageCrop.

@example
        / ImageCrop (GNU Astronomy Utilities 0.1) 0.1:
DATE    = ' ... '       / file creation date (YYYY-MM-DDThh:mm:ss UT)
CFITSIO = '3.37    '    / Version of CFITSIO used.
COMMENT GNU Astronomy Utilities 0.1
COMMENT http://www.gnu.org/software/gnuastro/
END
@end example












@node Files, Image manipulation, Common behavior, Top
@chapter Files

@cindex File operations
@cindex Operations on files
@cindex General file operations
This chapter documents the programs in Gnuastro that are provided for
getting information on the contents of a data file or converting a
file format. Before working on a FITS file, it is commonly the case
that you are not sure how many extensions it has within it and also
what each extension is (image, table or blank). In other cases you
want to use the data in a FITS file in other programs (for example in
reports) that don't recognize the FITS format.

@menu
* Header::                      Print and manipulate data file header.
* ConvertType::                 Convert data to various formats.
@end menu





@node Header, ConvertType, Files, Files
@section Header

The FITS standard requires each extension of a FITS file to have a
header, giving basic information about what is in that extension. Each
line in the header is for one keyword, specifying its name, value and
a short comment string. Besides the basic information, the headers
also contain vital information about the data, how they were
processed, the instrument specifications that took the image and also
the World Coordinate System that is used to translate pixel
coordinates to sky or spectrum coordinates on the image or table.

@menu
* Invoking astheader::          Arguments and options to Header.
@end menu

@node Invoking astheader,  , Header, Header
@subsection Invoking Header

Header can print or manipulate the header information in an extension
of an astronomical data file. The executable name is @file{astheader}
with the following general template

@example
$ astheader [OPTION...] ASTRdata
@end example


@noindent
One line examples:

@example
$ astheader image.fits
$ astheader --update=OLDKEY,153.034,"Old keyword comment"
$ astheader --remove=COMMENT --comment="Anything you like ;-)."
$ astheader --add=MYKEY1,20.00,"An example keyword" --add=MYKEY2,fd
@end example

@cindex HDU
If no keyword modification options are given, the full header of the
given HDU will be printed on the command line. If any of the keywords
are to be modified, the headers of the input file will be changed. If
you want to keep the original FITS file, it is easiest to create a
copy first and then run Header on that. In the FITS standard, keywords
are always uppercase. So case does not matter in the input or output
keyword names you specify.

Most of the options can accept multiple instances in one command. For
example you can add multiple keywords to delete by calling delete
multiple times, since repeated keywords are allowed, you can even
delete the same keyword multiple times. The action of such options
will start from the top most keyword.

@cartouche
@noindent
@strong{FITS STANDARD KEYWORDS:} Some header keywords are necessary
for later operations on a FITS file, for example BITPIX or NAXIS, see
the FITS standard for their full list. If you modify (for example
remove or rename) such keywords, the FITS file extension might not be
usable any more. Also be careful for the world coordinate system
keywords, if you modify or change their values, any future world
coordinate system (like RA and Dec) measurements on the image will
also change.
@end cartouche

@cartouche
@noindent
@strong{PRECEDENCE:} The order of operations are as follows. Note that
while the order within each class of actions is preserved, the order
of individual actions is not. So irrespective of what order you called
@option{--delete} and @option{--update}. First all the delete
operations are going to take effect then the update operations.
@enumerate
@item
@option{--delete}
@item
@option{--rename}
@item
@option{--update}
@item
@option{--write}
@item
@option{--history}
@item
@option{--comment}
@item
@option{--date}
@end enumerate
@noindent
All possible syntax errors will be reported before the keywords are
actually written. FITS errors during any of these actions will be
reported, but Header won't stop until all the operations are
complete. If @option{quitonerror} is called, then Header will
immediately stop upon the first error.
@end cartouche

@cindex GNU Grep
If only a certain set of header keywords are desired, it is easiest to
pipe the output of Header to GNU Grep. Grep is a very powerfull and
advanced tool to search strings which is precisely made for such
situations. For example if you only want to check the size of an image
FITS HDU, you can run:

@example
$ astheader input.fits | grep NAXIS
@end example

@noindent
The options particular to Header can be seen below. See @ref{Common
options} for a list of the options that are common to all Gnuastro
programs, they are not repeated here.
@table @option

@item -d
@itemx --delete
(@option{=STR}) Delete one instance of the desired keyword. Multiple
instances of @option{--delete} can be given (possibly even for the
same keyword). All keywords given will be removed from the headers in
the opposite order (last given keyword will be deleted first). If the
keyword doesn't exist, Header will give a warning and return with a
non-zero value, but will not stop.

@item -r
@itemx --rename
(@option{=STR}) Rename a keyword to a new value. The old name and the
new name should be separated by either a comma (@key{,}) or a space
character. Note that if you use a space character, you have to put the
value to this option within double quotation marks (@key{"}) so the
space character is not interpreted as an option separator. Multiple
instances of @option{--rename} can be given in one command. The
keywords will be renamed in the specified order.

@item -u
@itemx --update
(@option{=STR}) Update a keyword, its value, its comments and its
units all defined separately. If there are multiple instances of the
keyword in the header, they will be changed from top to bottom (with
multiple @option{--update} options).

@noindent
The format of the values to this option can best be specified with an
exmaple:

@example
--update=KEYWORD,value,"comments for this keyword",unit
@end example

@noindent
The value can be any numerical or string value. Other than the
@code{KEYWORD}, all the other values are optional. To leave a given
token empty, follow the preceding comma (@key{,}) immediately with the
next. If any space character is present around the commas, it will be
considered part of the respective token. So if more than one token has
space characters within it, the safest method to specify a value to
this option is to put double quotation marks around each individual
token that needs it. Note that without double quotation marks, space
characters will be seen as option separators and can lead to undefined
behavior.

@item -w
@itemx --write
(@option{=STR}) Write a keyword to the header. For the format of
inputing the possible values, comments and units for the keyword, see
the @option{--update} option above.

@item -H
@itemx --history
(@option{=STR}) Add a @code{HISTORY} keyword to the header. The string
given to this keyword will be separated into multiple keyword cards if
it is longer than 70 characters. With each run only one value for the
@option{--history} option will be read. If there are multiple, it is
the last one.

@item -c
@itemx --comment
(@option{=STR}) Add a @code{COMMENT} keyword to the header. Similar to
the explanation for @option{--history} above.

@item -t
@itemx --date
Put the current date and time in the header. If the @code{DATE}
keyword already exists in the header, it will be updated.

@item -Q
@itemx --quitonerror
Quit if any of the operations above are not successful. By default if
an error occurs, Header will warn the user of the faulty keyword and
continue with the rest of actions.

@end table














@node ConvertType,  , Header, Files
@section ConvertType

@cindex Data format conversion
@cindex Converting data formats
@cindex Image format conversion
@cindex Converting image formats
@pindex @r{ConvertType @value{CONVERTT_VERSION} (}astconvertt@r{)}
The formats of astronomical data were defined mainly for archiving and
processing. In other situations, the data might be useful in other
formats. For example, when you are writing a paper or report or if you
are making slides for a talk, you can't use a FITS image. Other image
formats should be used. In other cases you might want your pixel
values in a table format as plain text for input to other programs
that don't recognize FITS, or to include as a table in your
report. ConvertType is created for such situations. The various types
will increase with future updates and based on need.

The conversion is not only one way (from FITS to other formats), but
two ways (except the EPS and PDF formats). So you can convert a JPEG
image or text file into a FITS image. Basically, other than EPS, you
can use any of the recognized formats as different color channel
inputs to get any of the recognized outputs. So before explaining the
options and arguments, first a short description of the recognized
files types will be given followed a short introduction to digital
color.

@menu
* Recognized file types::       Recognized file types
* Color::                       Some explanations on color.
* Invoking astconvertt::        Options and arguments to ConvertType.
@end menu

@node Recognized file types, Color, ConvertType, ConvertType
@subsection Recognized file types

The various standards and the file name extensions recognized by
ConvertType are listed below.

@table @asis
@item FITS or IMH
@cindex Astronomical data format
Astronomical data are commonly stored in the FITS format (and in older
data sets in IRAF @file{.imh} format), a list of file name suffixes
which indicate that the file is in this format is given in
@ref{Arguments}.

Each extension of a FITS image only has one value per pixel, so when
used as input, each input FITS image contributes as one color
channel. If you want multiple extensions in one FITS file for
different color channels, you have to repeat the file name multiple
times and use the @option{--hdu}, @option{--hdu2}, @option{--hdu3} or
@option{--hdu4} options to specify the different extensions.

@item JPEG
@cindex JPEG format
@cindex Raster graphics
@cindex Pixelated graphics
The JPEG standard was created by the Joint photographic experts
group. It is currently one of the most commonly used image
formats. Its major advantage is the compression algorithm that is
defined by the standard. Like the FITS standard, this is a raster
graphics format, which means that it is pixelated.

A JPEG file can have 1 (for grayscale), 3 (for RGB) and 4 (for CMYK)
color channels. If you only want to convert one JPEG image into other
formats, there is no problem, however, if you want to use it in
combination with other input files, make sure that the final number of
color channels does not exceed four. If it does, then ConvertType will
abort and notify you.

@cindex Suffixes, JPEG images
The file name endings that are recognized as a JPEG file for input
are: @file{.jpg}, @file{.JPG}, @file{.jpeg}, @file{.JPEG},
@file{.jpe}, @file{.jif}, @file{.jfif} and @file{.jfi}.

@item EPS
@cindex EPS
@cindex PostScript
@cindex Vector graphics
@cindex Encapsulated PostScript
The Encapsulated PostScript (EPS) format is essentially a one page
PostScript file which has a specified size. PostScript also includes
non-image data, for example lines and texts. It is a fully functional
programming language to describe a document. Therefore in ConvertType,
EPS is only an output format and cannot be used as input. Contrary to
the FITS or JPEG formats, PostScript is not a raster format, but is
categorized as vector graphics.

@cindex PDF
@cindex Adobe systems
@cindex PostScript vs. PDF
@cindex Compiled PostScript
@cindex Portable Document format
@cindex Static document description format
The Portable Document Format (PDF) is currently the most common format
for documents. Some believe that PDF has replaced PostScript and that
PostScript is now obsolete. This view is wrong, a PostScript file is
an actual plain text file that can be edited like any program source
with any text editor. To be able to display its programmed content or
print, it needs to pass through a processor or compiler. A PDF file
can be thought of as the processed output of the compiler on an input
PostScript file. PostScript, EPS and PDF were created and are
registered by Adobe Systems.

@cindex @TeX{}
@cindex @LaTeX{}
With these features in mind, you can see that when you are compiling a
document with @TeX{} or @LaTeX{}, using an EPS file is much more low
level than a JPEG and thus you have much greater control and therefore
quality. Since it also includes vector graphic lines we also use such
lines to make a thin border around the image to make its appearance in
the document much better. No matter the resolution of the display or
printer, these lines will always be clear and not pixelated. In the
future addition of text might be included (for example labels or
object IDs) on the EPS output. However, this can be done better with
tools within @TeX{} or @LaTeX{} such as
PGF/Tikz@footnote{@url{http://sourceforge.net/projects/pgf/}}.

@cindex Binary image
@cindex Saving binary image
@cindex Black and white image
If the final input image (possibly after all operations on the flux
explained below) is a binary image or only has two colors of black and
white (in segmentation maps for example), then PostScript has another
great advantage compared to other formats. It allows for 1 bit pixels
(pixels with a value of 0 or 1), this can decrease the output file
size by 8 times. So if a grayscale image is binary, ConvertType will
exploit this property in the EPS and PDF (see below) outputs.

@cindex Suffixes, EPS format
The standard formats for an EPS file are @file{.eps}, @file{.EPS},
@file{.epsf} and @file{.epsi}. The EPS outputs of ConvertType have the
@file{.eps} suffix.

@item PDF
@cindex Suffixes, PDF format
@cindex GPL Ghostscript
As explained above, a PDF document is a static document description
format, viewing its result is therefore much faster and more efficient
than PostScript. To create a PDF output, ConvertType will make a
PostScript page description and convert that to PDF using GPL
Ghostscript. The suffixes recognized for a PDF file are: @file{.pdf},
@file{.PDF}. If GPL Ghostscript cannot be run on the PostScript file,
it will remain and a warning will be printed.

@item @option{blank}
@cindex @file{blank} color channel
This is not actually a file type! But can be used to fill one color
channel with a blank value. If this argument is given for any color
channel, that channel will not be used in the output.

@item Plain text
@cindex Plain text
@cindex Suffixes, plain text
Plain text files have the advantage that they can be viewed with any
text editor or on the command line. Most programs also support input
as plain text files. In ConvertType, if the input arguments do not
have any of the extensions listed above for other formats, the input
is assumed to be a text file. Each plain text file is considered to
contain one color channel. There is no standard output for plain text
files.

@cindex Mis-spelling file suffix
@cindex File suffix mis-spelling
If any of the extension above is mis-spelled, this will result in the
output becoming a plain text file with that (short) name. If this
happens, ConvertType will warn you and write the output as a plain
text file. If you don't want that warning, set your plain text output
file names longer than 5 characters. When converting an image to plain
text, consider the fact that if the image is large the number of
columns in each line will become very large, possibly making it very
hard to open in some text editors.

@end table

@node Color, Invoking astconvertt, Recognized file types, ConvertType
@subsection Color

@cindex RGB
@cindex CMYK
@cindex Image
@cindex Pixels
@cindex Grayscale
@cindex Colorspace
@cindex Primary colors
@cindex Colorspace, grayscale
An image is a two dimensional array of 2 dimensional elements called
pixels. If each pixel only has one value, the image is known as a
grayscale image and no color is defined. The range of values in the
image can be interpreted as shades of any color, it is customary to
use shades of black or grayscale. However, to produce the color
spectrum in the digital world, several primary colors must be
mixed. Therefore in a color image, each pixel has several values
depending on how many primary colors were choosen. For example on the
digital monitor or color digital cameras, all colors are built by
mixing the three colors of Red-Green-Blue (RGB) with various
proportions. However, for printing on paper, standard printers use the
Cyan-Magenta-Yellow-Key (CMYK, Key=black) color space. Therefore when
printing an RGB image, usually a transformation of color spaces will
be necessary.

In a colored digital camera, a color image is produced by dividing the
pixel's area between three colors (filters). However in astronomy due
to the intrinsic faintness of most of the targets, the collecting area
of the pixel is very important for us. Hence the full area of the
pixel is used and one value is stored for that pixel in the end. One
color filter is used for the whole image. Thus a FITS image is
inherently a grayscale image and no color can be defined for it.

@cindex Colorspace, transformation
One way to represent a grayscale image in different color spaces is to
use the same proportions of the primary colors in each pixel. This is
the common way most FITS image converters work: they fill all the
channels with the same values. The downside is two fold:

@itemize

@item
Three (for RGB) or four (for CMYK) values have to be stored for every
pixel, this makes the output file very heavy (in terms of bytes).

@item
If printing, the printing errors of each color channel can make the
printed image slightly more blurred than it actually is.

@end itemize

@cindex PNG standard
@cindex Single channel CMYK
To solve both these problems, the best way is to save the FITS image
into the black channel of the CMYK color space. In the RGB color space
all three channels have to be used. The JPEG standard is the only
common standard that accepts CMYK color space, that is why currently
only the JPEG standard is included and not the PNG standard for
example.

The JPEG and EPS standards set two sizes for the number of bits in
each channel: 8-bit and 12-bit. The former is by far the most common
and is what is used in ConvertType. Therefore, each channel should
have values between 0 to @math{2^8-1=255}. From this we see how each
pixel in a grayscale image is one byte (8 bits) long, in an RGB image,
it is 3bytes long and in CMYK it is 4bytes long. But thanks to the
JPEG compression algorithms, when all the pixels of one channel have
the same value, that channel is compressed to one pixel. Therefore a
Grayscale image and a CMYK image that has only the K-channel filled
are approximately the same file size.


@node Invoking astconvertt,  , Color, ConvertType
@subsection Invoking ConvertType

ConvertType will convert any recognized input file type to any
specified output type. The executable name is @file{astconvertt} with
the following general template

@example
$ astconvertt [OPTION...] InputFile [InputFile2] ... [InputFile4]
@end example

@noindent
One line examples:

@example
$ astconvertt M31.fits --output=pdf
$ astconvertt galaxy.jpg -ogalaxy.fits
$ astconvertt f1.txt f2.txt f3.fits -o.jpg
$ astconvertt M31_r.fits M31_g.fits blank -oeps
@end example

@noindent
The file type of the output will be specified with the (possibly
complete) file name given to the @option{--output} option, which can
either be given on the command line or in any of the configuration
files (see @ref{Configuration files}). Note that if the output suffix
is not recognized, it will default to plain text format, see
@ref{Recognized file types}.

The order of multiple input files is important. After reading the
input file(s) the number of color channels in all the inputs will be
used to define which color space is being used for the outputs and how
each color channel is interpreted. Note that one file might have more
than one color channel (for example in the JPEG format). If there is
one color channel the output is grayscale, if three input color
channels are given they are respectively considered to be the red,
green and blue color channels and if there are four color channels
they are respectively considered to be cyan, magenta, yellow and
black.

The value to @option{--output} (or @option{-o}) can be either a full
file name or just the suffix of the desired output format. In the
former case, that same name will be used for the output. In the latter
case, the name of the output file will be set based on the automatic
output guidelines, see @ref{Automatic output}. Note that the suffix
name can optionally start a @file{.} (dot), so for example
@option{--output=.jpg} and @option{--output=jpg} are equivalent. Be
careful that if you want your output in plain text, you have to give
the full file name. So if @option{-otxt} or @option{--output=.txt} are
given, the output file will be named @file{txt} or @file{.txt} (the
latter will be a hidden file!).

Besides the common set of options explained in @ref{Common options},
the options to ConvertType can be classified into input, output and
flux related options. The majority of the options are to do with the
flux range. Astronomical data usually have a very large dynamic range
(difference between maximum and minimum value) and different subjects
might be better demonstrated with a limited flux range.

@noindent
Input:
@table @option
@item --hdu2
If the second input file is a FITS file, the value to this option will
be used to specify which HDU will be used. Note that for the first
file, the (@option{--hdu} or @option{-h} in the common options is
used)

@item --hdu3
The HDU of the third input FITS file.

@item --hdu4
The HDU of the fourth input FITS file.
@end table

@noindent
Output:
@table @option

@item -w
@itemx --widthincm
(@option{=FLT}) The width of the output in centimeters. This is only
relevant for those formats that accept such a width (not plain text
for example). For most digital purposes, the number of pixels is far
more important than the value to this parameter because you can adjust
the absolute width (in inches or centimeters) in your document
preparation program.

@item -b
@itemx --borderwidth
@cindex Border on an image
(@option{=INT}) The width of the border to be put around the EPS and
PDF outputs in units of PostScript points. There are 72 or 28.35
PostScript points in an inch or centimeter respectively. In other
words, there are roughly 3 PostScript points in every millimeter. If
you are planning on adding a border, its significance is highly
correlated with the value you give to the @option{--widthincm}
parameter.

Unfortunately in the document structuring convention of the PostScript
language, the ``bounding box'' has to be in units of PostScript points
with no fractions allowed. So the border values only have to be
specified in integers. To have a final border that is thinner than one
PostScript point in your document, you can ask for a larger width in
ConvertType and then scale down the output EPS or PDF file in your
document preparation program. For example by setting @command{width}
in your @command{includegraphics} command in @TeX{} or @LaTeX{}. Since
it is vector graphics, the changes of size have no effect on the
quality of your output quality (pixels don't get different values).

@item -u
@itemx --quality
@cindex JPEG compression quality
@cindex Compression quality in JPEG
@cindex Quality of compression in JPEG
(@option{=INT}) The quality (compression) of the output JPEG file with
values from 0 to 100 (inclusive). For other formats the value to this
option is ignored. Note that only in grayscale (when one input color
channel is given) will this actually be the exact quality (each pixel
will correspond to one input value). If it is in color mode, some
degradation will occur. While the JPEG standard does support loss-less
graphics, it is not commonly supported.

@end table

@noindent
Flux range:

@table @option

@item -c
@itemx --change
@cindex Change converted pixel values
(@option{=STR}) Change pixel values with the following format
@option{"from1:to1, from2:to2,..."}. This option is very useful in
displaying labeled pixels (not actual data images which have noise)
like segmentation maps. In labeled images, usually a group of pixels
have a fixed integer value. With this option, you can manipulate the
labels before the image is displayed to get a better output for print
or to emphasize on a particular set of labels and ignore the rest. The
labels in the images will be changed in the same order given. By
default first the pixel values will be converted then the pixel values
will be truncated (see @option{--fluxlow} and @option{--fluxhigh}).

You can use any number for the values irrespective of your final
output, your given values are stored and used in the double precision
floating point format. So for example if your input image has labels
from 1 to 20000 and you only want to display those with labels 957 and
11342 then you can run ConvertType with these options:

@example
$ astconvertt --change=957:50000,11342:50001 --fluxlow=5e4 \
   --fluxhigh=1e5 segmentationmap.fits --output=jpg
@end example

@noindent
While the output JPEG format is only 8 bit, this operation is done in
an intermediate step which is stored in double precision floating
point. The pixel values are converted to 8-bit after all operations on
the input fluxes have been complete. By placing the value in double
quotes you can use as many spaces as you like for better readability.

@item -C
@itemx --changeaftertrunc
Change pixel values (with @option{--change}) after truncation of the
flux values, by default it is the opposite.

@item -L
@itemx --fluxlow
(@option{=FLT}) The minimum flux (pixel value) to display in the
output image, any pixel value below this value will be set to this
value in the output. If the value to this option is the same as
@option{--fluxmax}, then no flux truncation will be applied. Note that
when multiple channels are given, this value is used for all the color
channels.

@item -H
@itemx --fluxhigh
(@option{=FLT}) The maximum flux (pixel value) to display in the
output image, see @option{--fluxlow}.

@item -m
@itemx --maxbyte
(@option{=INT}) This is only used for the JPEG and EPS output formats
which have an 8-bit space for each channel of each pixel. The maximum
value in each pixel can therefore be @mymath{2^8-1=255}. With this
option you can change (decrease) the maximum value. By doing so you
will decrease the dynamic range. It can be useful if you plan to use
those values for other purposes.

@item -i
@itemx --flminbyte
(@option{=INT}) If the lowest pixel value in the input channels is
larger than the value to @option{--fluxlow}, then that input value
will be redundant. In some situations it might be necessary to set the
minimum byte value (0) to correspond to that flux even if the data do
not reach that value. With this option you can do this. Note that if
the minimum pixel value is smaller than @option{--fluxlow}, then this
option is redundant.

@item -a
@itemx --fhmaxbyte
(@option{=INT}) See @option{--flminbyte}.

@item -l
@itemx --log
Display the logarithm of the input data. This is done after the
conversion and flux truncation steps, see above.

@item -n
@itemx --noinvert
For 8-bit output types (JPEG and EPS for example) the final value that
is stored is inverted so white becomes black and vice versa. The
reason for this is that astronomical images usually have a very large
area of blank sky in them. The result will be that a large are of the
image will be black. Therefore, by default the 8-bit values are
inverted so the images blend in better with the text in a document.

Note that this behaviour is ideal for grayscale images, if you want a
color image, the colors are going to be mixed up. For color images it
is best to call this option so the image is not inverted.

@end table





















@node Image manipulation, Image analysis, Files, Top
@chapter Image manipulation

Images are one of the major formats of data that is used in
astronomy. The functions in this chapter explain the GNU Astronomy
Utilities which are provided for their manipulaton. For example
cropping out a part of a larger image or convolving the image with a
given kernel or applying a transformation to it.

@menu
* ImageCrop::                   Crop region(s) from FITS image(s).
* Convolve::                    Convolve an image with a kernel.
* ImageWarp::                   Warp/Transform an image to a different grid.
* SubtractSky::                 Find the sky and subtract it from image.
@end menu

@node ImageCrop, Convolve, Image manipulation, Image manipulation
@section ImageCrop

@cindex Section of an image
@cindex Crop part of image
@cindex Postage stamp images
@cindex Large astronomical images
@pindex @r{ImageCrop @value{IMGCROP_VERSION} (}astimgcrop@r{)}
Astronomical images are often very large, filled with thousands of
galaxies. It often happens that you only want a section of the image,
or you have a catalog of sources and you want to visually analyze them
in small postage stamps. ImageCrop is made to do all these
things. When more than one crop is required, ImageCrop will divide the
crops between multiple threads to significantly reduce the run time.

@cindex Mosaicing
@cindex Image tiles
@cindex Image mosaic
@cindex COSMOS survey
@cindex Imaging surveys
@cindex Hubble Space Telescope
One of the main problems in achieving this goal is that astronomical
surveys are usually extremely large. So large in fact, that the whole
survey will not fit into a reasonably sized file. Because of this
surveys usually cut the final image into separate tiles and store each
tile in a file. For example the COSMOS survey's Hubble space
telescope, ACS F814W image consists of 81 separate FITS images, with
each one having a volume of 1.7 Giga bytes.

@cindex Stitch multiple images
Even though the tile sizes are chosen to be large enough that too many
galaxies don't fall on the edges of the tiles, inevitably some do and
if you simply crop the image of the galaxy from that one tile, you
will miss a large area of the surrounding sky (which is essential in
estimating the noise). Therefore in its WCS mode, ImageCrop will
stitch parts of the tiles that are relevant for a target (with the
given width) from all the input images that cover that region into the
output. Of course, the tiles have to be present in the list of input
files.

@menu
* ImageCrop modes::             Basic ImageCrop modes.
* Crop section syntax::         How to define a section to crop.
* Blank pixels::                Pixels with no value.
* Invoking astimgcrop::         Calling ImageCrop on the command line
@end menu

@node ImageCrop modes, Crop section syntax, ImageCrop, ImageCrop
@subsection ImageCrop modes
In order to be as comprehensive as possible, ImageCrop has two major
modes of operation listed below.

@table @asis
@item Image
The image mode uses the pixel coordinates. Depending on your command
line options, this mode consists of three sub-modes. In image mode,
only one image may be input.
@itemize

@item
Catalog (multiple crops). Coordinates are read from a text file. The
@option{--xcol} and @option{--ycol} columns in the catalog are
interpreted as the center of a square crop box whose width is
specified with the @option{--iwidth} option in pixels. Since the given
pixel has to be on the center, the width has to be an odd number, so
if you give an even number for the width, it will be added by one. If
a catalog file name is provided (with @option{--imagemode} activated
of course) this mode will be used.

@item
Center (one crop). The box center is given on the command line with
the @option{--xc} and @option{--yc} parameters. The image width is
similar to above.

@item
Section (one crop). You can specify the section of pixels along each
axis in the image which you want to be cropped with the
@option{--section} option. See @ref{Crop section syntax} for a full
explanation on the syntax of specifying the desired region.
@end itemize

The latter two cases will only have one crop box. In both cases,
ImageCrop will go into the image mode, irrespective of calling
@option{--wcsmode} or the default mode. In the first two cases, since
you specify a central pixel, the crop box will be a square with an odd
number of pixels on the side, so your desired pixel sits right in the
center, see @ref{Blank pixels} on how to disable this for cases when
the box exceeds the image size.

@item WCS
The Right ascension (RA) and Declination (Dec) of the objects in a
catalog is used to define the central position of each postage
stamp. In this mode, the width (@option{--wwidth}) is read in units of
arc seconds and multiple images (tiles in a survey) can be input. If
the objects are closer to the edge of the image than half the required
width, other tiles (if they are present in the input files) are used
to fill the empty space. The square output cropped box will have an
odd number of pixels on the side.

In this mode, the input images do not necessarily have to be the same
size, each individual tile can even be smaller than the final crop. In
any case, any part of any of the input images which overlaps with the
desired region will be used in the crop. Note that if there is an over
lap, the pixels from the last input image read are going to be
used. The input images all just have to be aligned with the celestial
coordinates, see the caution note below.

Similar to the image mode, there are two sub-modes:

@itemize

@item
Catalog (multiple crops). Similar to catalog mode in image mode. The
RA and Dec column should be specified in the catalog (@option{--racol}
and @option{--deccol}).

@item
Center (one crop). You can specify the center of only one crop box (no
matter how many input images there are) with the options @option{--ra}
and @option{--dec}. If it exists in the input images, it will be
cropped similar to the catalog mode. If automatic output is triggered
(you don't specify a file name for @option{--output}) and several of
the input images are used to stitch and crop the region around the
central point, the name of the first input will be used in automatic
output, see @ref{Automatic output}.

@end itemize

@cartouche
@noindent
@strong{CAUTION:} In WCS mode, the image has to be aligned with the
celestial coordinates, such that the first FITS axis is parallel
(opposite direction) to the Right Ascension (RA) while the second FITS
axis is parallel to the declination. If these conditions aren't met
for an image, ImageCrop will warn you and abort. You have to use other
tools to transform the image to the correct directions.
@end cartouche

@end table

In short, if you don't specify a catalog, you have to specify box
coordinates manually on the command line. When you do specify a
catalog, ImageCrop has to be in one of the two major modes
(@option{--imgmode} or @option{--wcsmode}). Note that the single crop
box parameters specified in the sub-modes will not be written to or
read from the configuration file, they have to be specified on each
execution.


@node Crop section syntax, Blank pixels, ImageCrop modes, ImageCrop
@subsection Crop section syntax

@cindex Crop a given section of image
When in image mode, one of the methods to crop only one box from the
input image is to define a section. Instead of defining four
parameters for you to specify the corners of your section, ImageCrop
has a powerful syntax to read the box parameters from a string of
characters. If you leave certain parts of the string to be empty,
ImageCrop can fill them for you based on the input image sizes.

@cindex Define section to crop
To define a box, you need the coordinates of two points: the first
pixel in the box at (@code{X1}, @code{Y1}) and the pixel which is
immediately outside of the box (@code{X2, @code{Y2}}), for coordinates
in total. The four coordinates can be specified with one string:
@command{X1:X2,Y1:Y2} which is given to the @option{--section}
option. Therefore, the pixels along the first axis that are
@math{\geq}@command{X1} and <@command{X2} will be included in the
cropped image. The same goes for the second axis. Note that each
different term will be read as an integer, not a float (there are no
sub-pixels). Also, following the FITS standard, pixel indexes along
each axis starts from unity(1) not zero(0).

@cindex Crop section format
You can omit any of the values and they will be filled automatically.
The left hand side of the colon (@command{:}) will be filled with
@command{1}, and the right side with the image size. So, @command{2:,:}
will include the full range of pixels along the second axis and only
those with a first axis index larger than @command{2} in the first
axis. If the colon is omitted for a dimension, then the full range is
automatically used. So the same string is also equal to @command{2:,}
or @command{2:} or even @command{2}. If you want such a case for the
second axis, you should set it to: @command{,2}.

If you specify a negative value, it will be seen as before the indexes
of the image which are outside the image along the bottom or left
sides when viewed in SAO ds9. In case you want to count from the top
or right sides of the image, you can use a star (@option{*}). When
confronted with a @option{*}, ImageCrop will replace it with the
maximum length of the image in that dimension. So
@command{*-10:*+10,*-20:*+20} will mean that the crop box will be
@math{20\times40} pixels in size and only include the top corner of
the input image with 3/4 of the image being covered by blank pixels,
see @ref{Blank pixels}.

If you feel more comfortable with space characters between the values,
you can use as many space characters as you wish, just be careful to
put your value in double quotes, for example @command{-s"5:200,
123:854"}. If you forget, anything after the first space will not be
seen by @option{--section}, because the unquoted space character is
one of the characters that separates options on the command line.



@node Blank pixels, Invoking astimgcrop, Crop section syntax, ImageCrop
@subsection Blank pixels

@cindex Blank pixel
The cropped box can potentially include pixels that are beyond the
image range. For example when a target in the input catalog was very
near the edge of the input image. The parts of the cropped image that
were not in the input image will be filled with the following two
values depending on the data type of the image. In both cases, SAO ds9
will not color code those pixels.
@itemize
@item
If the data type of the image is a floating point type (float or
double), IEEE NaN (Not a number) will be used.
@item
For integer types, pixels out of the image will be filled with the
value of the @command{BLANK} keyword in the cropped image header. The
value assigned to it is the lowest value possible for that type, so
you will probably never need it any way. Only for the unsigned
character type (@command{BITPIX=8} in the FITS header), the maximum
value is used because it is unsigned, the smallest value is zero which
is often meaningful.
@end itemize
You can ask for such blank regions to not be included in the output
crop image using the @option{--noblank} option. In such cases, there
is no guarantee that the image size of your outputs are what you asked
for.

In some survey images, unfortunately they do not use the
@command{BLANK} FITS keyword. Instead they just give all pixels
outside of the survey area a value of zero. So by default, when
dealing with float or double image types, any values that are 0.0 are
also regarded as blank regions. This can be turned off with the
@option{--zeroisnotblank} option.


@node Invoking astimgcrop,  , Blank pixels, ImageCrop
@subsection Invoking ImageCrop

ImageCrop will crop a region from an image. If in WCS mode, it will
also stitch parts from separate images in the input files. The
executable name is @file{astimgcrop} with the following general
template

@example
$ astimgcrop [OPTION...] [ASCIIcatalog] ASTRdata ...
@end example


@noindent
One line examples:

@example
$ astimgcrop -I catalog.txt image.fits
$ astimgcrop -W catalog.txt /mnt/data/COSMOS/*_drz.fits
$ astimgcrop --section=10:*-10,10:*-10 --hdu=2 image.fits
$ astimgcrop --ra=189.16704 --dec=62.218203 goodsnorth.fits
$ astimgcrop --xc=568.342 --yc=2091.719 --iwidth=200 image.fits
@end example

@noindent
ImageCrop has one mandatory argument which is the input image name(s),
shown above with @file{ASTRdata ...}. You can use shell expansions,
for example @command{*} for this if you have lots of images in WCS
mode. If the crop box centers are in a catalog, you also have to
provide the catalog name as an argument. Alternatively, you have to
provide the crop box parameters with command line options.

@cindex Asynchronous thread allocation
When in catalog mode, ImageCrop will run using any number of threads
that you have specified with the @option{--numthreads} option, see
@ref{Common options}. Note that when multiple threads are being used,
in verbose mode, the outputs will not be in order. This is because the
threads are asynchronous and thus not started in order. When the box
coordinates are given on the command line, no threads will be created.

@menu
* astimgcrop options::          A list of all the options with explanation.
* astimgcrop output::           The outputs of ImageCrop.
@end menu

@node astimgcrop options, astimgcrop output, Invoking astimgcrop, Invoking astimgcrop
@subsubsection ImageCrop options

The options can be classified into the following contexts: Input,
Output and operating mode options. Options that are common to all
Gnuastro program are listed in @ref{Common options} and will not be
repeated here.

@cartouche
@noindent
@strong{NOTE:} The coordinates are in the FITS format. So the first
axis is the horizontal axis when viewed in SAO ds9 and the second axis
is the vertical. Also in the FITS standard, counting begins from 1
(one) not 0 (zero).
@end cartouche

@noindent
Crop box parameters:
@table @option

@item -x
@itemx --xc
(@option{=FLT}) The first FITS axis value of central position of the
crop box in single image mode.

@item -y
@itemx --yc
(@option{=FLT}) The second FITS axis value of the central position of
the crop box in single image mode.

@item -s
@itemx --section
(@option{=STR}) Section of the input image which you want to be
cropped. See @ref{Crop section syntax} for a complete explanation on
the syntax required for this input.

@item -r
@itemx --ra
(@option{=FLT}) The first FITS axis value of central position of the
crop box in single image mode.

@item -d
@itemx --dec
(@option{=FLT}) The second FITS axis value of the central position of
the crop box in single image mode.

@item -i
@itemx --xcol
(@option{=INT}) Column number of the first FITS axis position of the
box center, starting from zero. In SAO ds9, the first FITS axis is the
horizontal axis.

@item -j
@itemx --ycol
(@option{=INT}) Column number of the second FITS axis position of the
box center, starting from zero. In SAO ds9, the second FITS axis is
the vertical axis.

@item -a
@itemx --iwidth
(@option{=INT}) Width the square box to crop in image mode in units of
pixels. In order for the chosen central pixel to be in the center of
the cropped image, the final width has to be an odd number, therefore
if the width

@item -f
@itemx --racol
(@option{=INT}) Column number of Right Ascension (RA) in the input
catalog, starting from zero.

@item -g
@itemx --deccol
(@option{=INT}) Column number of declination in the input catalog,
starting from zero.

@item -w
@itemx --wwidth
(@option{=FLT}) The width of the crop box in WCS mode in units of
arc-seconds.

@end table

@noindent
Output options:
@table @option

@item -c
@itemx --checkcenter
@cindex Check center of crop
(@option{=INT}) Box size of region in the center of the image to check
in units of pixels. This is only used in WCS mode. Because surveys
don't often have a clean square or rectangle shape, some of the pixels
on the sides of the surveys don't have any data and are commonly
filled with zero valued pixels.

If the RA and Dec of any of the targets specified in the catalog fall
in such regions, that cropped image will be useless! Therefore with
this option, you can specify a width of a small box (3 pixels is often
good enough) around the central pixel of the cropped image. If all the
pixels in this small box have the value of zero, no cropped image will
be created and this object will be flagged in the final log file.

@item -p
@itemx --suffix
(@option{=STR}) The suffix (or post-fix) of the output files for when
you want all the cropped images to have a special ending. One case
where this might be helpful is when besides the science images, you
want the weight images (or exposure maps, which are also distributed
with survey images) of the cropped regions too. So in one run, you can
set the input images to the science images and
@option{--suffix=_s.fits}. In the next run you can set the weight
images as input and @option{--suffix=_w.fits}.

@item -b
@itemx --noblank
Pixels outside of the input image that are in the crop box will not be
used. By default they are filled with blank values (depending on
type), see @ref{Blank pixels}.

@item -z
@itemx --zeroisnotblank
In float or double images, it is common to give the value of zero to
blank pixels. If the input image type is one of these two types, such
pixels will also be considered as blank. You can disable this behavior
with this option, see @ref{Blank pixels}.

@end table

@noindent
Operating mode options:
@table @option

@item -I
@itemx --imgmode
Operate in Image mode as described above. This option is only useful
when catalog is being provided. If coordinates are given on the
command line, the mode is automatically set based on them.

@item -W
@itemx --wcsmode
Operate in WCS mode. See explanations for @option{--imgmode}.

@end table





@node astimgcrop output,  , astimgcrop options, Invoking astimgcrop
@subsubsection ImageCrop output
When a catalog is given, the value of @option{--output} (see
@ref{Common options}) will be seen as the directory to store the
output cropped images. In such cases, the outputs will consist of two
parts: a variable part (the row number of each target starting from 1)
along with a fixed string which you can set with the @option{--suffix}
option. Note that in catalog mode, only one image can be input.

When the crop box is specified on the command line, the value to
@option{--output} will be used as a file name. If no output is
specified or if it is a directory, the output file name will follow
the automatic output names of Gnuastro, see @ref{Automatic output}
for the input image.

The header of each output cropped image will contain the names of the
input image(s) it was cut from. If a name is longer than the 70
character space that the FITS standard allows for header keyword
values, the name will be cut into several keywords from the nearest
slash (@key{/}). The keywords have the following format:
@command{ICFn_m}. Where @command{n} is the number of the image used in
this crop and @command{m} is the part of the name. Following the name
is another keyword named @command{ICFnPIX} which shows the pixel range
from that input image in the same syntax as @ref{Crop section syntax}.

Once done, a log file will be created in the current directory named
@file{astimgcrop.log}. This file will keep the names of all the
outputs along with the number of images that were used in them and
also whether the central pixels of the cropped image are full. There
are also comments on the top explaining basic information about the
run. If the log file cannot be created (for example you don't have
write permission in the directory you are running ImageCrop in) it
will not be created (unless @option{--individual} is called). You can
see the same results in verbose mode on the command line in such
cases.






















@node Convolve, ImageWarp, ImageCrop, Image manipulation
@section Convolve

@cindex Convolution
@cindex Neighborhood
@cindex Weighted average
@cindex Average, weighted
@cindex Kernel, convolution
Convolution is the process of changing the value of one pixel to the
@emph{weighted} average of all the pixels in its
@emph{neighborhood}@footnote{The definition here is the specific
definition that is most commonly used in image processing and
astronomy. Mathematically speaking, convolution is a far more general
process of merging two functions.}. We define the `neighbourhood' of
each pixel (how many pixels) and the `weight' function (how much each
neighbouring pixel should contribute depending on its position)
through a second image which is known as a spatial
kernel@footnote{Also known as filter, here we will use `kernel'.}. A
nice and fully illustrated introduction to convolution has been
provided by
ImageMagick@footnote{@url{http://www.imagemagick.org/Usage/convolve/}}.

@cindex Detection
@cindex Atmosphere
@cindex Blur image
@cindex Cosmic rays
@cindex Pixel mixing
@cindex Mixing pixel values
Convolution of an image will generally result in blurring the image
because it mixes pixel values. In other words, if the image has sharp
differences in neighbouring pixel values@footnote{In astronomy, the
only major time we confront such sharp borders in signal are cosmic
rays. All other sources of signal in an image are already blurred by
the atmosphere or the optics of the instrument.}, those sharp
differences will become smoother. This has very good consequences in
detection for example, because in an actual observed image, the
variation in neighbouring pixel values due to noise can be very
high. But after convolution, those variations will decrease and we
have a better hope in detecting the possible underlying
signal. Another case where convolution is extensively used is in mock
images and modelling in general, convolution can be used to simulate
the effect of the atmosphere or the optical system on the mock
profiles that we create, see @ref{PSF}.

@cindex Spatial domain
@cindex Frequency domain
Convolution is a very interesting and important topic in any form of
signal analysis (including astronomical observations). So we strongly
recommend going through any good image processing book to get a good
understanding of it@footnote{Our main reference for this chapter was:
Gonzalez, R. C., Woods, R. E., 2008, Digital image processing (third
edition), Pearson Prentice Hall.}. We will just have a fast summary
here.  In discussing convolution, understanding the spatial and
frequency domains is the key. An image viewed in the spatial domain is
the same image you are observing: each pixel has a certain flux value
and the pixel (which has a fixed spatial position) with the highest
flux value can be seen first@footnote{Assuming that the highest flux
is the easiest to see}. In the frequency domain, the spatial change of
flux values is emphasized, with the lowest frequency (related to the
sum of the pixels in the image) occupying the first pixel (in FITS on
the bottom left of the image) and higher frequencies extending
outwards@footnote{In the frequency domain of a real image, we will
actually be dealing with complex pixel values we can view either the
amplitude or phase.}@footnote{Chapter 4 of Gonzalez and woods (2008)
introduces the concepts of sampling and the frequency domain very
nicely. The nicely illustrated guide by ImageMagick is also very
educative: @url{http://www.imagemagick.org/Usage/fourier/}}.  Removing
(filtering) certain frequency ranges is the source of the term
filtering@footnote{For example ``low pass filtering'' which refers to
removing small frequencies}.

@menu
* Convolution process::         More basic explanations.
* Convolution on the edges::    Dealing with the edges of an image.
* Spatial vs. Frequency domain::  Comparison of the two domains.
* Invoking astconvolve::        Options and arguments to Convolve.
@end menu

@node Convolution process, Convolution on the edges, Convolve, Convolve
@subsection Convolution process

In convolution, the kernel specifies the weight and positions of the
neighbors of each pixel. Visualizing convolution in the spatial domain
might be easier. To find the convolved value of a pixel, the central
pixel of the kernel is placed on that pixel. The values of each
overlapping pixel in the kernel and image are multiplied by each other
and summed for all the kernel pixels. To have one pixel in the center,
the sides of the convolution kernel have to be an odd number. This
process effectively mixes the pixel values of each pixel with its
neighbors, resulting in a blurred image compared to the sharper input
image.

@cindex Linear spatial filtering
Formally, convolution is one kind of linear `spatial filtering' in
image processing texts. If we assume that the kernel has @mymath{2a+1}
and @mymath{2b+1} pixels on each side, the convolved value of a pixel
placed at @mymath{x} and @mymath{y} (@mymath{C_{x,y}}) can be
calculated from the neighboring pixel values in the input image
(@mymath{I}) and the kernel (@mymath{K}) from

@dispmath{C_{x,y}=\sum_{s=-a}^{a}\sum_{t=-b}^{b}K_{s,t}\times{}I_{x+s,y+t}.}

@cindex Correlation
@cindex Convolution
Any pixel coordinate that is outside of the image in the equation
above will be considered to be zero. When the kernel is symmetric
about its center the blurred image has the same orientation as the
original image. However, if the kernel is not symmetric, the image
will be affected in the opposite manner, this is a natural consequence
of the definition of spatial filtering. In order to avoid this we can
rotate the kernel about its center by 180 degrees so convolution can
have the same original orentation. Technically speaking, only if the
kernel is flipped the process is known @emph{Convolution}. If it isn't
it is known as @emph{Correlation}.

To be a weighted average, the sum of the weights (the pixels in the
kernel) have to be unity. This will have the consequence that the
convolved image of an object and unconvolved object will have the same
total flux, which is natural, because convolution should not eat up
the object photons, it only disperses them.

@cindex Fast Fourier Transform
@cindex GNU Scientific Library
In the frequency domain, no rotating is necessary. The two images have
to be padded with zero valued pixels such that the number of pixels on
the sides of the two images are identical. The sides of the padded
image have to be at least equal to the sum of the sides of each image
minus one. The speed of the algorithms for Fast Fourier Transform
(FFT) depend on the size of the paded images. If the final sides are a
factor of 2, 3, 4, 5, 6, 7 the GNU Scientific Library provides
efficient algorithms for the fourier transform. In case the size is
not a multiple of any of these, then it will fall back to the standard
Discrete Fourier Transform which will be slower.





@node Convolution on the edges, Spatial vs. Frequency domain, Convolution process, Convolve
@subsection Convolution on the edges

In purely `linear' spatial filtering (convolution), there are problems
on the edges of the input image. Explaining the problem in the spatial
domain might be easier@footnote{Once a good understanding of the
frequency domain is achieved the reason in that domain is also very
enlightening, see any image processing book for a good
explanation.}. The problem originates from the fact that on the edges,
in practice@footnote{Because we assumed the overlapping pixels outside
the input image have a value of zero.}, the sum of the weights we use
on the actual image pixels is not unity. For example, as discussed
above, a profile in the center of an image will have the same total
flux before and after convolution. However, for a profile on the side
of the image, the total flux (sum of its pixels within the image) will
not be equal, some flux is going to be `eaten' by the edges.

If you ran @command{$ make check} on the source files of Gnuastro, you
can see the this effect by comparing the
@file{convolve_frequency.fits} with @file{convolve_spatial.fits} in
the @file{./tests/} directory. In the spatial domain, any blank pixel
in the image will not be used in the convolution, see @ref{Blank
pixels}, so the problem explained above will also occur on the sides
of blank regions (which might be masked for example). The solution to
this edge effect problem (only in the spatial domain) is to not assume
that the sum of the kernel pixels is unity, so taking @mymath{W} as
the sum of the kernel pixels that used non-blank image pixels, the
equation in @ref{Convolution process} will become:

@dispmath{C_{x,y}= { \sum_{s=-a}^{a}\sum_{t=-b}^{b}K_{s,t}\times{}I_{x+s,y+t} \over W}.}

@noindent
In this manner, objects which are near the sides of the image or blank
pixels will also have the same flux (within the image) before and
after convolution. This correction is applied by default in Convolve
when convolving in the spatial domain. To disable it, you can use the
@option{--noedgecorrection} option. In the frequency domain, there is
no way to avoid this loss of flux near the edges of the image.

Note that the edge effect discussed here is different from the one in
@ref{If convolving afterwards}. In making mock images we want to
simulate a real observation. In a real observation the images of the
galaxies on the sides of the CCD are first blurred by the atmosphere
and instrument, then imaged. So light from the parts of a galaxy which
are immediately outside the CCD will affect the parts of the galaxy
which are covered by the CCD. Therefore in modeling the observation,
we have to convolve an image that is larger than the input image by
exactly half of the convolution kernel. We can hence conclude that
this correction for the edges is only useful when working on actual
observed images (where we don't have any more data on the edges) and
not in modeling.


@node Spatial vs. Frequency domain, Invoking astconvolve, Convolution on the edges, Convolve
@subsection Spatial vs. Frequency domain

With the discussions above it might not be clear when to choose the
spatial domain and when to choose the frequency domain. Here we will
try to list the benefits of each.

@noindent
The spatial domain,
@itemize
@item
Can correct for the edge effects of convolution, see @ref{Convolution
on the edges}.

@item
Can operate on blank pixels.

@item
Can be faster than frequency domain when the kernel is small (in terms
of the number of pixels on the sides).
@end itemize

@noindent
The frequency domain,
@itemize
@item
Will be much faster when the image and kernel are both large.
@end itemize

@noindent
As a general rule of thumb, when working on an image of modelled
profiles use the frequency domain and when working on an image of real
(observed) objects use the spatial domain (corrected for the
edges). The reason is that if you apply a frequency domain convolution
to a real image, you are going to loose information on the edges and
generally you don't want large kernels. But when you have made the
profiles in the image your self, you can just make a larger input
image and crop the central parts to completely remove the edge effect,
see @ref{If convolving afterwards}. Also due to oversampling, both the
kernels and the images can become very large and the speed boost of
frequency domain convolution will significantly improve the processing
time, see @ref{Oversampling}.


@node Invoking astconvolve,  , Spatial vs. Frequency domain, Convolve
@subsection Invoking Convolve

Convolve an input image with a known kernel. The general template for
convolve is:

@example
$ astconvolve [OPTION...] ASTRdata
@end example

@noindent
One line examples:

@example
$ astconvolve --kernel=psf.fits mockimg.fits
@end example

The only argument accepted by Convolve is an input image file. For the
full list of options to all Gnuastro programs, please see @ref{Common
options}, here we will only explain the options particular to
Convolve:

@table @option

@item -k
@itemx --kernel
(@option{=STR}) The input kernel image filename. It should have an odd
number of pixels and any blank pixel value in the image will be
changed to zero. Prior to convolution several operations will be done
on the image, see @ref{Convolution process} for an explanation of the
reason for the last two.
@itemize

@item
Whatever its initial type, it will be converted to a floating point
array for analysis.

@item
@cindex NaN
@cindex Blank pixel
Any blank or NaN (not a number) pixel in the kernel will be given a
value of zero.

@item
The kernel will be flipped immediately after reading it, can be disabled with the @option{--nokernelflip}

@item
The kernel will be normalized (such that the sum of its pixels will be
unity), can be disabled with @option{--nokernelnorm}.
@end itemize

@item -H
@itemx --khdu
(@option{=STR}) The input kernel image HDU name or number.

@item --nokernelflip
Do not flip the kernel after reading it the spatial domain
convolution. This can be useful if the flipping has already been
applied to the kernel.

@item --nokernelnorm
Do not normalize the kernel after reading it, such that the sum of its
pixels is unity.

@item -C
@itemx --noedgecorrection
Do not apply edge correction when convolving in the spatial domain,
see @ref{Convolution on the edges}.

@item -f
@itemx --frequency
@cindex Discrete fourier transform
Convolve using discrete fourier transform in the frequency domain: The
fourier transform of both arrays is first calculated and
multiplied. Then the inverse fourier transform is applied to the
product to give the final convolved image.

For large images, this process will be more efficient than convolving
in the spatial domain. However, the edges of the image will loose some
flux, see @ref{Convolution on the edges}.

@item -s
@itemx --spatial
Convolve in the spatial domain, see @ref{Convolution process}.


@item --viewfreqsteps
With this option a file with the initial name of the output file will
be created that is suffixed with @file{_freqsteps.fits}, all the steps
done to arrive at the final convolved image are saved as extensions in
this file. The extensions in order are:

@enumerate
@item
The padded input image. In frequency domain convolution the two images
(input and convolved) have to be the same size and both should be
padded by zeros.

@item
The padded kernel, similar to the above.

@item
@cindex Phase angle
@cindex Complex numbers
@cindex Numbers, complex
@cindex Fourier spectrum
@cindex Spectrum, Fourier
The Fourier spectrum of the forward Fourier transform of the input
image. Note that the fourier transform is a complex operation (and not
viewable in one image!)  So we either have to show the `Fourier
spectrum' or the `Phase angle'. For the complex number
@mymath{a+ib}, the Fourier spectrum is defined as
@mymath{\sqrt{a^2+b^2}} while the phase angle is defined as
@mymath{arctan(b/a)}.

@item
The Fourier spectrum of the forward Fourier transform of the kernel
image.

@item
The Fourier spectrum of the multiplied (through complex arithmetic)
transformed images.

@item
@cindex Round-off error
@cindex Floating point round-off error
@cindex Error, floating point round-off
The inverse Fourier transform of the multiplied image. If you open it,
you will see that the convolved image is now in the center, not on one
side of the image as it started with (in the padded image of the first
extension). If you are working on a mock image which originally had
pixels of precisely 0.0, you will notice that in those parts that your
convolved profile(s) did not conver, the values are now
@mymath{\sim10^{-18}}, this is due to floating-point round off
errors. Therefore in the final step (when cropping the central parts
of the image), we also remove any pixel with a value less than
@mymath{10^{-17}}.

@end enumerate
@end table











@node ImageWarp, SubtractSky, Convolve, Image manipulation
@section ImageWarp
Image warpring is the process of mapping the pixels of one image onto
a new pixel grid. This process is sometimes known as transformation,
however following the discussion of Heckbert 1989@footnote{Paul
S. Heckbert. 1989. @emph{Fundamentals of Texture mapping and Image
Warping}, Master's thesis at University of California, Berkely.} we
will not be using that term because it can be confused with only pixel
value or flux transformations. Here we specifically mean the pixel
grid transformation which is better conveyed with `warp'.

@cindex Gravitational lensing
Image wrapping is a very important step in astronomy, both in
observational data analysis and in simulating modeled images. In
modelling, warping an image is necessary when we want to apply grid
transformations to the initial models, for example in simulating
gravitational lensing (Radial warpings are not yet included in
ImageWarp). Observational reasons for warping an image are listed
below:

@itemize

@cindex Signal to noise ratio
@item
@strong{Noise:} Most scientifically interesting targets are inherently
faint (have a very low Signal to noise ratio). Therefore one short
exposure is not enough to detect such objects that are drowned deeply
in the noise. We need multiple exposures so we can add them together
and increase the objects' signal to noise ratio. Keeping the telescope
fixed on one field of the sky is practically impossible. Therefore
very deep observations have to put into the same grid before adding
them.

@cindex Mosaicing
@cindex Image mosaic
@item
@strong{Resolution:} If we have multiple images of one patch of the
sky (hopefully at multiple orientations) we can warp them to the same
grid. The multiple orientations will allow us to `guess' the values of
pixels on an output pixel grid that has smaller pixel sizes and thus
increase the resolution of the output. This process of merging
multiple observations is known as Mosaicing.

@cindex Cosmic rays
@item
@strong{Cosmic rays:} Cosmic rays can randomly fall on any part of an
image. If they collide vertically with the camera, they are going to
create a very sharp and bright spot that in most cases can be separted
easily@footnote{All astronomical targets are blurred with the PSF, see
@ref{PSF}, however a cosmic ray is not and so it is very sharp (it
suddenly stops at one pixel).}. However, depending on the depth of the
camera pixels, and the angle that a cosmic rays collides with it, it
can cover a line-like larger area on the CCD which makes the detection
using their sharp edges very hard and error prone. One of the best
methods to remove cosmic rays is to compare multiple images of the
same field. To do that, we need all the images to be on the same pixel
grid.

@cindex Optical distortion
@cindex Distortion, optical
@item
@strong{Optical distortion:} (Not yet included in ImageWarp) In wide
field images, the optical distortion that occurs on the outer parts of
the focal plane will make accurate comparison of the objects at
various locations impossible. It is therefore necessary to warp the
image and correct for those distortions prior to the analysis.

@cindex ACS
@cindex CCD
@cindex WFC3
@cindex Wide Field Camera 3
@cindex Charge-coupled device
@cindex Hubble Space Telescope
@cindex Advanced camera for surveys
@item
@strong{Detector not on focal plane:} In some cases (like the Hubble
Space Telescope ACS and WFC3 cameras), the CCD might be tilted
compared to the focal plane, therefore the recorded CCD pixels have to
be projected onto the focal plane before further analysis.

@end itemize

@menu
* Warping basics::              Basics of coordinate transformation.
* Merging multiple warpings::   How to merge multiple matrices.
* Resampling::                  Warping an image is re-sampling it.
* Invoking astimgwarp::         Arguments and options for ImageWarp.
@end menu

@node Warping basics, Merging multiple warpings, ImageWarp, ImageWarp
@subsection Warping basics

@cindex Scaling
@cindex Coordinate transformation
Lets take @mymath{\left[\matrix{u&v}\right]} as the coordinates of
a point in the input image and @mymath{\left[\matrix{x&y}\right]} as the
coordinates of that same point in the output image@footnote{These can
be any real number, we are not necessarily talking about integer
pixels here.}. The simplest form of coordinate transformation (or
warping) is the scaling of the coordinates, lets assume we want to
scale the first axis by @mymath{M} and the second by @mymath{N}, the
output coordinates of that point can be calculated by

@dispmath{\left[\matrix{x\cr y}\right]=
          \left[\matrix{Mu\cr Nv}\right]=
          \left[\matrix{M&0\cr0&N}\right]\left[\matrix{u\cr v}\right]}

@cindex Matrix
@cindex Multiplication, Matrix
@cindex Rotation of coordinates
@noindent
Note that these are matrix multiplications. We thus see that we can
represent any such grid warping as a matrix. Another thing we can do
with this @mymath{2\times2} matrix is to rotate the output coordinate
around the common center of both coordinates. If the output is rotated
anticlockwise by @mymath{\theta} degrees from the positive (to the
right) horizontal axis, then the warping matrix should become:

@dispmath{\left[\matrix{x\cr y}\right]=
   \left[\matrix{ucos\theta-vsin\theta\cr usin\theta+vcos\theta}\right]=
   \left[\matrix{cos\theta&-sin\theta\cr sin\theta&cos\theta}\right]
   \left[\matrix{u\cr v}\right]
   }

@cindex Flip coordinates
@noindent
We can also flip the coordinates around the first axis, the second
axis and the coordinate center with the following three matrices
respectively:

@dispmath{\left[\matrix{1&0\cr0&-1}\right]\quad\quad
          \left[\matrix{-1&0\cr0&1}\right]\quad\quad
          \left[\matrix{-1&0\cr0&-1}\right]}

@cindex Shear
@noindent
The final thing we can do with this definition of a @mymath{2\times2}
warping matrix is shear. If we want the output to be sheared along the
first axis with @mymath{A} and along the second with @mymath{B}, then
we can use the matrix:

@dispmath{\left[\matrix{1&A\cr B&1}\right]}

@noindent
To have one matrix representing any combination of these steps, you
use matrix multiplication, see @ref{Merging multiple warpings}. So any
combinations of these transformations can be displayed with one
@mymath{2\times2} matrix:

@dispmath{\left[\matrix{a&b\cr c&d}\right]}

@cindex Wide Field Camera 3
@cindex Hubble Space Telescope
@cindex Advanced Camera for Surveys
The transformations above can cover a lot of the needs of most
coordinate transformations. However they are limited to mapping the
point @mymath{[\matrix{0&0}]} to @mymath{[\matrix{0&0}]}. Therefore
they are useless if you want one coordinate to be shifted compared to
the other one. They are also space invariant, meaning that all the
coordinates in the image will recieve the same transformation. In
other words, all the pixels in the output image will have the same
area if placed over the input image. So transformations which require
varying output pixel sizes like projections cannot be applied through
this @mymath{2\times2} matrix either (for example for the tilted ACS
and WFC3 camera detectors on board the Hubble space telescope).

@cindex M@"obius, August. F.
@cindex Homogeneous coordinates
@cindex Coordinates, homogeneous
To add these further capabilities, namely translation and projection,
we use the homogeneous coordinates. They were defined about 200 years
ago by August Ferdinand M@"obius (1790 -- 1868). For simplicity, we
will only discuss points on a 2D plane and avoid the complexities of
higher dimensions. We cannot provide a deep mathematical introduction
here, interested readers can get a more detailed explanation from
Wikipedia@footnote{@url{http://en.wikipedia.org/wiki/Homogeneous_coordinates}}
and the references therein.

By adding an extra coordinate to a point we can add the flexibility we
need. The point @mymath{[\matrix{x&y}]} can be represented as
@mymath{[\matrix{xZ&yZ&Z}]} in homogeneous coordinates. Therefore
multiplying all the coordinates of a point in the homogenous
coordinates with a constant will give the same point. Put another way,
the point @mymath{[\matrix{x&y&Z}]} corresponds to the point
@mymath{[\matrix{x/Z&y/Z}]} on the constant @mymath{Z} plane. Setting
@mymath{Z=1}, we get the input image plane, so
@mymath{[\matrix{u&v&1}]} corresponds to @mymath{[\matrix{u&v}]}. With
this definition, the transformations above can be generally written
as:

@dispmath{\left[\matrix{x\cr y\cr 1}\right]=
          \left[\matrix{a&b&0\cr c&d&0\cr 0&0&1}\right]
          \left[\matrix{u\cr v\cr 1}\right]}

@noindent
@cindex Affine Transformation
@cindex Transformation, affine
We thus acquired 4 extra degrees of freedom. By giving non-zero values
to the zero valued elements of the last column we can have translation
(try the matrix multiplication!). In general, any coordinate
transformation that is represented by the matrix below is known as an
affine
transformation@footnote{@url{http://en.wikipedia.org/wiki/Affine_transformation}}:

@dispmath{\left[\matrix{a&b&c\cr d&e&f\cr 0&0&1}\right]}

@cindex Homography
@cindex Projective transformation
@cindex Transformation, projective
We can now consider translation, but the affine transform is still
spatially invariant. Giving non-zero values to the other two elements
in the matrix above gives us the projective transformation or
Homography@footnote{@url{http://en.wikipedia.org/wiki/Homography}}
which is the most general type of transformation with the
@mymath{3\times3} matrix:

@dispmath{\left[\matrix{x'\cr y'\cr w}\right]=
          \left[\matrix{a&b&c\cr d&e&f\cr g&h&1}\right]
          \left[\matrix{u\cr v\cr 1}\right]}

@noindent
So the output coordinates can be calculated from:

@dispmath{x={x' \over w}={au+bv+c \over gu+hv+1}\quad\quad\quad\quad
          y={y' \over w}={du+ev+f \over gu+hv+1}}

Thus with homography we can change the sizes of the output pixels on
the input plane, giving a `perspective'-like visual impression. This
can be quantitatively seen in the two equations above. When
@mymath{g=h=0}, the denominator is independent of @mymath{u} or
@mymath{v} and thus we have spatial invariance. Homography preserves
lines at all orientations. A very useful fact about homography is that
its inverse is also a homography. These two properties play a very
important role in the implementation of this transformation. A short
but instructive and illustrated review of affine, projective and also
bilinear mappings is provided in Heckbert 1989@footnote{Paul
S. Heckbert. 1989. @emph{Fundamentals of Texture mapping and Image
Warping}, Master's thesis at University of California, Berkely. Note
that since points are defined as row vectors there, the matrix is the
transpose of the one discussed here.}.

@node Merging multiple warpings, Resampling, Warping basics, ImageWarp
@subsection Merging multiple warpings

@cindex Commutative property
@cindex Matrix multiplication
@cindex Multiplication, matrix
@cindex Non-commutative operations
@cindex Operations, non-commutative
In @ref{Warping basics} we saw how one basic warping/transformation
can be represented with a 3 by 3 matrix. To make more complex warpings
these matrices have to be multiplied through matrix
multiplication. However matrix multiplication is not commutative, so
the order of the set of matrices you use for the multiplication is
going to be very important.

The first warping should be placed as the left-most matrix. The second
warping to the right of that and so on. The second transformation is
going to occur on the warped coordinates of the first.  As an example
for merging a few transforms into one matrix, the multiplication below
represents the rotation of an image about a point
@mymath{[\matrix{U&V}]} anticlockwise from the horizontal axis by an
angle of @mymath{\theta}. To do this, first we take the origin to
@mymath{[\matrix{U&V}]} through translation. Then we rotate the image,
then we translate it back to where it was initially. These three
operations can be merged in one operation by calculating the matrix
multiplication below:

@dispmath{\left[\matrix{1&0&U\cr0&1&V\cr{}0&0&1}\right]
          \left[\matrix{cos\theta&-sin\theta&0\cr sin\theta&cos\theta&0\cr                0&0&1}\right]
          \left[\matrix{1&0&-U\cr0&1&-V\cr{}0&0&1}\right]}





@node Resampling, Invoking astimgwarp, Merging multiple warpings, ImageWarp
@subsection Resampling

@cindex Pixel
@cindex Camera
@cindex Detector
@cindex Sampling
@cindex Resampling
@cindex Pixel mixing
@cindex Photoelectrons
@cindex Picture element
@cindex Mixing pixel values
A digital image is composed of descrete `picture elements' or
`pixels'. When a real image is created from a camera or detector, each
pixel's area is used to store the number of photoelectrons that were
created when incident photons collided with that pixel's surface
area. This process is called the `sampling' of a continuous or analog
data into digital data. When we change the pixel grid of an image or
warp it as we defined in @ref{Warping basics}, we have to `guess' the
flux value of each pixel on the new grid based on the old grid, or
resample it. Because of the `guessing', any form of warping on the
data is going to degrade the image and mix the original pixel values
with each other. So if an analysis can be done on an un-warped data
image, it is best to leave the image untouched and pursue the
analysis. However as discussed in @ref{ImageWarp} this is not possible
most of the times, so we have to accept the problem and re-sample the
image.

@cindex Point pixels
@cindex Interpolation
@cindex Bicubic interpolation
@cindex Signal to noise ratio
@cindex Bilinear interpolation
@cindex Interpolation, bicubic
@cindex Interpolation, bilinear
In most applications of image processing, it is sufficient to consider
each pixel to be a point and not an area. This assumption can
significantly speed up the processing of an image and also the
simplicity of the code. It is a fine assumption when the
signal to noise ratio of the objects are very large. The question will
then be one of interpolation because you have multiple points
distributed over the output image and you want to find the values at
the pixel centers. To increase the accuracy, you might also sample
more than one point from within a pixel giving you more points for a
more accurate interpolation in the output grid.

@cindex Image edges
@cindex Edges, image
However, interpolation has several problems. The first one is that it
will depend on the type of function you want to assume for the
interpolation. For example you can choose a bi-linear or bi-cubic (the
`bi's are for the 2 dimentional nature of the data) interpolation
method. For the latter there are various ways to set the
constants@footnote{see
@url{http://entropymine.com/imageworsener/bicubic/} for a nice
introduction.}. Such functional interpolation functions can fail
seriously on the edges of an image. They will also need normalization
so that the flux of the objects before and after the warpings are
comparable. The most basic problem with such techniques is that they
are based on a point while a detector pixel is an area. They add a
level of subjectivitiy to the data (make more assumptions through the
functions than the data can handle). For most applications this is
fine, but in scientific applications where detection of the faintest
possible galaxies or fainter parts of bright galaxies is our aim, we
cannot afford this loss. Because of these reasons ImageWarp will not
use such interpolation techniques.

@cindex Drizzle
@cindex Pixel mixing
@cindex Exact area resampling
ImageWarp will do interpolation based on ``pixel mixing''@footnote{For
a graphic demonstration see
@url{http://entropymine.com/imageworsener/pixelmixing/}.}  or ``area
resampling''. This is also what the Hubble Space Telescope pipeline
calles
``Drizzling''@footnote{@url{http://en.wikipedia.org/wiki/Drizzle_(image_processing)}}. This
technique requires no functions, it is thus non-parametric. It is also
the closest we can get (make least assumptions) to what actually
happens on the detector pixels. The basic idea is that you
reverse-transform each output pixel to find which pixels of the input
image it covers and what fraction of the area of the input pixels are
covered. To find the output pixel value, you simply sum the value of
each input pixel weighted by the overlap fraction (between 0 to 1) of
the output pixel and that input pixel. Through this process, pixels
are treated as an area not as a point (which is how detectors create
the image), also the total flux of an object will be left completely
unchanged.

If there are very high spatial-frequency signals in the image (for
example fringes) which vary on a scale smaller than your output image
pixel size, pixel mixing can cause
ailiasing@footnote{@url{http://en.wikipedia.org/wiki/Aliasing}}. So if
the input image has fringes, they have to be calculated and removed
separately (which would naturally be done in any astronomical
application). Because of the PSF no astronomical target has a sharp
change in the signal so this issue is less important for astronoimcal
applications, see @ref{PSF}.


@node Invoking astimgwarp,  , Resampling, ImageWarp
@subsection Invoking ImageWarp

The general template for invoking ImageWarp is:

@example
$ astimgwarp [OPTIONS...] [matrix.txt] InputImage
@end example

@noindent
One line examples:

@example
$ astimgwarp matrix.txt image.fits
$ astimgwarp --matrix=0.2,0,0.4,0,0.2,0.4,0,0,1 image.fits
$ astimgwarp --matrix="0.7071,-0.7071  0.7071,0.7071" image.fits
@end example

ImageWarp can accept two arguments, one (the input image) is mandatory
if any processing is to be done. An optional argument is a plain text
file that will keep the warp/transform matrix, see @ref{Warping
basics}. There is also the @option{--matrix} option from which the
matrix can be literally specified on the command line. If both are
present when calling ImageWarp, the contents of the plain text file
have higher precedence. The general options to all Gnuastro programs
can be seen in @ref{Common options}.

@cindex WCSLIB
@cindex World Coordinate System
By default the WCS (World Coordinate System) information of the input
image is going to be corrected in the output image. WCSLIB will save
the input WCS information in the @code{PC} matrix@footnote{Greisen
E.W., Calabretta M.R. (2002) Representation of world coordinates in
FITS. Astronomy and Astrophysics, 395, 1061-1075.}. To correct the
WCS, ImageWarp multiplies the @code{PC} matrix with the inverse of the
specified transformation matrix. Also the @code{CRPIX} point is going
to be changed to its correct place in the output image
coordinates. This behavior can be disabled with the
@option{--nowcscorrection} option.

To be the most accurate the input image will be converted to double
precision floating points and all the processing will be done in this
format. By default, in the end, the output image will be converted
back to the input image data type. Note that if the input type was not
a floating point format, then the floating point output pixels are
going to be rounded to the nearest integer (using the @code{round}
function in the C programming language) which can lead to a loss of
data. This behavior can be disabled with the @option{--doubletype}
option. The input file and input warping matrix elements are stored in
the output's header.

@cartouche
@noindent
@strong{Coordinates of pixel center}: Based on the FITS standard,
integer values are assigned to the center of a pixel and the
coordinate [1.0, 1.0] is the center of the bottom left (first) image
pixel. So the point [0.0, 0.0] is half a pixel away (in each axis)
from the bottom left vertice of the first pixel@footnote{So if you
want to warp the image relative to the bottom left vertice of the
bottom left pixel, you have to shift the warping center by [0.5, 0.5],
apply your transform then shift back by [-0.5, -0.5]. Similar to the
example in see @ref{Merging multiple warpings}. For example see the
one line example above which scales the image by one fifth
(0.2). Without this correction (if it was
@code{0.2,0,0,0,0.2,0,0,0,1}), the image would not be correctly
scaled.}.
@end cartouche

@table @option

@item -m
@itemx --matrix
(@option{=STR}) The warp/transformation matrix. All the elements in
this matrix must be separated by any number of space, tab or comma
(@key{,}) characters. If you want to use the first two, then be sure
to wrap the matrix within double quotation marks (@key{"}) so they are
not confused with other arguments on the command line, see
@ref{Options}. This also applies to values in the configuration files,
see @ref{Configuration file format}.  The transformation matrix can be
either 2 by 2 or 3 by 3 array, see @ref{Warping basics}.

@cindex NaN
The determinant of the matrix has to be non-zero and it must not
contain any non-number values (for example infinities or NaNs). The
elements of the matrix have to be written row by row. So for the
general homography matrix of @ref{Warping basics}, it should be called
with @command{--matrix=a,b,c,d,e,f,g,h,1}.

@item -n
@itemx --nowcscorrection
Do not correct the WCS information of the input image and save it
untouched to the output image.

@cindex Blank pixel
@cindex Pixel, blank
@item -z
@itemx --zerofornoinput
Set output pixels which do not correspond to any input to zero. By
default they are set to blank pixel values, see @ref{Blank pixels}.

@item -d
@itemx --doubletype
By default the output image is going to have the same type as the
input image. If this option is called, the output will be in double
precision floating point format irrespective of the input data
type. When dealing with integer input formats, this option can be
useful in checking the results.

@end table






@node SubtractSky,  , ImageWarp, Image manipulation
@section SubtractSky

@cindex Atmosphere
@cindex Flat field
@cindex Stray light
@cindex Bias subtraction
Raw astronomical images (and even poorly processed images) don't
usually have a uniform `sky' value over their surface prior to
processing, see @ref{Sky value} for a complete definition of the sky
value. However, a uniform sky value over the image is vital for
further processing. For ground based images (particularly at longer
wavelengths) this can be due to actual variations of flux in the
atmosphere. Another cause might be systematic biases in the instrument
or prior processing. For example stray light in the telescope/camera
or bad flat-fielding or bias subtraction. The latter is a major issue
in space based images where the atmosphere is no longer a problem.

@cindex Grid
@cindex Mesh
@cindex Gradient
SubtractSky is a tool to find the sky value on a grid over the
image. The size of the grid will determine how accurately it can
account for gradients in the sky value. Such that if the gradient
(change of sky value) is too sharp, a smaller grid size has to be
chosen. However the results will be most accurate with a larger grid
size.


@menu
* Sky value::                   Definition of the sky value.
* Tiling an image::             Defining a mesh grid on the image.
* Sky value interpolation::     How blank grid elements are filled.
* Invoking astsubtractsky::     Options and arguments to SubtractSky.
@end menu

@node Sky value, Tiling an image, SubtractSky, SubtractSky
@subsection Sky value

@cindex Sky value
The discussion here is taken from Akhlaghi and Ichikawa
(2015)@footnote{See the section on sky in Akhlaghi M.,
Ichikawa. T. (2015). Astrophysical Journal Supplement Series.}. Let's
assume that all instrument defects -- bias, dark and flat -- have been
corrected and the total flux of a detected object, @mymath{O}, is
desired. The sources of flux on pixel @mymath{i}@footnote{For this
analysis the dimentionality of the data (image) is irrelevant. So if
the data is an image (2D) with width of @mymath{w} pixels, then a
pixel located on column @mymath{x} and row @mymath{y} (where all
counting starts from zero and (0, 0) is located on the bottom left
corner of the image), would have an index: @mymath{i=x+y\times{}w}.}
of the image can be written as follows:

@itemize
@item
Contribution from the target object, (@mymath{O_i}).
@item
Contribution from other detected objects, (@mymath{D_i}).
@item
Undetected objects or the fainter undetected regions of bright
objects, (@mymath{U_i}).
@item
@cindex Cosmic rays
A cosmic ray, (@mymath{C_i}).
@item
@cindex Background flux
The background flux, which is defined to be the count if none of the
others exists on that pixel, (@mymath{B_i}).
@end itemize
@noindent
The total flux in this pixel, @mymath{T_i}, can thus be written as:

@dispmath{T_i=B_i+D_i+U_i+C_i+O_i.}

@cindex Cosmic ray removal
@noindent
By definition, @mymath{D_i} is detected and it can be assumed that it
is correctly subtracted, so that @mymath{D_i} can be set to
zero. There are also methods to detect and remove cosmic rays (for
example, van Dokkum (2001)@footnote{van Dokkum,
P. G. (2001). Publications of the Astronomical Society of the Pacific.
113, 1420.}) enabling us to set @mymath{C_i=0}. Note that in practice,
@mymath{D_i} and @mymath{U_i} are correlated, because they both
directly depend on the detection algorithm and its input
parameters. Also note that no detection or cosmic ray removal
algorithm is perfect. With these limitations in mind, the observed sky
value for this pixel (@mymath{S_i}) can be defined as

@cindex Sky value
@dispmath{S_i=B_i+U_i.}

@noindent
Therefore, as the detection process (algorithm and input parameters)
becomes more accurate, or @mymath{U_i\to0}, the sky value will tend to
the background value or @mymath{S_i\to B_i}. Therefore, while
@mymath{B_i} is an inherent property of the data (pixel in an image),
@mymath{S_i} depends on the detection process. Over a group of pixels,
for example in an image or part of an image, this equation translates
to the average of undetected pixels.  With this definition of sky, the
object flux in the data can be calculated with

@dispmath{ T_{i}=S_{i}+O_{i} \quad\rightarrow\quad
           O_{i}=T_{i}-S_{i}.}

@noindent
@cindex photo-electrons
Hence, the more accurately @mymath{S_i} is measured, the more
accurately the flux of the target object can be measured
(photometry). Similarly, any under(over) estimation in the sky will
directly translate to an over(under) estimation of the measured
object's flux.  In the fainter outskirts of an object a very small
fraction of the photo-electrons in the pixels actually belong to
objects. Therefore even a small over estimation of the sky value will
result in the loss of a very large portion of most galaxies. Based on
the definition above, the sky value is only correctly found when all
the detected objects (@mymath{D_i} and @mymath{C_i}) have been removed
from the data.


@menu
* Finding the sky value::       How SubtractSky finds the sky value.
* Sky value misconceptions::    Sky value misconceptions and wrong approaches.
@end menu



@node Finding the sky value, Sky value misconceptions, Sky value, Sky value
@subsubsection Finding the sky value

@cindex Data
@cindex Distribution mode
@cindex Distribution mean
@cindex Distribution median
@cindex Mode of distribution
@cindex Mean of distribution
@cindex Median of distribution
This technique to find the sky value in a distribution was initially
proposed in Akhlaghi and Ichikawa 2015@footnote{Akhlaghi M.,
Ichikawa. T. (2015). Astrophysical Journal Supplement Series.}. When
we have absolutely no data and only noise in a dataset, the mean,
median and mode of the distribution are equal within statistical
errors and approximately equal to zero. Data always has a positive
value and will never become negative, see Figure 1 in Akhlaghi and
Ichikawa (2015). Therefore, as data is buried into the noise, all
three of these measures shift to the positive. The mean is the fastest
in this shift, since it is most reliant on the flux values. The median
is slower since it is defined based on an ordered distribution and so
is not affected by a small (less than half) number of
outliers. Finally, the mode is the slowest to shift to the positive.

@cindex Sky value
Inversing the argument above gives the basis of SubtractSky's
algorithm to find the sky value. Namely, when the mode and median of a
distribution are approximately equal, we can argue that there is no
significant data in the distribution. So we can consider the image to
be made of a grid and use this argument to `detect' data in each grid
element. When a grid element satisfies the condition above, we keep
its mean value. Recall that the sky was the mean of undetected
pixels. Any grid element that dosn't satisfy this condition is kept
with a blank value. Finally, when all the grid elements have been
checked, we can interpolate over all the empty elements and smooth the
final result to find the sky value over the full image. See @ref{Sky
value interpolation}.

Note that through the difference of the mode and median we have
actually `detected' data in the distribution. However this detection
was only based on the flux of the data, not its spatial position in
each mesh. So we adhere to the definition of Sky value in @ref{Sky
value}. Finding the median is very easy, the main problem is in
finding the mode through a robust method. In Appendix C of Akhlaghi
and Ichikawa (2015) a new approach to finding the mode in any
astronomically relevant distribution is introduced.


@node Sky value misconceptions,  , Finding the sky value, Sky value
@subsubsection Sky value misconceptions

As defined in @ref{Sky value}, the sky value is only accurately
defined when the detection algorithm is not significantly reliant on
the sky value. In particular its detection threshold. However, most
signal-based detection tools @footnote{According to Akhlaghi and
Ichikawa (2015), signal-based detection is a detection process that
realies heavily on assumptions about the to-be-detected objects. This
method was the most heavily used technique prior to the introduction
of NoiseChisel in that paper.} used the sky value as a reference to
define the detection threshold. So these old techniques had to rely on
approximations based on other assumptions about the data. A full
review of those other techniques can be seen in Appendix A of Akhlaghi
and Ichikawa (2015)@footnote{Akhlaghi M.,
Ichikawa. T. (2015). Astrophysical Journal Supplement Series.}. Since
they were extensively used in astronomical data analysis for several
decades, such approximations have given rise to a lot of
misconceptions and disagreements about the sky value and how to
measure it. As a summary, the major methods used until now were an
approximation of the mode of the image pixel distribution and
@mymath{\sigma}-clipping.

@itemize
@cindex Histogram
@cindex Distribution mode
@cindex Mode of a distribution
@cindex Probability density function
@item
To find the mode of a distribution those methods would either have to
assume (or find) a certain probablity density function (PDF) or use
the histogram. But the image pixels can have any distribution, and the
histogram results are very inaccurate (there is a large dispersion)
and depend on bin-widths.

@cindex @mymath{\sigma}-clipping
@item
Another approach was to iteratively clip the brightest pixels in the
image (which is known as @mymath{\sigma}-clipping, since the reference
was found from the image mean and its stadard deviation or
@mymath{\sigma}). The problem with @mymath{\sigma}-clipping was that
real astronomical objects have diffuse and faint wings that penetrate
deeply into the noise. So only removing their brightest parts is
completely useless in removing the systematic bias an object's fainter
parts cause in the sky value.
@end itemize

As discussed in @ref{Sky value}, the sky value can only be correctly
defined as the average of undetected pixels. Therefore all such
approaches that try to approximate the sky value prior to detection
are ultimately poor approximations.




@node Tiling an image, Sky value interpolation, Sky value, SubtractSky
@subsection Tiling an image

@cindex Grid
@cindex Tile
@cindex Gradient
@cindex Mesh grid
Some of the programs in Gnuastro will need to divide the pixels in an
image into individual tiles or a mesh grid to be able to deal with
gradients. In this section we will explain the concept in detail and
how the user can check the grid. In the case of SubtractSky, if the
image is completely uniform then one sky value will suffice for the
whole image. See @ref{Sky value} for the definition of the sky value.
Unfortunately though as discussed in @ref{SubtractSky}, in most images
taken with ground or space-based telescopes the sky value is not
uniform. So we have to break the image up into small tiles on a mesh
grid and find the sky value on those tiles.

Meshes are considered to be a square with a side of
@option{--meshsize} pixels. The best mesh size is directly related to
the gradient on the image. In practice we assume that the gradient is
not significant over each mesh. So if there is a strong gradient (for
example in long wavelength ground based images) or the image is of a
crowded area where there isn't too much blank area, you have to choose
a smaller mesh size. A larger mesh will give more pixels and so the
scatter in the results will be less.

@cindex CCD
@cindex Amplifier
@cindex Bias current
@cindex Subaru Telescope
@cindex Hyper Suprime-Cam
@cindex Hubble Space Telescope
For raw image processing, a simple mesh grid is not sufficient. Raw
images are the unprocessed outputs of the camera detectors. Large
detectors usually have multiple amplifiers, for example the Hubble
Space Telecope Advanced Camera for Surveys (ACS) has four amplifiers
over its full detector area dividing the square field of view to four
smaller squares. Ground based image detectors are not exempt, for
example each CCD of Subaru Telescope's gigantic Hyper Suprime-Cam
camera (which has 104 CCDs) has four amplifiers, but they have the
same height of the CCD and divide the width by four parts.

@cindex Channel
The bias current on each amplifier is different, and normaly bias
subtraction is not accurately done. So after subtracting the bias
current, you can clearly still identify the boundaries of different
amplifiers by eye. This results in the final reduced data to have
non-uniform amplifier-shaped regions with higher or lower background
flux values. Such systematic biases will then propagate to all
subsequent measurements we do on the data (for example photometry and
subsequent stellar mass and star formation rate measurements in the
case of galaxies). Therefore an accurate sky subtraction routine
should also be able to account for such biases.

To get an accurate result, the mesh boundaries should be located
exactly on the amplifier boundaries. Otherwise, the meshes which lie
over two amplifier regions are going to give very biased results and
the amplifier boundary will still be present after sky subtraction.
So in practice, we define `channel's. A channel is an independent mesh
grid that covers one amplifier to ensure that the meshes do not pass
the amplifier boundary. They are also used in subsequent steps as the
area used to identify nearby neighbours to interpolate, see @ref{Sky
value interpolation}. The number of channels along each axis can be
specified by the user at run time through @option{--nch1} and
@option{--nch2} or in the configuration files, see @ref{Configuration
files}. The area of each channel will then be tiled by meshes of the
given size and subsequent processing will be done on those meshes. If
the image is processed or the detector only has one amplifier, you can
set the number of channels in both axises to 1.

Unlike the channel size, that has to be an exact multiple of the image
size, the mesh size can be any number. If it is not an exact multiple
of the image side, the last (rightest, for the first FITS dimention,
and highest for the second when viewed in SAO ds9) mesh will have a
different size than the rest. If the remainder of the image size
divided by mesh size is larger than a certain fraction (value to
@option{--lastmeshfrac}) of the mesh size along each axis, a new
(smaller) mesh will be put there instead of a larger mesh. This is
done to avoid the last mesh becoming too large compared to the other
meshes in the grid. Generally, it is best practice to choose the mesh
size such that the last mesh is only a few (negligible) pixels wider
or thinner than the rest.

The final mesh grid can be seen on the image with the
@option{--checkmesh} option that is available to all programs which
use the mesh grid for localized operations. When this option is
called, a multi-extension FITS file with the input name and suffix
@file{_mesh.fits} will be created along with the usual run of the
program, see @ref{Automatic output}. The first extension will be the
input image. For each mesh grid the image produces, there will be a
subsequent extension. Each pixel in the grid extensions is labled to
the mesh that it is part of. You can flip through the extensions to
check the mesh sizes and locations compared to the input image.

@node Sky value interpolation, Invoking astsubtractsky, Tiling an image, SubtractSky
@subsection Sky value interpolation

As explained in @ref{Finding the sky value}, the sky value will not be
found over some of the grid elements. For example when a large galaxy
is present in the image, no sky value will be found for the grid
elements that lie over it. However, the sky value should be `guessed'
over that part of the image. We cannot just not subtract the sky value
from those regions! To fill in such blank grid elements, we use
interpolation. If the number of grid elements in the input image
becomes smaller than @option{--mininterp}, then SubtractSky will abort
and notify you.

@cindex Spline interpolation
@cindex Linear interpolation
@cindex Bicubic interpolation
@cindex Interpolation, spline
@cindex Interpolation, bicubic
@cindex Interpolation, bilinear
Parametric interpolations like bi-linear or bicubic or spline
interpolations are not used because they fail terribly on the edges of
the image. They are also prone to cause significant gradients in the
image. So to find the interpolated value for each grid element,
SubtractSky will look at a certain number of the nearest
neighbours. The exact number can be specified through
@option{--numnearest}. The median value of those grid elements will be
taken as the final value for the blank mesh. The median is chosen
because on the fainter wings of bright objects, the mean can easily
become biased.

Once all the grid elements are filled, the grid sky values should be
smoothed. This is because when the median is used, there will be
strong differences from one grid element to the next. By smoothing the
grid, the variation between grid element to grid element will be far
less and so the sky subtracted image will become much more uniform. To
smooth the image, SubtractSky uses an average filter. An average
filter is just a convolution of the grid (spatial convolution) by a
kernel will all elements having an equal weight, see @ref{Convolution
process}. The size of this kernel can be set through the
@option{--kernelwidth} option (which has to be an odd number as with
any kernel).



@node Invoking astsubtractsky,  , Sky value interpolation, SubtractSky
@subsection Invoking SubtractSky

SubtractSky will find the sky value on a grid in an image and subtract
it. The executable name is @file{astsubtractsky} with the following
general template:

@example
$ astsubtractsky [OPTION ...] Image
@end example

@noindent
One line examples:

@example
$ astsubtractsky processedimage.fits
$ astsubtractsky --nch1=2 --nch2=2 fromcamera.fits
@end example

@cindex Blank pixels
The only required input to SubtractSky is the input data file that
currently has to be only a 2D image. But in the future it might be
useful to use it for 1D or 3D data too. Any pixels in the image with a
blank value will be ignored in the analysis, see @ref{Blank
pixels}. Alternatively a mask can be specified which indicates pixels
to not be used (see @option{--mask} and @option{--mhdu}).

@table @option

@item -M
@itemx --mask
(@option{=STR}) Mask image file name. In case certain image pixels
should not be considered, you can define a mask image file name with
this option. Any pixel with a non-zero value in the specified mask
image will not be considered in the input image. It goes without
saying that the two images have to have the same size. If this option
is not given and the @option{--mhdu} option has a different value from
@option{--hdu}, then the input image name will be used. If a name is
specified on the command line or in any of the configuration files, it
will be used. If SubtractSky doesn't get any mask file name, it will
use all the non-NaN pixels in the image. Therefore, specifying a mask
file name in any of the configuration files is not mandatory.

Note that if the mask image has blank pixels, then they act like
pixels with non-zero values and will be masked (see @ref{Blank
pixels}).

@item -H
@itemx --mhdu
(@option{=STR}) The mask image header name or number. Similar to the
@option{--hdu} option, see @ref{Common options}. Note that while the
mask name is optional in the configuration files, the mask hdu is not
and must be specified in at least one of the configuration files.


@item -n
@itemx --numnearest
(@option{=INT}) The number of nearest grid elements with a successful
sky value to use for interpolating over blank grid elements (those
that had a significant contribution of flux), see @ref{Sky value
interpolation}.

@item -m
@itemx --mininterp
(@option{=INT}) The minimum number of grid elements with a sky
value. If the number of grid elements in the image becomes smaller
than this value, the program will abort.

@item -k
@itemx --kernelwidth
(@option{=INT}) The width of the average filter kernel used to smooth
the interpolated image. See @ref{Sky value interpolation}.

@item -s
@itemx --meshsize
(@option{=INT}) The size of each mesh, see @ref{Tiling an image}. If
the width of all channels are not an exact multiple of the specified
size, then the last mesh on each axis will have a different size to
cover the full channel.

@item -a
@itemx --nch1
(@option{=INT}) The number of channels along the first FITS axis
(horizontal when viewed in SAO ds9). If the length of the image is not
an exact multiple of this number, then SubtractSky will stop.

@item -b
@itemx --nch2
(@option{=INT}) The number of channels along the second FITS axis,
(horizontal when viewed in SAO ds9). Similar to @option{--nch1}.

@item -L
@itemx --lastmeshfrac
(@option{=FLT}) Fraction of extra area on the last (rightest on the
first FITS axis and highest/top on the second) mesh, to define a new
one. See @ref{Tiling an image}.

@item --checkmesh
An image with suffix @file{_mesh.fits} will be created for you to
check the mesh grid, see @ref{Tiling an image}. SubtractSky only uses
one mesh grid, so only one grid extension will be included in the
produced file.

@item -d
@itemx --mirrordist
(@option{=FLT}) The distance beyond the mirror point (in units of the
error in the mirror point) to check in finding the mode. See appendix
C in Akhlaghi and Ichikawa (2015) for a complete explanation of the
mode-finding algorithm. The value to this option is shown as
@mymath{\alpha} in that appendix.

@item -Q
@itemx --minmodeq
(@option{=FLT}) The minimum acceptable quantile for the mode of each
mesh.

@item -u
@itemx --sigclipmultip
(@option{=FLT}) The multiple of the standard devation to clip from the
distribution in @mymath{\sigma}-clipping. This is necessary to remove
the effect of cosmic rays.

@item -t
@itemx --sigcliptolerance
(@option{=FLT}) The tolerance of sigma clipping. If the fractional
change in the standard deviation before and after sigma clipping is
less than the value given to this option, @mymath{\sigma}-clipping
will stop.

@item --checkinterpolation
A two extension FITS image ending with @file{_interp.fits} will be
created which shows the average value on each mesh before
interpolation and after interpolation.

@item --checksmoothing
A two extension FITS image ending with @file{_smooth.fits} will be
created showing how the interpolated sky value is smoothed.

@end table









@node Image analysis, Modeling and fittings, Image manipulation, Top
@chapter Image analysis

Astronomical images contain very valuable information, the tools in
this section can help in extracting and quantifying that
information. For example calculating image statistics, or finding the
sky value or detecting objects within an image.

@menu
* ImageStatistics::             Calculate main image statistics.
@end menu

@node ImageStatistics,  , Image analysis, Image analysis
@section ImageStatistics

The distribution of pixel values in an image can give us valuable
information about the image, for example if it is a positively skewed
distribution, we can see that there is significant data in the
image. If the distribution is roughly symmetric, we can tell that
there is no significant data in the image.

On the other hand, in some measurements that we do on the image, we
might need to know the certain statistical parameters of the
image. For example, if we have run a detection algorithm on an image,
and we want to see how accurate it was, one method is to calculate the
average of the undetected pixels and see how reasonable it is (if
detection is done correctly, the average of undetected pixels should
be approximately equal to the background value, see @ref{Sky
value}). ImageStatistics is built for precisely such situatons.

@menu
* Invoking astimgstat::         Arguments and options to ImageStatistics
@end menu

@node Invoking astimgstat,  , ImageStatistics, ImageStatistics
@subsection Invoking ImageStatistics

ImageStatistics will print the major statistical measures of an
image's pixel flux distribution. The executable name is
@file{astimgstat} with the following general template

@example
$ astimgstat [OPTION ...] InputImage.fits
@end example

@noindent
One line examples:

@example
$ astimgstat input.fits
@end example

@noindent
If ImageStatistics is to run, an input image should be provided with
the recognized extensions as input data, see @ref{Arguments}.

















@node Modeling and fittings, Table manipulation, Image analysis, Top
@chapter Modeling and fitting

@cindex Fitting
@cindex Modeling
In order to fully understand observations after initial analysis on
the image, it is very important to compare them with the existing
models to be able to further understand both the models and the
data. The tools in this chapter create model galaxies and will provide
2D fittings to be able to understand the detections.

@menu
* MakeProfiles::                Making mock galaxies and stars.
* MakeNoise::                   Make (add) noise to an image.
@end menu




@node MakeProfiles, MakeNoise, Modeling and fittings, Modeling and fittings
@section MakeProfiles

@cindex Checking detection algorithms
@pindex @r{MakeProfiles @value{MKPROF_VERSION} (}astmkprof@r{)}
MakeProfiles will create mock astronomical profiles from a catalog,
either individually or together in one output image. In data analysis,
making a mock image can act like a calibration tool, through which you
can test how successfully your detection technique is able to detect a
known set of objects. There are commonly two aspects to detecting: the
detection of the fainter parts of bright objects (which in the case of
galaxies fade into the noise very slowly) or the complete detection of
an over-all faint object. Making mock galaxies is the most accurate
(and idealistic) way these two aspects of a detection algorithm can be
tested. You also need mock profiles in fitting known functional
profiles with observations.

MakeProfiles was initially built for extra galactic studies, so
currently the only astronomical objects it can produce are stars and
galaxies. We welcome the simulation of any other astronomical
object. The general outline of the steps that MakeProfiles takes are
the following:

@enumerate

@item
Build the full profile out to its truncation radius in a possibly
over-sampled array.

@item
Multiply all the elements by a fixed constant so its total magnitude
equals the desired total magnitude.

@item
If @option{--individual} is called, save the array for each profile to
a FITS file.

@item
If @option{--nomerged} is not called, add the overlapping pixels of
all the created profiles to the output image and abort.

@end enumerate

Using input values, MakeProfiles adds the World Coordinate System
(WCS) headers of the FITS standard to all its outputs (except PSF
images!). For a simple test on a set of mock galaxies in one image,
there is no need for the third step or the WCS information.

@cindex Transform image
@cindex Lensing simulations
@cindex Image transformations
However in complicated simulations like weak lensing simulations,
where each galaxy undergoes various types of individual
transformations based on their position, those transformations can be
applied to the different individual images with other programs. After
all the transformations are applied, using the WCS information in each
individual profile image, they can be merged into one output image for
convolution and adding noise.

@menu
* Modeling basics::             Astronomical modeling basics.
* If convolving afterwards::    Considerations for convolving later.
* Profile total magnitude::     Definition of total profile magnitude.
* Magnitude to flux conversion::  Converting magnitude to flux.
* Invoking astmkprof::          Inputs and Options for MakeProfiles.
@end menu



@node Modeling basics, If convolving afterwards, MakeProfiles, MakeProfiles
@subsection Modeling basics

In the subsections below, first a review of some very basic
information and concepts behind modeling a real astronomical image is
given. You can skip this subsection if you are already sufficiently
familiar with these concepts.

@menu
* Defining an ellipse::         Defining an ellipse in 2D.
* PSF::                         Radial profiles for the PSF.
* Stars::                       Making mock star profiles.
* Galaxies::                    Radial profiles for galaxies.
* Sampling from a function::    Sample a function on a pixelated canvas.
* Oversampling::                Oversampling the model.
@end menu

@node Defining an ellipse, PSF, Modeling basics, Modeling basics
@subsubsection Defining an ellipse

@cindex Ellipse
The PSF, see @ref{PSF}, and galaxy radial profiles are generally
defined on an ellipse so in this section first defining an ellipse on
a pixelated 2D surface is discussed. Labeling the major axis of an
ellipse @mymath{a}, and its minor axis with @mymath{b}, the axis ratio
is defined as: @mymath{q\equiv b/a}. The major axis of an ellipse can
be aligned in any direction, therefore define the angle of the major
axis to the horizontal axis of the image is defined to be the position
angle of the ellipse and in this manual, we show it with
@mymath{\theta}.

@cindex Radial profile on ellipse
Our aim is to put a radial profile of any functional form
@mymath{f(r)} over an ellipse. Let's define the radial distance
@mymath{r_{el}} as the distance on the major axis to the center of the
ellipse which is located at @mymath{x_c} and @mymath{y_c}. We want to
find the elliptical distance of a point located at @mymath{(i,j)}, in
the image coordinate system, from the center of the ellipse. First the
coordinate system is rotated by @mymath{\theta} to get the new rotated
coordinates of that point @mymath{(i_r,j_r)}:

@dispmath{i_r(i,j)=(i_c-i)\cos(\theta)+(j_c-j)\sin(\theta)}
@dispmath{j_r(i,j)=(j_c-j)\cos(\theta)-(i_c-i)\sin(\theta)}

@cindex Elliptical distance
@noindent The elliptical distance of a point located at @mymath{(i,j)}
can now be defined as: @mymath{r_{el}^2=\sqrt{i_r^2+j_r^2/q^2} }. To
place the radial profiles explained below over an ellipse,
@mymath{f(r_{el}(i,j))} is calculated based on the functional radial
profile desired.

@cindex Breadth first search
@cindex Inside-out construction
@cindex Making profiles pixel by pixel
@cindex Pixel by pixel making of profiles
The way MakeProfiles builds the profile is that the nearest pixel in the
image to the given profile center is found and the profile value is
calculated for it, see @ref{Sampling from a function}. The next pixel
which the profile value is calculated on is the next nearest neighbor
of the initial pixel to the profile center (as defined by
@mymath{r_{el}}). This is done fairly efficiently using a breadth
first parsing
strategy@footnote{@url{http://en.wikipedia.org/wiki/Breadth-first_search}}
which is implemented through an ordered linked list.

Using this approach, we only go over one layer of pixels on the
circumference of the profile to build the profile. Not one more extra
pixel has to be checked. Another consequence of this strategy is that
extending MakeProfiles to three dimensions becomes very simple: only
the neighbors of each pixel have to be changed. Everything else after
that (when the pixel index and its radial profile have entered the
linked list) is the same, no matter the number of dimensions we are
dealing with.



@node PSF, Stars, Defining an ellipse, Modeling basics
@subsubsection Point Spread function

@cindex PSF
@cindex Point source
@cindex Diffraction limited
@cindex Point Spread Function
@cindex Spread of a point source
Assume we have a `point' source, or a source that is far smaller
than the maxium resolution (a pixel). When we take an image of it, it
will `spread' over an area. To quantify that spread, we can define a
`function'. This is how the point spread function or the PSF of an
image is defined. This `spread' can have various causes, for example
in ground based astronomy, due to the atmosphere. In practice we can
never surpass the `spread' due to the diffraction of the lens
aperture. Various other effects can also be quantified through a PSF.
For example, the simple fact that we are sampling in a discrete space,
namely the pixels, also produces a very small `spread' in the image.

@cindex Blur image
@cindex Convolution
@cindex Image blurring
@cindex PSF image size
Convolution is the mathematical process by which we can apply a
`spread' to an image, or in other words blur the image. The total
flux of an object should remain unchanged after
convolution. Therefore, it is important that the sum of all the pixels
of the PSF be unity. The image also has to have an odd number of
pixels on its sides so one pixel can be defined as the center. In
MakeProfiles, the PSF can be set by the two methods explained below.

@table @asis

@item Parametric functions
@cindex FWHM
@cindex PSF width
@cindex Parametric PSFs
@cindex Full Width at Half Maximum
A known mathematical function is used to make the PSF. In this case,
only the parameters to define the functions are necessary and
MakeProfiles will make a PSF based on the given parameters for each
function. In both cases, the center of the profile has to be exactly
in the middle of the central pixel of the PSF (which is automatically
done by MakeProfiles). When talking about the PSF, usually, the full
width at half maximum or FWHM is used as a scale of the width of the
PSF.

@table @cite
@item Gaussian
@cindex Gaussian distribution
In the older papers, and to a lesser extent even today, some
researchers use the 2D Gaussian function to approximate the PSF of
ground based images. In its most general form, a Gaussian function can
be written as:

@dispmath{f(r)=a \exp \left( -(x-\mu)^2 \over 2\sigma^2 \right)+d}

Since the center of the profile is pre-defined, @mymath{\mu} and
@mymath{d} are constrained. @mymath{a} can also be found because the
function has to be normalized. So the only important parameter for
MakeProfiles is the @mymath{\sigma}. In the Gaussian function we have
this relation between the FWHM and @mymath{\sigma}:

@cindex Gaussian FWHM
@dispmath{\rm{FWHM}_g=2\sqrt{2\ln{2}}\sigma \approx 2.35482\sigma}

@item Moffat
@cindex Moffat function
The Gaussian profile is much sharper than the images taken from stars
on photographic plates or CCDs. Therefore in 1969, Moffat proposed
this functional form for the image of stars:

@dispmath{f(r)=a \left[ 1+\left( r\over \alpha \right)^2 \right]^{-\beta}}

@cindex Moffat beta
Again, @mymath{a} is constrained by the normalization, therefore two
parameters define the shape of the Moffat function: @mymath{\alpha} and
@mymath{\beta}. The radial parameter is @mymath{\alpha} which is related
to the FWHM by

@cindex Moffat FWHM
@dispmath{\rm{FWHM}_m=2\alpha\sqrt{2^{1/\beta}-1}}

@cindex Compare Moffat and Gaussian
@cindex PSF, Moffat compared Gaussian
@noindent
Comparing with the PSF predicted from atmospheric turbulence theory
with a Moffat function, Trujillo et al.@footnote{Trujillo, I.,
J. A. L. Aguerri, J. Cepa, and C. M. Gutierrez (2001). ``The effects
of seeing on S@'ersic profiles - II. The Moffat PSF''. In: MNRAS 328,
pp. 977---985.} claim that @mymath{\beta} should be 4.765. They also
show how the Moffat PSF contains the Gaussian PSF as a limiting case
when @mymath{\beta\to\infty}.

@end table

@item An input FITS image
An input image file can also be specified to be used as a PSF. If the
sum of its pixels are not equal to 1, the pixels will be multiplied
by a fraction so the sum does become 1.
@end table


While the Gaussian is only dependent on the FWHM, the Moffat function
is also dependent on @mymath{\beta}. Comparing these two functions
with a fixed FWHM gives the following results:

@itemize
@item
Within the FWHM, the functions don't have significant differences.
@item
For a fixed FWHM, as @mymath{\beta} increases, the Moffat function
becomes sharper.
@item
The Gaussian function is much sharper than the Moffat functions, even
when @mymath{\beta} is large.
@end itemize




@node Stars, Galaxies, PSF, Modeling basics
@subsubsection Stars

@cindex Modeling stars
@cindex Stars, modeling
In MakeProfiles, stars are generally considered to be a point
source. This is usually the case for extra galactic studies, were
nearby stars are also in the field. Since a star is only a point
source, we assume that it only fills one pixel prior to
convolution. In fact, exactly for this reason, in astronomical images
the light profiles of stars are one of the best methods to understand
the shape of the PSF and a very large fraction of scientific research
is preformed by assuming the shapes of stars to be the PSF of the
image.





@node Galaxies, Sampling from a function, Stars, Modeling basics
@subsubsection Galaxies

@cindex Galaxy profiles
@cindex S@'ersic profile
@cindex Profiles, galaxies
@cindex Generalized de Vaucouleur profile
Today, most practitioners agree that galaxy profiles can be modeled
with one or a few generalized de Vaucouleur's (or S@'ersic) profiles.

@dispmath{I(r) = I_e exp \left ( -b_n \left[ \left( r \over r_e \right)^{1/n} -1 \right] \right )}

@cindex S@'ersic, J. L.
@cindex S@'ersic index
@cindex de Vaucouleur profile
@cindex G@'erard de Vaucouleurs
G@'erard de Vaucouleurs (1918-1995) was first to show in 1948 that
this function best fits the galaxy light profiles, with the only
difference that he held @mymath{n} fixed to a value of 4. 20 years
later in 1968, J. L. S@'ersic showed that @mymath{n} can have a
variety of values and does not necessarily need to be 4.

@cindex Effective radius
@cindex Radius, effective
@cindex Total profile flux
This profile depends on the effective radius (@mymath{r_e}) which is
defined as the radius which contains half of the total brightness of
the object. The total profile flux is defined as the integration of
the profile to infinity. @mymath{I_e} is the surface brightness at the
effective radius.  The S@'ersic index @mymath{n} is used to define the
concentration of the profile within @mymath{r_e} and @mymath{b_n} is a
constant dependent on @mymath{n}. MacArthur et al.@footnote{MacArthur,
L. A., S. Courteau, and J. A. Holtzman (2003). ``Structure of
Disk-dominated Galaxies. I. Bulge/Disk Parameters, Simulations, and
Secular Evolution''. In: ApJ 582, pp. 689---722.} show that for
@mymath{n>0.35}, @mymath{b_n} can be accurately approximated using
this equation:

@dispmath{b_n=2n - {1\over 3} + {4\over 405n} + {46\over 25515n^2} + {131\over 1148175n^3}-{2194697\over 30690717750n^4}}





@node Sampling from a function, Oversampling, Galaxies, Modeling basics
@subsubsection Sampling from a function

@cindex Sampling
A pixel is the ultimate level of accuracy to gather data, we can't get
any more accurate in one image, this is known as sampling in signal
processing. However, the mathematical profiles which describe our
models have infinite accuracy. Over a large fraction of the area of
astrophysically interesting profiles (for example galaxies or PSFs),
the variation of the profile over the area of one pixel is not too
significant. In such cases, the elliptical radius (@mymath{r_{el}} of
the center of the pixel can be assigned as the final value of the
pixel, see @ref{Defining an ellipse}).

@cindex Integration over pixel
@cindex Gradient over pixel area
@cindex Function gradient over pixel area
As you approach their center, some galaxies become very sharp (their
value significantly changes over one pixel's area). This sharpness
increases with smaller effective radius and larger S@'ersic values.
Thus rendering the central value extremely inaccurate. The first
method that comes to mind for solving this problem is integration. The
functional form of the profile can be integrated over the pixel area
in a 2D integration process. However, unfortunately numerical
integration techniques also have their limitations and when such sharp
profiles are needed they can become extremely inaccurate.

@cindex Monte carlo integration
The most accurate method of sampling a continuous profile on a
discrete space is by choosing a large number of random points within
the boundaries of the pixel and taking their average value (or Monte
Carlo integration). This is also, generally speaking, what happens in
practice with the photons on the pixel. The number of random points
can be set with @option{--numrandom}.

Unfortunately, repeating this Monte Carlo process would be extremely
time and CPU consuming if it is to be applied to every pixel. In order
to not lose too much accuracy, in MakeProfiles, the profile is built
using both methods explained above. The building of the profile begins
from its central pixel and continues outwards. Monte Carlo integration
is first applied (which yields @mymath{F_r}), then the central pixel
value (@mymath{F_c}) on the same pixel. If the fractional difference
(@mymath{|F_r-F_c|/F_r}) is lower than a given tolerance level we will
stop using Monte Carlo integration and only use the central pixel
value.

@cindex Inside-out construction
The ordering of the pixels in this inside-out construction is based on
@mymath{r=\sqrt{(i_c-i)^2+(j_c-j)^2}}, not @mymath{r_{el}}, see
@ref{Defining an ellipse}. When the axis ratios are large (near one)
this is fine. But when they are small and the object is highly
elliptical, it might seem more reasonable to follow @mymath{r_{el}}
not @mymath{r}. The problem is that the gradient is stronger in pixels
with smaller @mymath{r} (and larger @mymath{r_{el}}) than those with
smaller @mymath{r_{el}}. In other words, the gradient is strongest
along the minor axis. So if the next pixel is chosen based on
@mymath{r_{el}}, the tolerance level will be reached sooner and lots
of pixels with large fractional differences will be missed.






@node Oversampling,  , Sampling from a function, Modeling basics
@subsubsection Oversampling

@cindex Oversampling
The steps explained in @ref{Sampling from a function} do give an
accurate representation of a profile prior to convolution. However, in
an actual observation, the image is first convolved with or blurred by
the atmospheric and instrument PSF in a continuous space and then it
is sampled on the discrete pixels of the camera.

@cindex PSF over-sample
In order to more accurately simulate this process, the unconvolved
image and the PSF are created on a finer pixel grid. In other words,
the output image is a certain odd-integer multiple of the desired
size, we can call this `oversampling'. The user can specify this
multiple as a command line option. The reason this has to be an odd
number is that the PSF has to be centered on the center of its
image. An image with an even number of pixels on each side does not
have a central pixel.

The image can then be convolved with the PSF (which should also be
oversampled on the same scale). Finally, image can be sub-sampled to
get to the initial desired pixel size of the output image. After this,
mock noise can be added as explained in the next section. This is
because unlike the PSF, the noise occurs in each output pixel, not on
a continuous space like all the prior steps.




@node If convolving afterwards, Profile total magnitude, Modeling basics, MakeProfiles
@subsection If convolving afterwards

In case you want to convolve the image later with a given point spread
function, make sure to use a larger image size. After convolution, the
profiles become larger and a profile that is normally completely
outside of the image might fall within it.

On one axis, if you want your final (convolved) image to be @mymath{m}
pixels and your PSF is @mymath{2n+1} pixels wide, then when calling
MakeProfiles, set the axis size to @mymath{m+2n}, not @mymath{m}. You
also have to shift all the pixel positions of the profile centers on
the that axis by @mymath{n} pixels to the positive.

After convolution, you can crop the outer @mymath{n} pixels with the
section crop box specification of ImageCrop:
@option{--section=n:*-n,n:*-n} assuming your PSF is a square, see
@ref{Crop section syntax}. This will also remove all discrete Fourier
transform artifacts (blurred sides) from the final image. To
facilitate this shift, MakeProfiles has the options @option{--xshift},
@option{--yshift} and @option{--prepforconv}, see @ref{Invoking
astmkprof}.


@node Profile total magnitude, Magnitude to flux conversion, If convolving afterwards, MakeProfiles
@subsection Profile total magnitude

@cindex Truncation radius
@cindex Total profile flux
@cindex Sum for total flux
It is customary to use the 2D integration to infinity of a profile as
its total magnitude. However, in MakeProfiles, we do not follow this
idealistic approach and apply a more realistic method to find the
total magnitude: the sum of all the pixels belonging to a profile
within its predefined truncation radius. Note that if the truncation
radius is not large enough, this can be significantly different from
the total integrated light to infinity.

@cindex Integration to infinity
An integration to infinity is not a realistic condition because no
galaxy extends indefinitely (important for high S@'ersic index
profiles), pixelation can also cause a significant difference between
the actual total pixel sum value of the profile and that of
integration to infinity, especially in small and high S@'ersic index
profiles. To be safe, you can specify a large enough truncation radius
for such compact high S@'ersic index profiles.

If oversampling is used then the total flux is calculated using the
over-sampled image, see @ref{Oversampling} which is much more
accurate. The profile is first built in an array completely bounding
it with a normalization constant of unity. Taking @mymath{F} to be the
desired total flux and @mymath{S} to be the sum of the pixels in the
created profile, every pixel is then multiplied by @mymath{F/S} so the
sum is exactly @mymath{F}.

If the @option{--individual} option is called, this same array is
written to a FITS file. If not, only the overlapping pixels of this
array and the output image are kept and added to the output array.


@node Magnitude to flux conversion, Invoking astmkprof, Profile total magnitude, MakeProfiles
@subsection Magnitude to flux conversion

@cindex Magnitude zero-point
@cindex Magnitudes from flux
@cindex Flux to magnitude conversion
@cindex Astronomical Magnitude system
The total brightness of the object is not specified in units of flux,
but in magnitudes. The magnitude scale is a relative measure of
brightness. When a reference object has magnitude @mymath{m_r} with
flux @mymath{F_r}, then the magnitude of an object with a flux of
@mymath{F} is calculated by:

@dispmath{m-m_r=-2.5\log_{10} \left( F \over F_r \right)}

@cindex Zero-point magnitude
The @emph{zero-point} magnitude (@mymath{m_z}) is defined as the
magnitude in which @mymath{F_r=1}. So when you specify the magnitude
of your desired object in the @option{--mcol} of your input catalog,
then it will have a total flux of:

@dispmath{\log_{10}F={m_z-m \over 2.5} \rightarrow
          F=10^{m_z-m \over 2.5}}


@node Invoking astmkprof,  , Magnitude to flux conversion, MakeProfiles
@subsection Invoking MakeProfiles

MakeProfiles will make any number of profiles specified in a catalog
either individually or in one image. The executable name is
@file{astmkprof} with the following general template

@example
$ astmkprof [OPTION ...] [BackgroundImage] Catalog
@end example

@noindent
One line examples:

@example
$ astmkprof background.fits catalog.txt
$ astmkprof --xcol=0 --ycol=1 catalog.txt
$ astmkprof --individual --oversample 3 -x500 -y500 catalog.txt
@end example

@noindent
If mock galaxies are to be made, the catalog (which stores the
parameters for each mock profile) is the mandatory argument. The input
catalog has to be a text file formatted in a table with columns
separated by space, tab or comma (@key{,}) characters. See @ref{Common
behavior} for a complete explanation of some common behaviour and
options in all Gnuastro programs including MakeProfiles.

If a data image file (see @ref{Arguments}) is given, that image is
used as the background. The flux value of each profile pixel will be
added to the pixel in that background value. In this case the values
to all options relating to the output size and WCS will be ignored if
specified (for example @option{--naxis1}, @option{--naxis2} and
@option{--prepforconv}) on the command line or in the configuration
files. The profiles will be made on the background image (their values
will be added to the background image pixels). Note that
@option{--oversample} will remain active even if a background image is
specified.

@menu
* MakeProfiles catalog::        Required catalog properties.
* MakeProfiles options::        Full list of MakeProfiles options.
* MakeProfiles output::         The generated outputs.
@end menu

@node MakeProfiles catalog, MakeProfiles options, Invoking astmkprof, Invoking astmkprof
@subsubsection MakeProfiles catalog
The catalog is a text file table. Its columns can be ordered in any
desired manner, you can specify which columns belong to which
parameters using the set of options ending with @option{col}, for
example @option{--xcol} or @option{--rcol}, see @ref{MakeProfiles
options}.

The value for the profile center in the catalog (in the
@option{--xcol} and @option{--ycol} columns) can be a floating point
number so the profile center can be on any sub-pixel position. Note
that pixel positions in the FITS standard start from 1 and an integer
is the pixel center. So a 2D image actually starts from the position
(0.5, 0.5). In MakeProfiles profile centers do not have to be in the
image.  Even if only one pixel of the profile within the truncation
radius is within the output image, that pixel is included in the
image. Profiles that are completely out of the image will not be
created. You can use the output log file to see which profiles were
within the image.

If PSF profiles (Moffat or Gaussian) are in the catalog and the
profiles are to be built in one image (when @option{--individual} is
not used), it is assumed they are the PSF(s) you want to convolve your
created image with. So by default, they will not be built in the
output image but as separate files. The total flux of these separate
files will also be set to unity (1) so you are ready to convolve. As a
summary, their position and magnitude will be ignored. This behaviour
can be disabled with the @option{--psfinimg} option. If you want to
create all the profiles separately (with @option{--individual}) and
you want the total flux of your PSF profiles to be unity, you have to
set their magnitudes in the catalog to the zero-point magnitude and be
sure that the central positions of the profiles don't have any
fractional part (the PSF center has to be in the center of the pixel).


@node MakeProfiles options, MakeProfiles output, MakeProfiles catalog, Invoking astmkprof
@subsubsection MakeProfiles options
The common options that are shared by Gnuastro programs, are fully
explained in @ref{Common options} and are not repeated here. Since
there are no image inputs, the@option{--hdu} option is ignored. The
options can be classified into the following categories: Output,
Profiles, Catalog and WCS. Below each one is reviewed.

@noindent
Output:

@table @option

@item -x
@itemx --naxis1
(@option{=INT}) The number of pixels in the output image along the
first FITS axis (horizontal when viewed in SAO ds9). This is before
over-sampling. For example if you call MakeProfiles with
@option{--naxis1=100 --oversample=5} (assuming no shift due for later
convolution), then the final image size along the first axis will be
500. If a background image is specified, any possible value to this
option is ignored.

@item -y
@itemx --naxis2
(@option{=INT}) The number of pixels in the output image along the
second FITS axis (vertical when viewed in SAO ds9), see the
explanation for @option{--naxis1}.

@item -s
@itemx --oversample
(@option{=INT}) The scale to over-sample the profiles and final
image. If not an odd number, will be added by one, see
@ref{Oversampling}. Note that this @option{--oversample} will remain
active even if an input image is specified. If your input catalog is
based on the background image, be sure to set @option{--oversample=1}.

@item --psfinimg
Build the possibly existing PSF profiles (Moffat or Gaussian) in the
catalog into the final image. By default they are built separately so
you can convolve your images with them, thus their magnitude and
positions are ignored. With this option, they will be built in the
final image like every other galaxy profile. To have a final PSF in
your image, make a point profile where you want the PSF and after
convolution it will be the PSF.

@item -i
@itemx --individual

@cindex Individual profiles
@cindex Build individual profiles
If this option is called, each profile is created in a separate FITS
image named with the row number of the profile in the catalog. In this
case, only the sub-pixel position of the profile center is
important.

The output will have an odd number of pixels. If there is no
oversampling, the central pixel will contain the profile center. If
the value to @option{--oversample} is larger than unity, then the
profile center is on any of the central @option{--oversample}'d pixels
depending on the fractional value of the profile center.

If the fractional value is larger than half, it is on the bottom half
of the central region. This is due to the FITS definition of a real
number position: The center of a pixel has fractional value
@mymath{0.00} so each pixel contains these fractions: .5 -- .75 -- .00
(pixel center) -- .25 -- .5.

@item -m
@itemx --nomerged
Don't make a merged image. By default after making the profiles, they
are added to a final image with sides of @option{--naxis1} and
@option{--naxis2} if they overlap with it.

@end table

@noindent
Profiles:

@table @option

@item -r
@itemx --numrandom
The number of random points used in the central regions of the
profile, see @ref{Sampling from a function}.

@item -t
@itemx --tolerance
(@option{=FLT}) The tolerance to switch from Monte Carlo integration
to the central pixel value, see @ref{Sampling from a function}.

@item -p
@itemx --tunitinp
The truncation column of the catalog is in units of pixels. By
default, the truncation column is considered to be in units of the
radial parameters of the profile (@option{--rcol}). Read it as
`t-unit-in-p' for `truncation unit in pixels'.

@item -X
@itemx --xshift
(@option{=INT}) Shift all the profiles and enlarge the image along the
first FITS axis, see @mymath{n} in @ref{If convolving
afterwards}. This is useful when you want to convolve the image
afterwards. If you are using an external PSF, be sure to oversample it
to the same scale used for creating the mock images. If a background
image is specified, any possible value to this option is ignored.

@item -Y
@itemx --yshift
(@option{=INT}) Similar to @option{--xshift} for the second FITS axis.

@item -c
@itemx --prepforconv
Shift all the profiles and enlarge the image based on half the width
of the first Moffat or Gaussian profile in the catalog, considering
any possible oversampling see @ref{If convolving
afterwards}. @option{--prepforconv} is only checked and possibly
activated if @option{--xshift} and @option{--yshift} are both zero
(after reading the command line and configuration files). If a
background image is specified, any possible value to this option is
ignored.

@item -M
@itemx --setconsttomin
For profiles that have a constant value (no variation from pixel to
pixel), set the constant value to the minimum value in the image. This
is very useful if the profiles with constant value are to be used as
masks. When displaying the images in a document (and inverting the
images as is automatically done in ConvertType), the masked pixels
will become white.

@item -R
@itemx --replace
Do not add pixel values to each other, replace them. By default, when
two profiles overlap, the final pixel value is the sum of all the
profiles that overlap on that pixel. When this option is given, the
pixels are not added but replaced by newer profiles.

@cindex CPU threads
@cindex Threads, CPU
When order does matter, make sure to use this function with
@option{--numthreads=1}. When multiple threads are used, the separate
profiles are built asynchronously and not in order. Since order does
not matter in an addition, this causes no problems by default but has
to be considered when this option is given. Using multiple threads is
no problem if the profiles are to be used as a mask (with
@option{--setconsttomin}) since all their pixel values are the same.

@item -w
@itemx --circumwidth
(@option{=FLT})

@item -z
@itemx --zeropoint
(@option{=FLT}) The zero-point magnitude of the image.

@end table

@noindent
Catalog: The value to all of these options is considered to be a
column number, where counting starts from zero.

@table @option

@item --fcol
(@option{=INT}) The functional form of the profile with one of the
values below. Note that this value will be converted to an integer
before analysis using the internal type conversion of C. So for
example 2.80 will be converted to 2.

@itemize
@item
0: S@'ersic.
@item
1: Moffat.
@item
2: Gaussian.
@item
3: Point source (a star).
@item
4: Flat profile: all pixels have same value.
@item
5: Circumference: same value for all pixels between the truncation
radius (@mymath{r_t}) and @mymath{r_t-w} where @mymath{w} is the value
to the @option{--circumwidth}. Currently this is only intended to be
used for making an elliptical annulus (with a width of 1 or 2 pixels).
@end itemize

@item --xcol
(@option{=INT}) The center of the profiles along the first FITS axis
(horizontal when viewed in SAO ds9).

@item --ycol
(@option{=INT}) The center of the profiles along the second FITS axis
(vertical when viewed in SAO ds9).

@item --rcol
(@option{=INT}) The radius parameter of the profiles. Effective radius
(@mymath{r_e}) if S@'ersic, FWHM if Moffat or Gaussian.

@item --ncol
(@option{=INT}) The S@'ersic index (@mymath{n}) or Moffat
@mymath{\beta}.

@item --pcol
(@option{=INT}) The position angle (in degrees) of the profiles
relative to the first FITS axis (horizontal when viewed in SAO ds9).

@item --qcol
(@option{=INT}) The axis ratio of the profiles (minor axis divided by
the major axis).

@item --mcol
(@option{=INT}) The total pixelated magnitude of the profile within the
truncation radius, see @ref{Profile total magnitude}.

@item --tcol
(@option{=INT}) The truncation radius of this profile. By default it
is in units of the radial parameter of the profile (the value in the
@option{--rcol} of the catalog). If @option{--tunitinp} is given, this
value is interpreted in units of pixels (prior to oversampling)
irrespective of the profile.

@end table

@noindent
WCS:

@table @option

@item --crpix1
(@option{=FLT}) The pixel coordinates of the WCS reference point on
the first (horizontal) FITS axis (counting from 1).

@item --crpix2
(@option{=FLT}) The pixel coordinates of the WCS reference point on
the second (vertical) FITS axis (counting from 1).

@item --crval1
(@option{=FLT}) The Right Ascension (RA) of the reference point.

@item --crval2
(@option{=FLT}) The Declination of the reference point.

@item --resolution
(@option{=FLT}) The resolution of the non-oversampled image in units
of arcseconds/pixel.

@end table

@node MakeProfiles output,  , MakeProfiles options, Invoking astmkprof
@subsubsection MakeProfiles output

Besides the final merged image of all the profiles or individual
profiles that can be built based on the input options, MakeProfiles
will also create a log file in the current directory (where you run
MockProfiles). The values for each column are explained in the first
few commented (starting with @command{#} character). The log file
includes the following information:

@itemize
@item
The total magnitude of the profile in the image. This will be
different from your input magnitude if the profile was not completely
in the image.

@item
The number of pixels (in the oversampled image) which used Monte Carlo
integration and not the central pixel value.

@item
The fraction of flux in the Monte Carlo integrated pixels.

@item
If an individual image was created or not.
@end itemize












@node MakeNoise,  , MakeProfiles, Modeling and fittings
@section MakeNoise

@cindex Noise
Real data are always burried in noise, therefore to finalize a
simulation of real data (for example to test our observational
algorithms) it is essential to add noise to the mock profiles created
with MakeProfiles, see @ref{MakeProfiles}. Below, the general
principles and concepts to help understand how noise is quantified is
discussed.  MakeNoise options and argument are then discussed in
@ref{Invoking astmknoise}.

@menu
* Noise basics::                Noise concepts and definitions.
* Invoking astmknoise::         Options and arguments to MakeNoise.
@end menu



@node Noise basics, Invoking astmknoise, MakeNoise, MakeNoise
@subsection Noise basics

@cindex Noise
@cindex Image noise
Deep astronomical images, like those used in extragalactic studies
seriously suffer from noise in the data. Generally speaking, the
sources of noise in an astronomical image are photon counting noise
and Instrumental noise which are discussed in detail below. We finish
with a short introduction on how random numbers are generated and how
you can determine the random number generator and seed value.

@menu
* Photon counting noise::       Poisson noise
* Instrumental noise::          Readout, dark current and other sources.
* Final noised pixel value::    How the final noised value is calculated.
* Generating random numbers::   How random numbers are generated.
@end menu

@node Photon counting noise, Instrumental noise, Noise basics, Noise basics
@subsubsection Photon counting noise

@cindex Counting error
@cindex Photon counting noise
Thanks to the very accurate electronics used in today's detectors,
this type of noise is the main cause of concern for extra galactic
studies.  It can generally be associate with the counting error that
is known to have a Poisson distribution. The Poisson distribution is
about counting. But counting is a discrete operation with only
positive values, for example we can't count @mymath{3.2} or
@mymath{-2} of anything. We only count @mymath{0}, @mymath{1},
@mymath{2}, @mymath{3} and so on. Therefore the Poisson distribution
is also a discrete distribution, only applying to whole positive
integers.

Let's assume the mean value of counting something is known. In this
case, the number of electrons that are produced by photons in the
CCD. Let's call this mean @mymath{\lambda}.  Let's take @mymath{k} to
represent the result of counting in one particular time we attempt to
count. The probability density function of @mymath{k} can be written
as:

@cindex Poisson distribution
@dispmath{f(k)={\lambda^k \over k!} e^{-\lambda},\quad k\in \{0, 1, 2,
3, \dots \}}

@cindex Skewed Poisson distribution
Because the Poisson distribution is only applicable to positive
values, it is by nature very skewed when @mymath{\lambda} is near
zero. One qualitative way to imagine it is that there simply aren't
enough integers smaller than @mymath{\lambda}, than there are larger
integers. Therefore to accommodate all possibilities, it has to be
skewed when @mymath{\lambda} is small.

@cindex Compare Poisson and Gaussian
But as @mymath{\lambda} becomes larger and larger, the distribution
becomes more and more symmetric. One very useful property of the
Poisson distribution is that the mean value is also its variance.
When @mymath{\lambda} is very large, say @mymath{\lambda>1000}, then
the normal (Gaussian) distribution, see @ref{PSF}, is an excellent
approximation of the Poisson distribution with mean
@mymath{\mu=\lambda} and standard deviation
@mymath{\sigma=\sqrt{\lambda}}.

We see that the variance or dispersion of the distribution depends on
the mean value, and when it is large it can be approximated with a
Gaussian that only has one free parameter (@mymath{\mu=\lambda} and
@mymath{\sigma=\sqrt{\lambda}}) instead of two that it originally has.

@cindex Sky value
@cindex Background flux
@cindex Undetected objects
The astronomical objects after convolution with the PSF of the
instrument, lie above a certain background flux. This background flux
is defined to be the average flux of a region in the image that has
absolutely no objects. The physical origin of this background value is
the brightness of the atmosphere or possible stray light within the
imagining instrument. It is thus an ideal definition, because in
practice, what lies deep in the noise far lower than the detection
limit is never known@footnote{See the section on sky in Akhlaghi M.,
Ichikawa. T. 2015. Astrophysical Journal Supplement Series.}. However,
in a real image, a relatively large number of very faint objects can
been fully buried in the noise. These undetected objects will bias the
background measurement to slightly larger values. The sky value is
therefore defined to be the average of the undetected regions in the
image, so in an ideal case where all the objects have been detected,
the sky value and background value are the same.

@cindex Background flux gradients
@cindex Gradients in background flux
@cindex Variation of background flux
As longer wavelengths are used, the background value becomes more
significant and also varies over a wide image field. Such variations
are not currently implemented in MakeProfiles, but will be in the
future. In a mock image, we have the luxury of setting the background
value.

@cindex Simulating noise
@cindex Noise simulation
In each pixel of the canvas of pixels the flux is the sum of
contributions from various sources after convolution. Let's name this
flux of the convolved sum of possibly overlapping objects,
@mymath{I_{nn}}.  @mymath{nn} representing `no noise'. For now,
let's assume the background is constant and represented by
@mymath{B}. In practice the background values are larger than
@mymath{\sim1,000} counts. Then the flux after adding noise is a
random value taken from a Gaussian distribution with the following
mean (@mymath{\mu}) and standard deviation (@mymath{\sigma}):

@dispmath{\mu=B+I_{nn}, \quad \sigma=\sqrt{B+I_{nn}}}

Since this type of noise is inherent in the objects we study, it is
usually measured on the same scale as the astronomical objects, namely
the magnitude system, see @ref{Magnitude to flux conversion}. It is
then internally converted to the flux scale for further processing.

@node Instrumental noise, Final noised pixel value, Photon counting noise, Noise basics
@subsubsection Instrumental noise

@cindex Readout noise
@cindex Instrumental noise
@cindex Noise, instrumental
While taking images with a camera, a dark current is fed to the
pixels, the variation of the value of this dark current over the
pixels, also adds to the final image noise. Another source of noise is
the readout noise that is produced by the electronics in the CCD that
attempt to read the amount of flux that was recorded. In deep
extra-galactic studies these sources of noise are not as significant
as the noise of the background sky. Let @mymath{C} represent the
combined standard deviation of all these sources of noise. If only
this source of noise is present, the noised pixel value would be a
random value chosen from a Gaussian distribution with

@dispmath{\mu=I_{nn}, \quad \sigma=\sqrt{C^2+I_{nn}}}

This type of noise is completley independent of the type of objects
being studied, it is completely determined by the instrument. So the
flux scale (and not magnitude scale) is most commonly used for this
type of noise. In practice, this value is usually reported in ADUs not
flux or electron counts. The gain value of the device can be used to
convert between these two.

@node Final noised pixel value, Generating random numbers, Instrumental noise, Noise basics
@subsubsection Final noised pixel value
Depending on the values you specify for @mymath{B} and @mymath{C} from
the above, the final noised value for each pixel is a random value
chosen from a Gaussian distribution with

@dispmath{\mu=B+I_{nn}, \quad \sigma=\sqrt{C^2+B+I_{nn}}}



@node Generating random numbers,  , Final noised pixel value, Noise basics
@subsubsection Generating random numbers

@cindex Random numbers
@cindex Numbers, random
As discussed above, to generate noise we need to make random samples
of a particular distribution. So it is important to understand some
general concepts regarding the generation of random numbers. For a
very complete and nice introduction we strongly advise reading Donald
Knuth's ``The art of computer programming'', volume 2, chapter
3@footnote{Knuth, Donald. 1998. The art of computer
programming. Addison--Wesley. ISBN 0-201-89684-2 }. Quoting from the
GNU Scientific Library manual, ``If you don't own it, you should stop
reading right now, run to the nearest bookstore, and buy
it''@footnote{For students, running to the library might be more
affordable!}!

@cindex Psudo-random numbers
@cindex Numbers, psudo-random
@cindex Seed, psudo-random numbers
Using only software, we can only produce what is called a psudo-random
sequence of numbers. A truely random number generator is through a
hardware (lets assume we have made sure it has no systematic biases),
for examle throwing dice or flipping coins (which have remained from
the ancient times). More modern hardware methods use atmospheric
noise, thermal noise or other types of external electromagnetic or
quantum phenomena. All psudo-random number generators (software)
require a seed to be the basis of the generation. The advantage of
having a seed is that if you specify the same seed for multiple runs,
you will get an identical sequence of random numbers which allows you
to reproduce the same final noised image.

@cindex Environment variables
@cindex GNU Scientific Library
MakeNoise uses the GNU Scientific Library (GSL) to generate random
numbers. GSL allows the user to set the random number generator
through environment variables, see @ref{Installation directory} for an
introduction to environment variables. In the chapter titled ``Random
Number Generation'' they have fully explained the various random
number generators that are available (there are a lot of
them!). Through the two environment variables @code{GSL_RNG_TYPE} and
@code{GSL_RNG_SEED} you can sepecify the generator and its seed
respectively. If you don't specify values for these environment
variables, GSL will use its default type and seed. The default type is
sufficient for most general applications.

There are two ways you can specify values for these environment
variables. You can call them on the same command line as MakeNoise for
example:

@example
$ GSL_RNG_TYPE="taus" GSL_RNG_SEED=345 astmknoise input.fits
@end example

@noindent
In this manner the values will only be used for this particular
execution of MakeNoise. To define them for the full period of your
terminal session or script length, you can use the shell's
@command{export} command (for a script remove the @code{$} signs):

@example
$ export GSL_RNG_TYPE="taus"
$ export GSL_RNG_SEED=345
@end example

@cindex Startup scripts
@cindex @file{.bashrc}
@noindent
The subsequent programs in the particular terminal (or script) that
you ran these commands on which use of GSL's random number generators
(including MakeNoise) will hence forth use these values.  Finally, in
case you want set values for these variables any time you run
MakeNoise (in any terminal or script), you can add these commands to
your @file{.bashrc} startup script@footnote{If you are giving the
scripts to others you have to make sure you also tell them to set them
separately. So for scripts, it is best to keep all such variable
definitions within the script.}.

@cindex GNU C Library
By default, MakeNoise will only use the @code{GSL_RNG_TYPE}
variable. For the seed, by default it will use the microsecond level
accuracy of the GNU C Library. So the random number sequences of
separate runs will be different@footnote{So unless your commands are
less than one microsecond apart, two images will not have the same
sequence of noise values.}. If you want MakeNoise to use the
@code{GSL_RNG_SEED} variable for a reproducable result, you can use
the @option{--envseed} option.

@node Invoking astmknoise,  , Noise basics, MakeNoise
@subsection Invoking MakeNoise

MakeNoise will add noise to an existing image. The executable name is
@file{astmknoise} with the following general template

@example
$ astmknoise [OPTION ...] InputImage.fits
@end example

@noindent
One line examples:

@example
$ astmknoise --background=1000 --stdadd=20 mockimage.fits
@end example

@noindent
If actual processing is to be done, the input image is a mandatory
argument. The full list of options common to all the programs in
Gnuastro can be seen in @ref{Common options}. The output will have the
same type as the input image, however the internal processing is done
on a double precision floating point format. If the input values were
integer types, then each floating point number will be rounded to the
nearest integer away from zero. This might cause integer overflow if
types with small ranges are used (for example images with a
@code{BITPIX} of @code{8} which can only keep 256 values). This can be
disabled with the @option{doubletype} option.  The header of the
output FITS file keeps all the parameters that were influential in
making it. This is done for future reproducability.

@table @option

@item -b
@itemx --background
(@option{=FLT}) The background value for the image in units of
magnitudes, see @ref{Photon counting noise} and @ref{Magnitude to flux
conversion}.

@item -z
@itemx --zeropoint
(@option{=FLT}) The zeropoint magnitude used to convert the value of
@option{--background} (in units of magnitude) to flux, see
@ref{Magnitude to flux conversion}.

@item -s
@itemx --stdadd
(@option{=FLT}) The instrumental noise which is in units of flux, see
@ref{Instrumental noise}.

@item -e
@itemx --envseed
Use the @code{GSL_RNG_SEED} environment variable for the seed used in
the random number generator, see @ref{Generating random numbers}. With
this option, the output image noise is always going to be identical
(or reproducable).

@item -d
@itemx --doubletype
Save the output in the double precision floating point format that was
used internally. This option will be most useful if the input images
were of integer types.

@item -i
@itemx --backgroundinmean
Keep the background value in the mean of the distribution. By default,
the background value will not be used in the mean of the distribution
to find a noised value for each pixel. If this option is called, it
will be used. Note that in the equations of @ref{Photon counting
noise}, @ref{Instrumental noise} and @ref{Final noised pixel value},
the background is included in the mean.

@end table








@node Table manipulation, Developing, Modeling and fittings, Top
@chapter Table manipulation

@cindex Table manipulation
@cindex Manipulating tables
The FITS standard also specifies tables as a form of data that can be
stored in the extensions of a FITS file. These tables can be ASCII
tables or binary tables. The utilities in this section provide the
tools to directly read and write to FITS tables.

The software for this section have to be added ....




















@node Developing, Other useful software, Table manipulation, Top
@chapter Developing

The basic idea of GNU Astronomy Utilities is for an interested
astronomer to be able to easily understand the code of any of the
programs, be able to modify the code if she feels there is an
improvement and finally, to be able to add new programs to the
existing utilities for their own benefit, and the larger community if
they are willing to share it. In short, we hope that at least from the
software point of view, the ``obscurantist faith in the expert's
special skill and in his personal knowledge and authority'' can be
broken, see @ref{Science and its tools}. The following software
architecture can be one of the most basic and easy to understand for
any interested inquirer.

First some general design choices are tackled. It is followed by a
short explanation of the version controlled source. The libraries and
headers in their respective directories are then explained. Later the
the basic conventions for managing the code in each program to
facilitate reading the code by an outside inquirer is
discussed. Finally some notes on the building process are given.


@menu
* Why C::                       Why Gnuastro is designed in C.
* Design philosophy::           General ideas behind the package structure.
* Gnuastro project webpage::    Central hub for Gnuastro activities.
* Version controlled source::   How to get and prepare the VCSed code.
* Internal libraries::          Internal static (not installed) libraries.
* Header files::                Library and common headers.
* Program source::              Conventions for the code.
* Test scripts::                Understanding the test scripts.
* Building::                    Explanations on building.
* After making changes::        What to do after you have finished you changes.
@end menu




@node Why C, Design philosophy, Developing, Developing
@section Why C programming language?
@cindex C programming language
@cindex C++ programming language
@cindex Python programming language
Currently the programming language that is most commonly used in
scientific applications is C++, and more recently Python. One of the
main reasons behind this choice is that through the Object oriented
programming paradigm, they offer a much higher level of
abstraction. However, GNU Astronomy Utilities are written in the C
programming language. The reasons can be summarized with simplicity
and speed. Both are extremely important in a scientific software.

@cindex ANSI C
@cindex ISO C90
@cindex Ritchie, Dennis
@cindex Kernighan, Brian
@cindex Stroustrup, Bjarne
A simple comparison of the main books of C++ and C can act as a
guide. The ``C programming language''@footnote{Brian Kernighan, Dennis
Ritchie. @emph{The C programming language}. Prentice Hall, Inc.,
Second edition, 1988. It is also commonly known as K&R and is based on
the ANSI C and ISO C90 standards.} book, written by the authors of C,
is only 286 pages and covers a very good fraction of the language, it
has also remained unchanged from 1988. C is the main programming
language of nearly all operating systems and there is no plan of any
significant update. The most recent ``C++ programming
language''@footnote{Bjarne Stroustrup. @emph{The C++ programming
language}. Addison-Wesley Professional; 4 edition, 2013.}  book, also
written by its author, on the other hand has 1366 pages and its fourth
edition came out in 2013!  As discussed in @ref{Science and its
tools}, it is very important for other scientists to be able to
readily read the code of a program at their will with minimum
requirements.

@cindex Object oriented programming
In C++, inheriting objects in the object oriented programming paradigm
and their internal functions make the code very easy to write for the
programmer who is deeply invested in those objects and understands all
their relations well. But it simultaneously makes reading the program
for a first time reader (a curious scientist who wants to know only
how a small step was done) extremely hard. Before understanding the
methods, the scientist has to invest a lot of time in understanding
those objects and their relations. But in C, if only simple structures
are used, all variables can be given as the basic language types for
example @code{int}s or @code{float}s and their pointers to define
arrays. So when an outside reader is only interested in one part of
the program, that part is all they have to understand.

Recently it is also becoming common to write scientific software in
Python, or a combination of it with C or C++. Python is a high level
scripting language which doesn't need compilation. It is very useful
when you want to do something on the go and don't want to be halted by
the troubles of compiling, linking, memory checking, etc. When the
data sets are small and the job is temporary, this ability of Python
is great and is highly encouraged. A very good example might be
plotting, in which Python is undoubtedly one of the best.

But as the data sets increase in size and the processing becomes very
complicated, the speed of Python scripts significantly decrease. So
when the program doesn't change too often and is widely used in a
large community mostly on large data sets (like astronomical images),
using Python will waste a lot of valuable research-hours. Some use
Python as a wrapper for C or C++ functions to fix the speed
issue. However because such actions allow separate programs to share
memory (through Python), the code in such programs tends to become
extremely complicated very soon, which is contrary to the principles
in @ref{Science and its tools}.

Like C++, Python is object oriented, so as explained above, it needs a
high level of experience with that particular program to fully
understand its inner workings. To make things worse, since it is
mainly for fast and on the go programming, it constantly undergoes
significant changes, such that Python 2.x and Python 3.x are not
compatible. Lots of research teams that invested heavily in Python 2.x
cannot benefit from Python 3.x or future versions any more. Some
converters are available, but since they are automatic, lots of
complications might arise in the conversion. Thus, re-writing all the
changes would be the only truly reliable option. If a research
project begins using Python 3.x today, there is no telling how
compatible their investments will be when Python 4.x or 5.x will come
out. This stems from the core principles of Python, which are very
useful when you look in the `on the go' basis as described before
and not future usage.

@cindex Low level programming
@cindex Programming, low level
Being a very low level (closer to the hardware) language, C is much
less complex for both the human reader and the computer. It thus
allows for closer relation between the programmer (program) and the
actual data in our disposal. This is contrary to the illusion of
abstractions that the higher level languages provide. The GNU coding
standards@footnote{@url{http://www.gnu.org/prep/standards/}} also
encourage the use of C over all other languages when generality of
usage and `high speed' is desired.





@node Design philosophy, Gnuastro project webpage, Why C, Developing
@section Design philosophy

The core processing functions of each program are written mostly with
the basic ISO C90 standard. We do make lots of use of the GNU
additions to the C language in the GNU C Library, but these additional
functions are mainly used in the user interface functions (reading
your inputs and preparing them prior to or after the analysis). The
actual algorithms, which most scientists would be more interested in,
are much more closer to ISO C90. For this reason, the source files
containing user interface code and those containing actual processing
code are clearly separated, see @ref{Program source}. If anything
particular to the GNU C Library is used in the processing functions,
it is explained in the comments in between the code.

@cindex GNU Coreutils
Similar to GNU Coreutils, all the Gnuastro utilities provide very low
level operations. This enables you to use the GNU Bash scripting
language (which is the default in most GNU/Linux operating systems) or
any other shell you might be using to operate on a large number of
files or do very complex things through the creative combinations of
these tools that the authors had never dreamed of. We have put a few
simple examples in @ref{Tutorials}.

@cindex GNU Bash
@cindex Python Matplotlib
@cindex Matplotlib, Python
@cindex PGFplots in @TeX{} or @LaTeX{}
For example all the analysis output is provided as ASCII tables which
you can feed into your favorite plotting program to inspect
visually. Python's Matplotlib is very useful for fast plotting of the
tables to immediately check your results. If you want to include the
plots in a document, you can use the PGFplots package within @LaTeX{},
no attempt is made to include such operations in Gnuastro. In short,
Bash can act as a glue to connect the inputs and outputs of all these
various Gnuastro utilities (and other programs) in any fashion you
please.

The advantage of this architecture is that the programs become small
and transparent: the starting and finishing point of every program is
clearly demarcated. For nearly all operations on a modern computer,
the read/write speed is very insignificant compared to the actual
processing a program does. Therefore the complexity which arises from
sharing memory in a large application is simply not worth the speed
gain. This basic design is influenced by Eric Raymond's ``The Art of
Unix Programming''@footnote{Eric S. Raymond, 2004, @emph{The Art of
Unix Programming}, Addison-Wesley Professional Computing Series.}
which beautifully describes the design philosophy and practice which
lead to the success of Unix-based operating
systems@footnote{KISS principle: Keep It Simple, Stupid!}.

Finally, and arguably the most important, principle of Gnuastro is
this: Gnuastro is not planned to be a repository of creative programs
with no clear purpose. The purpose of each program and all the major
operations it does have to be very clearly documented and aligned with
the general purpose of Gnuastro. Through the main management hub, we
have a set of planned tasks and bugs, see @ref{Gnuastro project
webpage}. If you have a plan to add something and want it to be an
official part of Gnuastro, please check there and if it (or something
similar to it) doesn't already exist, then add it. This will notify
all the developers of your intent, so potentially parallel operations
do not occur and similar ideas can be discussed. If something similar
to your idea already exists, you can contact the person in charge and
join that work.



@node Gnuastro project webpage, Version controlled source, Design philosophy, Developing
@section Gnuastro project webpage

@cindex Bug
@cindex Issue
@cindex Tracker
@cindex Report a bug
@cindex Management hub
@cindex Feature request
@cindex Central management
@url{https://savannah.gnu.org/projects/gnuastro/, Gnuastro's central
management
hub}@footnote{@url{https://savannah.gnu.org/projects/gnuastro/}} is
located on @url{https://savannah.gnu.org/, GNU
Savannah}@footnote{@url{https://savannah.gnu.org/}}. It is the central
software development management system for all GNU projects. Through
this central hub, you can view the list of activities that the
developers are engaged in, their activity on the version controlled
source, and other things. Each defined activity in the development
cycle is known as an `issue' (or `item'). An issue can be a bug (see
@ref{Report a bug}), or a suggested feature (see @ref{Suggest new
feature}) or an enhancement or generally any @emph{one} job that is to
be done. In Savannah, issues are classified into three categories or
`tracker's:

@table @asis

@cindex Mailing list: bug-gnuastro
@item Support
This tracker is a way that (possibly anonymous) users can get in touch
with the Gnuastro developers. It is a complement to the bug-gnuastro
mailing list (see @ref{Report a bug}). Anyone can post an issue to
this tracker. The developers will not submit an issue to this
list. They will only reassign the issues in this list to the other two
trackers if they are valid@footnote{Some of the issues registered here
might be due to a mistake on the user's side, not an actual bug in the
program.}. Ideally (when the developers have time to put on Gnuastro,
please don't forget that Gnuastro is a volunteer effort), there should
be no open items in this tracker.

@item Bugs
This tracker contains all the known bugs in the Gnuastro (problems
with the existing tools).

@item Tasks
The items in this tracker contain the future plans (or new
features/capabilities) that are to be added to Gnuastro.

@end table

@noindent
All the trackers can be browsed by a (possibly anonymous) visitor, but
to edit and comment on the Bugs and Tasks trackers, you have to be a
registered Gnuastro developer. When posting an issue to a tracker, it
is very important to choose the `Category' and `Item Group' options
accurately. The first contains a list of all Gnuastro's utilities
along with `Installation', `New utility' and `Webpage'. The ``Item
Group'' contains the nature of the issue, for example if it is a
`Crash' in the software (a bug), or a problem in the documentation
(also a bug) or a feature request or an enhancement.

The set of horizontal links on the top of the page (Starting with
`Main' and `Homepage' and finishing with `News') are the easiest way
to access these trackers (and other major aspects of the project) from
any part of the project webpage. Hovering your mouse over them will
open a drop down menu that will link you to the different things you
can do on each tracker (for example, `Submit new' or `Browse').  When
you browse each tracker, you can use the ``Display Criteria'' link
above the list to limit the displayed issues to what you are
interested in. The `Category' and `Group Item' (explained above) are a
good starting point.

@node Version controlled source, Internal libraries, Gnuastro project webpage, Developing
@section Version controlled source

@cindex Git
@cindex Version control
The source code that is publicly distributed does not contain the
revision history, it is only the final snapshot of a stable release,
ready to be configured and built. To be able to develop successfully,
the revision history of the code can be very useful, also some updates
that are not yet released might be in it.  We use Git for the version
control of Gnuastro. For those who are not familiar with it, we
suggest the Pro Git
book@footnote{@url{http://git-scm.com/book/en/v2}}. The whole book is
publicly available for online reading and downloading. The latest
version of Gnuastro can be cloned by running

@example
$ git clone git://git.sv.gnu.org/gnuastro.git
@end example

@cindex GNU C Library
@cindex GNU Autoconf Archive
@cindex GNU Portability Library
@cindex Automatically created build files
@noindent
The version controlled source code lacks the source files that we have
not written or are automatically built (and included in the
distributed @file{gnuastro-@value{VERSION}.tar.gz}) for configuration
and building. There are two types of files that we have not
written. To ensure portability for a wider range of operating systems
(those that don't include GNU C Library, namely glibc), we have used
the GNU Portability Library (Gnulib). Gnulib keeps a copy of all the
functions in glibc and you can include them in the source code to
replace system wide functions on other compilers. To test for various
system architectures and compiler configurations we make use of the
various GNU Autoconf macros in the GNU Autoconf
archives@footnote{@url{http://www.gnu.org/software/autoconf-archive/}}.

To get the Gnulib and the Autoconf archives, just run these commands
in any directory you want to store them in (lets assume you are in
@file{~/Development} directory):

@example
$ pwd
/home/yourusername/Development
$ git clone git://git.sv.gnu.org/gnulib.git
$ git clone git://git.sv.gnu.org/autoconf-archive.git
@end example

@noindent
This will download the full version controlled source of the two in
separate directories. Both these packages are regularly updated, so
every once and a while you can run @command{$ git pull} within them to
get any possible updates. First, include all the necessary packages
from Gnulib. To do that, run the following command from within the
cloned @file{gnuastro} directory@footnote{Note that the
@file{gnulib-tool} script has to be run from within the cloned Gnulib
directory, it is not insxtalled.}:

@example
$ ~/Development/gnulib/gnulib-tool --import --source-base=gnulib/lib \
  --with-tests --tests-base=gnulib/tests --no-vc-files math argp \
  error progname
@end example

@noindent
One of the directories made after running @file{gnulib-tool} is
@file{m4/}. We can now add the necessary Autoconf checks from the
Autoconf archives to this directory:

@example
$ cp ~/Development/autoconf-archive/m4/ax_pthread.m4 ./m4/
@end example

@cindex GNU Texinfo
@cindex GNU Libtool
@cindex GNU Autoconf
@cindex GNU Automake
@cindex GNU build system
@noindent
All the necessary GNU C Library functions and Autoconf macros are now
available. Now you can add the automatically generated files used to
build Gnuastro using the GNU build system. To generate those files you
have to run the following command in the cloned @file{gnuastro}
directory. @command{autoreconf} is part of GNU Autoconf and also
requires GNU Automake, GNU Libtool and GNU Texinfo to create all the
necessary files, see @ref{Building}.

@example
$ autoreconf --install
@end example

@noindent
Now you can easily configure, build and start hacking into the code
and you have the full revision history under your fingers.

The hand-written (that is version controlled) code for Gnuastro, this
manual and the tests are divided in the following sub-directories of
the top directory. Their names are standard and descriptive enough,
but a short summary is given here:

@cindex Top source code directories
@cindex Directories in Gnuastro source
@table @file

@item doc
The Texinfo source files for this manual and the Gnuastro webpage
file(s).

@item include
The header files of the internal static libraries and also some other
header files that are used by more than one program.

@item lib
The internal static libraries (only their @file{.c} files) are stored
here. These libraries hold functions that are used by more than one
program, they will not be installed.

@item src
This directory contains a subdirectory for every program in this
version of Gnuastro. The source code for each program is placed
inside each of these sub-directories to be easily separable.

@item tests
This directory keeps all the tests (checks) which are executed when
@command{make check} is run.

@end table

Until Gnuastro grows large enough to define its own, we strive to
follow the version control guidelines of the Git project as our
base. You can find it in the Git project's submitting patches
guideline@footnote{@url{https://github.com/git/git/blob/master/Documentation/SubmittingPatches}}.




@node Internal libraries, Header files, Version controlled source, Developing
@section Internal libraries

@cindex Static libraries
@cindex Internal libraries
@cindex Convenience libraries
@cindex Libraries, convenience
Libraries are binary (compiled) files which are not executable them
selves, but once linked with other binary files, they form the
building blocks of larger programs. Several functions are commonly
used by all or several of the programs in Gnuastro. Therefore they are
written as separate libraries so we don't have to maintain duplicate
code. Such libraries are commonly referred to as convenience
libraries. They are mostly to do with interaction with the outside
world (of the program), for example setting up the configuration
files, reading text catalogs or wrappers for CFITSIO and WCSLIB to
facilitate reading and writing of FITS files. The names of the
libraries are usually descriptive enough on the kind of functions they
keep.

Currently these libraries are not installed along with Gnuastro, they
are only statically linked to any program needing them in the build
directory and remain or are deleted from there. Note that in a static
link, the contents of the library are merged with the executable, so
they are no longer needed after the linking (you can safely delete
them after installing the executable). In the future if need be, they
can also be installed so they can be used by other programs too.


@node Header files, Program source, Internal libraries, Developing
@section Header files

@cindex Header files
The @file{include/} directory contains the headers for Gnuastro's
internal libraries (see @ref{Internal libraries}) and several
header-only files in the @file{include} directory. Below is a list of
the latter type.

@table @code

@item commonargs.h
@cindex @file{commonargs.h}
All the programs have a common set of options, see @ref{Common
options}. Instead of including separately them and making sure they
are identical in the implementation of all programs, the GNU C
library's ability to merge independent argument parsers with Argp is
used. This ensures that they are identical in all programs with only
one file to work on. The common options and the function to parse them
are thus defined in this header file. All the argument parsers in
various programs are merged with this argument parser to read the
user's input.

@item commonparams.h
@cindex @file{commonparams.h}
The structure that keeps the values of the common arguments and
whether they have been set or not is defined in this header file.

@item fixedstringmacros.h
@cindex @file{fixedstringmacros.h}
Some strings are fixed in all the programs, only the relevant names of
the packages must be put in them. The various names for each package
are defined in their @file{main.h} source file with macros of fixed
names. For example the copyright notice, or parts of the top
information in the @option{--help} output.

@item neighbors.h
@cindex @file{neighbors.h}
The macros in this header find the neighbors of a pixel index using
four or eight connectivity in a region of an image or the whole image.

@end table


@node Program source, Test scripts, Header files, Developing
@section Program source

@cindex Source file navigation
@cindex Navigating source files
@cindex Program structure convention
@cindex Convention for program source
@cindex Gnuastro program structure convention
Besides the fact that all the programs share some functions that were
explained in @ref{Internal libraries}, everything else about each
program is completely independent. In this section the conventions
used in all the program sources are explained. To easily understand
the explanations in this section, it is good to open the source files
of one or several of the programs in Gnuastro and inspect them as you
read along.


@menu
* Mandatory source code files::  How the source files of each program are managed.
* Coding conventions::          Basic conventions for coding structure.
* Multithreaded programming::   Gnuastro's multithreaded programming style.
* Documentation::               Documentation is an integral part of Gnuastro.
@end menu

@node Mandatory source code files, Coding conventions, Program source, Program source
@subsection Mandatory source code files

Some programs might need lots of source files and if there is no fixed
convention, navigating them can become very hard for a new inquirer
into the code. The following source files exist in every program's
source directory (which is located in @file{src/progname}). For small
programs, these files are enough. Larger programs will need more
files. In general for writing other source files, please choose
filenames that are descriptive.

@vtable @file

@item main.c
@cindex @code{main} function
Each executable has a @code{main} function, which is located in
@file{main.c}. Therefore this file in any program's source code will
be the starting point. No actual processing functions are to be
defined in this file, the function(s) in this file are only meant to
connect the most high level steps of each program. Generally,
@code{main} will first call the top user interface function to read
user input and make all the preparations. Then it will pass control to
the top processing function for that program. The functions to do both
these jobs must be defined in other source files.

@item main.h
@cindex Top root structure
@cindex @code{prognameparams}
@cindex Root parameter structure
@cindex Main parameters C structure
All the major parameters which will be used in the program must be
stored in a structure which is defined in @file{main.h}. The name of
this structure is usually @code{prognameparams}, for example
@code{imgcropparams}. So @code{#include "main.h"} will be a staple in
all the source codes of the program and most of the functions. Keeping
all the major parameters of a program in this structure has the major
benefit that most functions will only need one argument: a pointer to
this structure. This will significantly facilitate the job of the
programmer, the inquirer and the computer. All the programs in
Gnuastro are designed to be low-level, small and independent parts, so
this structure should not get too large.

The main root structure of a program contains at least two other
structures: a structure only keeping parameters for user interface
functions, which is also defined in @file{main.h} and the
@code{commonparams} structure which is defined in
@file{commonparams.h}, see @ref{Header files}. The main structure can
become very large and since the programmer and inquirer often don't
need to be confused with these parameters mixed with the actual
processing parameters, they are conveniently defined in another
structure which is named @code{uiparams} and is also defined in
@file{main.h}. It could be defined in @file{ui.h} (see below) so the
main functions remain completely ignorant to it, but its parameters
might be needed for reporting input conditions, so it is included as
part of the main program structure.

@cindex @code{p}
This top root structure is conveniently called @code{p} (short for
parameters) by all the programs. The @code{uiparams} structure is
called @code{up} (for user parameters) and the @code{commonparams}
structure is called @code{cp}. With this convention any reader can
immediately understand where to look for the definition of one
parameter.

@cindex Structure de-reference operator
@cindex Operator, structure de-reference
With this basic root structure, source code of functions can
potentially become full of structure de-reference operators
(@command{->}) which can make the code very un-readable. In order to
avoid this, whenever a parameter is used more than a couple of times
in a function, a parameter of the same type and with the same name (so
it can be searched) as the desired parameter should be defined and put
the value of the root structure inside of it in definition time. For
example

@example
char *hdu=p->cp.hdu;
int verb=p->cp.verb;
@end example

@item args.h
@cindex Argp argument parser
The argument parser structures (which are used by GNU C Library's
Argp) for each program are defined in @file{args.h}. They are separate
global variables and function definitions that will be used by
Argp. We recommend going through the appropriate section in GNU C
library to understand their exact meaning, although they should be
descriptive and understandable enough by looking at a few of the
programs.

@item ui.c, ui.h
@cindex User interface functions
@cindex Functions for user interface
The user interface functions are also a unique set of functions in all
the programs, so they are particularly named @file{ui.c} and
@file{ui.h} in all the programs. Everything related to reading the
user input arguments and options, checking the configuration files and
checking the consistency of the input parameters before the actual
program is run should be done in this file. Since most functions are
the same, with only the internal checks and structure parameters
differing, we recommend going through several of the examples and
structuring your @file{ui.c} in a similar fashion with the rest of the
programs.

@cindex @code{setparams} function
The most high-level function in @file{ui.c} is named @code{setparams}
which accepts @code{int argc, char *argv[]} and a pointer to the root
structure for that program, see the explanation for
@file{main.h}. This is the function that @code{main} calls. The basic
idea of the functions in this file is that the processing functions
should need a minimum number of such checks. With this convention an
inquirer who only wants to understand only one part (mostly the
processing part and not user input details) of the code can easily do
so. It also makes all the errors related to input appear before the
processing begins which is more convenient for the user.

@item progname.c
@cindex Top processing source file
The main processing functions in each program which keep the
function(s) that @code{main()} will call are in a file named
@file{progname.c}, for example @file{imgcrop.c} or
@file{noisechisel.c}. The function within these files which
@code{main()} calls is also named after the program, for example

@example
void
imgcrop(struct imgcropparams *p)
@end example

@noindent
or

@example
void
noisechisel(struct noisechiselparams *p)
@end example

@noindent
In this manner, if an inquirer is interested the processing steps,
they can immediately come and check this file for the first processing
step without having to go through @file{main.c} first. In most
situations, any failure in any step of the programs will result in an
informative error message and an immediate abort in the program. So
there is no need for return values. Under more complicated situations
where a return value might be necessary, @code{void} will be replaced
with an @code{int} in the examples above.

@item cite.h
@cindex Citation information
This file keeps the function to be called if the user runs any of the
programs with @option{--cite}, see @ref{Operating modes}.

@end vtable

@menu
* Coding conventions::          Conventions used for coding
* Multithreaded programming::   Gnuastro uses POSIX threads.
@end menu

@node Coding conventions, Multithreaded programming, Mandatory source code files, Program source
@subsection Coding conventions

@cindex GNU coding standards
@cindex Gnuastro coding convention
Generally we try our best to follow the GNU coding standards, besides
those the following conventions are adhered to until now. If new code
is also added in the same manner, it would be much more easily
readable by any interested astronomer (who will become familiar with
it after reading once).

@itemize

@item
It is very important that the code be easy to read by the eye. So when
the order of several lines within a function does not matter (mostly
when defining variables at the start of a function). You should put
the lines in the order of increasing length and group the variables
with similar types such that this half-pyramid of declarations becomes
most visible. If the reader is interested, a simple search will show
them the variable they are interested in. However, when looking
through the functions or reading the separate steps of the functions,
this `order' in the declarations will make reading the rest of the
function steps much more easier and pleasent to the eye.

@item
When ever you see that the function cannot be fully displayed
(vertically) in your monitor, this is a sign that it has become too
long and should be broken up into multiple functions. 40 lines is
usually a good reference. When the start and end of a function are
clearly visible in one glance, the function is much more easier to
understand. This is most important for low-level functions (which
usually define a lot of variables). Low-level functions do most of the
processing, they will also be the most interesting part of a program
for an inquiring astronomer. This convention is less important for
higher level functions that don't define too many variables and whose
only purpose is to run the lower-level functions in a specific order
and with checks.

@cindex Optimization flag
@cindex GNU Compiler Collection
In general you can be very liberal in breaking up the functions into
smaller parts, the GNU Compiler Collection (GCC) will automatically
compile the functions as inline functions when the optimizations are
turned on. So you don't have to worry about decreasing the speed. By
default Gnuastro will compile with the @option{-O3} optmization flag.

@cindex Buffers (Emacs)
@cindex Emacs buffers
@item
If possible, the text files should always be at most 80 characters
wide. Monitors today are certainly much wider, but with this limit,
reading the functions becomes much more easier. Also for the
developers, it allows multiple files (or multiple views of one file)
to be displayed beside each other on wide monitors (Emacs's buffers
are excellent for this capability).

For long comments you can use press @key{Alt-q} in Emacs to separate
them into separate lines automatically. For long literal strings, you
can use the fact that in C, two strings immediately after each other
are concatenated, for example @code{"The first part, " "and the second
part."} Note the space character in the end of the first part. Since
they are now separated, you can easily break a long literal string
into several lines and adhere to the maximum 80 character line length
policy.

@cindex Header file
@item
The headers required by each source file (ending with @file{.c})
should be defined inside of it. All the headers a program needs should
not be stacked in another header to include in all source files (for
example @file{main.h}). Although most `professional' programmers
choose the latter type, Gnuastro is primarily written for inquisitive
astronomers (who are generally amateur programmers). This is very
useful for readability by a first time reader. @file{main.h} may only
include the header file(s) that define types that the main program
structure needs, see @file{main.h} in @ref{Program source}. Those
particular header files that are included in @file{main.h} can
ofcourse be ignored (not included) in separate source files.

@item
The headers should be classified (by an empty line) into separate
groups:

@enumerate
@cindex GNU Portability Library
@item
@code{#include <config.h>}: This must be the first code line (not
commented or blank) in each source file. It sets macros that the GNU
Portability Library (Gnulib) will use for the possible
additions/modifications to C library headers.

@cindex GNU C library
@item
The C library (or GNU C library) header files, for example
@file{stdio.h} or @file{errno.h}.
@item
Installed library header files, for example @file{cfitsio.h} or
@file{gsl/gsl_rng.h}.
@item
Gnuastro common header files, for example @file{fitsarrayvv.h} or
@file{neighbors.h}, see @ref{Header files}.
@item
That particular program's header files, for example @file{main.h} and
@file{mkprof.h}.
@end enumerate

@noindent
As much as order does not matter when you include the header of each
group, sort them by length, see above.

@item
@cindex GNU Emacs
@cindex Trailing space
There should be no trailing white space in a line. To do this
automatically every time you save a file in Emacs, add the following
line to your @file{~/.emacs} file.
@example
(add-hook 'before-save-hook 'delete-trailing-whitespace)
@end example

@item
@cindex Tabs are evil
There should be no tabs in the indentation. Add the line below to your
@file{~/.emacs} file to do this automatically:
@example
(setq-default indent-tabs-mode nil)
@end example

@item
@cindex GNU Emacs
@cindex Function groups
@cindex Groups of similar functions
All similar functions are separated by 5 blank lines to be easily seen
to be related in a group when parsing the source code by eye. In Emacs
you can use @key{CTRL-u 5 CTRL-o}.

@item
One group of functions is separated from another with 20 blank
lines. In Emacs you can use @key{CTRL-u 20 CTRL-o}. Each group of
functions has short descriptive title of the functions in that
group. This title is surrounded by asterisks (@key{*}) to make it
clearly distinguishable. Such contextual grouping and clear title are
very important for easily understanding the code.

@end itemize


@node Multithreaded programming, Documentation, Coding conventions, Program source
@subsection Multithreaded programming

@cindex Multithreaded programming
Most of the programs in Gnuastro utilize multi-threaded programming
for the CPU intensive processing steps. This can potentially lead to a
significant decrease in the running time of a program, see @ref{A note
on threads}. In terms of reading the code, you don't need to know
anything about multi-threaded programming. You can simply follow the
case where only one thread is to be used. In these cases, threads are
not used and can be completely ignored.

@cindex POSIX threads library
@cindex Lawrence Livermore National Laboratory
At the time K&R's book was written, using threads was not common. We
use POSIX threads for multi-threaded programming, defined in the
@file{pthread.h} system wide header. There are various resources for
learning to use POSIX threads, the excellent tutorial from Lawrence
Livermore National
Laboratory@footnote{@url{https://computing.llnl.gov/tutorials/pthreads/}}
is a very good start.  The book `Advanced programming in the Unix
environment'@footnote{Don't let the title scare you! The two chapters
on Multi-threaded programming are very self sufficient and don't need
any more knowledge than K&R.}, by Richard Stevens and Stephen Rago,
Addison-Wesley, 2013 (Third edition) also has two chapters explaining
the POSIX thread constructs which can be very helpful.

@cindex OpenMP
An alternative to POSIX threads was OpenMP, but POSIX threads are low
level, allowing much more control, while being easier to understand,
see @ref{Why C}. All the situations where threads are used are
completely independent with minimal need of coordination between the
threads.  Such problems are known as ``embarrassingly parallel''
problems. They are some of the simplest problems to solve with threads
and also the ones that benefit most from threads, see the LLNL
introduction@footnote{@url{https://computing.llnl.gov/tutorials/parallel_comp/}}.


@node Documentation,  , Multithreaded programming, Program source
@subsection Documentation

Documentation (this manual) is an integral part of Gnuastro.
Documentation is not considered a separate project. So, no change is
considered valid for implementation unless the respective parts of the
manual have also been updated. The following procedure can be a good
suggestion to take when you have a new idea and are about to start
implementing it.

The steps below are not a requirement, the important thing is that
when you send the program to be included in Gnuastro, the manual and
the code have to both be fully up-to-date and compatible and the
purpose should be very clearly explained. You can follow any path you
choose to do this, the following path was what we found to be most
successful during the initial design and implementation steps of
Gnuastro.

@enumerate
@item
Edit the manual and fully explain your desired change, such that your
idea is completely embedded in the general context of the manual with
no sence of discontinuity for a first time reader. This will allow you
to plan the idea much more accurately and in the general context of
Gnuastro or a particular program. Later on, when you are coding, this
genral context will significantly help you as a road-map.

A very important part of this process is the program introduction,
which explains the purposes of the program. Before actually starting
to code, explain your idea's purpose thoroughly in the start of the
program section you wish to add or edit. While actually writing its
purpose for a new reader, you will probably get some very valuable
ideas that you hadn't thought of before, this has occured several
times during the creation of Gnuastro. If an introduction already
exists, embed or blend your idea's purpose with the existing
purposes. We emphasize that doing this is equally useful for you (as
the programmer) as it is useful for the user (reader). Recall that the
purpose of a program is very important, see @ref{Design philosophy}.

As you have already noticed for every program, it is very important
that the basics of the science and technique be explained in separate
subsections prior to the `Invoking Programname' subsection. If you are
writing a new program or your addition involves a new concept, also
include such subsections and explain the concepts so a person
completely unfamiliar with the concepts can get a general initial
understanding. You don't have to go deep into the details, just enough
to get an interested person (with absolutely no background)
started. If you feel you can't do that, then you have probably not
understood the concept your self! Have in mind that your only
limitation in length is the fatigue of the reader after reading a long
text, nothing else.

It might also help if you start implementing your idea in the
`Invoking ProgramName' subsection (explaining the options and
arguments you have in mind) at this stage too. Actually starting to
write it here will really help you later when you are coding.

@item
After you have finished adding your initial intended plan to the
manual, then start coding your change or new program within the
Gnuastro source files. While you are coding, you will notice that
somethings should be different from what you wrote in the manual (your
initial plan). So correct them as you are actually coding.

@item
In the end, read the section in the manual that you edited completely
and see if you didn't miss any change in the coding and to see if the
context is fairly contiues for a first time reader (who hasn't seen
the manual or had known of Gnuastro before you made your change).
@end enumerate

@node Test scripts, Building, Program source, Developing
@section Test scripts

@cindex Test scripts
@cindex Gnuastro test scripts
As explained in @ref{Tests}, for every program some simple tests are
written to check the various independent features of the program. All
the tests are placed in the @file{gnuastro-@value{VERSION}/tests}
directory, let's call it @file{TESTdir}. There is one script
(@file{prepconf.sh}) in this folder and several @file{Makefile}s. The
script is the first `test' that will be run. It will copy all the
configuration files from the various directories to a @file{.gnuastro}
directory which it will make so the various tests can set the default
values.

For each program, the tests are placed inside directories with the
program name. Each test is written as a shell script. The last line of
this script is the test which runs the program with certain
parameters. The return value of this script determines the fate of the
test, see the ``Support for test suites'' chapter of the Automake
manual for a very nice and complete explanation. In every script, two
variables are defined at first: @code{prog} and @code{execname}. The
first specifies the program name and the second the location of the
executable.

@cindex Build tree
@cindex Source tree
The most important thing to have in mind about all the test scripts is
that they are run from inside the @file{TESTdir} directory in the
``build tree''. Which can be different from the directory they are
stored in (known as the ``source tree''). This distinction is made by
GNU Autoconf and Automake (which configure, build and install
Gnuastro) so that you can install the program even if you don't have
write access to the directory keeping the source files. See the
``Parallel build trees (a.k.a VPATH builds)'' in the Automake manual
for a nice explanation.

Because of this, any possible data that was not generated by other
tests (and is thus in the build tree), for example the catalogs in
ImageCrop tests, has a @command{$topsrc} prefix instead of
@command{../} for the build three. This @command{$topsrc} variable
points to the source tree where the script can find the source data
(it is defined in @file{TESTdir/Makefile.am}). The executables and
other test products were built in the build tree (where they are being
run), so they don't need to be prefixed with that variable. This is
also true for images or files that were produced by other tests.





@node Building, After making changes, Test scripts, Developing
@section Building

@cindex GNU Libtool
@cindex GNU Autoconf
@cindex GNU Automake
@cindex GNU build system
To build the various programs and libraries in Gnuastro, the GNU build
system is used which defines the steps in @ref{Quick start}. It
consists of GNU Autoconf and GNU Automake and GNU Libtool which are
collectively known as GNU Autotools. They provide a very portable
system to check the environment a program is to be installed on prior
to compiling and set the compilation conditions based on the
particular user. They also make installing everything in their
standard places very easy for the programmer. Most of the small caps
files that you see in the top @file{gnuastro-@value{VERSION}/}
directory are created by these three tools.

By default all the programs are compiled with optimization flags for
increased speed. A side effect is that valuable debugging information
is lost. To compile with the debugging flag set on (and no
optimization) you can add the following options to configure:

@example
$ ./configure CFLAGS="-g -O0"
@end example

In order to understand the building process, you can go through the
Autoconf, Automake and Libtool manuals, like all GNU manuals they
provide both a great tutorial and technical documentation. The ``A
small Hello World'' section in Automake's manual (in chapter 2) can be
a good starting guide after you have read the introductions of
both. To get a good understand of how these three operate separately
yet the codes are all mixed, there is a great tutorial
book@footnote{@url{https://www.sourceware.org/autobook/}} which you
can get you started off.





@node After making changes,  , Building, Developing
@section After making changes
After you have made your your changes/additions, please take the
following steps:

@enumerate

@item
Write test(s) in the @file{tests/progname/} directory to test the
change(s)/addition(s) you have made. Then add their file names to
@file{tests/Makefile.am}. And run @command{$ make check} to make sure
everything is working correctly.

@item
Make sure the manual is completely up to date with your changes, see
@ref{Documentation}.

@cindex GNU Emacs
@cindex @file{ChangeLog}
@cindex GNU coding standards
@item
If you have @emph{changed} anything in the program, add it to the
@file{ChangeLog} (a file in the top source code
directory). @file{ChangeLog} has a specific format defined by the GNU
coding standards. The easiest way to add an entry to it is through
Emacs: by pressing @key{CTRL-x 4 a} within the places that you have
changed. Note that if you have only added something, there is no need
to include it in @file{ChangeLog}.

@cindex Making a distribution package
@item
Finally, to make sure everything will run and is checked correctly,
run

@example
$ make distcheck
@end example

@noindent
This command will create a distribution file (ending with
@file{.tar.gz}) and try to compile it in the most general cases, then
it will run the tests on what it has built in its own
mini-environment. If @command{$ make check} finishes successfully,
then you are safe to send your changes to us to implement or for your
own purposes.

@end enumerate





















@node Other useful software, GNU Free Documentation License, Developing, Top
@appendix Other useful software

In this appendix the installation of programs and libraries that are
not direct Gnuastro dependencies are discussed. However they can be
useful for working with Gnuastro.

@menu
* SAO ds9::                     Viewing FITS images.
* PGPLOT::                      Plotting directly in C
@end menu

@node SAO ds9, PGPLOT, Other useful software, Other useful software
@section SAO ds9

@cindex SAO ds9
@cindex FITS image viewer
SAO ds9@footnote{@url{http://ds9.si.edu/}} is not a requirement of
Gnuastro, it is a FITS image viewer. So to check your inputs and
outputs, it is one of the best options. Like the other packages, it
might already be available in your distribution's repositories. It is
already pre-compiled in the download section of its webpage. Once you
download it you can unpack and install (move it to a system recognized
directory) with the following commands (@code{x.x.x} is the version
number):

@example
$ tar -zxvf ds9.linux64.x.x.x.tar.gz
$ sudo mv ds9 /usr/local/bin
@end example

Once you run it, there might be a complaint about the Xss library,
which you can find in your distribution package management system. You
might also get an @command{XPA} related error. In this case, you have
to add the following line to your @file{~/.bashrc} and
@file{~/.profile} file (you will have to log out and back in again for
the latter):

@example
export XPA_METHOD=local
@end example


@menu
* Viewing multiextension FITS::  Configure SAO ds9 for multiextension images.
@end menu

@node Viewing multiextension FITS,  , SAO ds9, SAO ds9
@subsection Viewing multiextension FITS images

@cindex Multiextention FITS
@cindex Opening multiextention FITS
The FITS definition allows for multiple extensions inside a FITS file,
each extension can have a completely independent data set inside of
it. If you ordinarily open a multi-extension FITS file with SAO ds9,
for example by double clicking on the file or running @command{$ds9
foo.fits}, SAO ds9 will only show you the first extension. To be able
to switch between the extensions you have to follow these menus in the
SAO ds9 window: @clicksequence{File@click{}Open Other@click{}Open
Multi Ext Cube} and then choose the Multi extension FITS file in your
computer's file structure.

@findex ds9 -mecube
The method above is a little tedious to do every time you want view a
multi-extension FITS file. Fortunately SAO ds9 also provides options
that you can use to specify a particular behavior. One of those
options is @option{-mecube} which opens a FITS image as a
multi-extension data cube. So on the command line, if you run
@command{$ds9 -mecube foo.fits} a small window will also be opened,
which allows you to switch between the image extensions that
@file{foo.fits} might have. If @file{foo.fits} only consists of one
extension, then SAO ds9 will open as usual.

Just to avoid confusion, note that SAO ds9 does not follow the GNU
style of separating long and short options as explained in
@ref{Arguments and options}. In the GNU style, this `long' option
should have been called like @option{--mecube}, but SAO ds9 does
follow those conventions and has its own.

@cindex GNOME 3
It is really convenient if you set ds9 to always run with the
@option{-mecube} option on your graphical display. On GNOME 3 (the
most popular graphic user interface for GNU/Linux systems) you can do
this by taking the following steps:

@itemize

@item
@cindex @file{.desktop}
Open your favorite text editor and put the following text in a file
that ends with @file{.desktop}, for example @file{saods9.desktop}. The
file is very descriptive.
@example
[Desktop Entry]
Type=Application
Version=1.0
Name=SAO ds9
Comment=View FITS images
Exec=ds9 -mecube %f
Terminal=false
Categories=Graphic;FITS;
@end example

@item
Copy this file into your local (user) applications directory:
@example
$ cp saods9.desktop ~/.local/share/applications/
@end example
In case you don't have the directory, you can make it your self:

@example
$ mkdir -p ~/.local/share/applications/
@end example

@item
The steps above will add SAO ds9 as one of your applications. To make
it default for every time you click on a FITS file. Right click on a
FITS file and select ``Open With'', then go into ``Other
Application...'' and choose ``SAO ds9''.
@end itemize

@cindex GNOME 2
In case you are using GNOME 2 you can take the following steps: right
click on a FITS file and choose @clicksequence{Properties@click{}Open
With@click{}Add} button. A list of applications will show up, ds9
might already be present in the list, but don't choose it because it
will run with no options. Below the list is an option ``Use a custom
command''. Click on it and write the following command: @command{ds9
-mecube} in the box and click ``Add''. Then finally choose the command
you just added as the default and click the ``Close'' button.





@node PGPLOT,  , SAO ds9, Other useful software
@section PGPLOT

@cindex PGPLOT
@cindex C, plotting
@cindex Plotting directly in C
PGPLOT is a package for making plots in C. It is not directly needed
by Gnuastro, but can be used by WCSLIB, see @ref{WCSLIB}. As
explained in @ref{WCSLIB}, you can install WCSLIB without it too. It
is very old (the most recent version was released early 2001!), but
remains one of the main packages for plotting directly in C. WCSLIB
uses this package to make plots if you want it to make plots. If you
are interested you can also use it for your own purposes.

@cindex Python Matplotlib
@cindex Matplotlib, Python
@cindex PGFplots in @TeX{} or @LaTeX{}
If you want your plotting codes in between your C program, PGPLOT is
currently one of your best options. The recommended alternative to
this method is to get the raw data for the plots in text files and
input them into any of the various more modern and capable plotting
tools separately, for example the Matplotlib library in Python or
PGFplots in @LaTeX{}. This will also significantly help code
readability. Let's get back to PGPLOT for the sake of
WCSLIB. Installing it is a little tricky (mainly because it is so
old!).

You can download the most recent version from the FTP link in its
webpage@footnote{@url{http://www.astro.caltech.edu/~tjp/pgplot/}}. You
can unpack it with the @command{tar -vxzf} command. Let's assume the
directory you have unpacked it to is @file{PGPLOT}, most probably it
is: @file{/home/username/Downloads/pgplot/}.  open the
@file{drivers.list} file:
@example
$ gedit drivers.list
@end example
@noindent
Remove the @code{!} for the following lines and save the file in the
end:
@example
PSDRIV 1 /PS
PSDRIV 2 /VPS
PSDRIV 3 /CPS
PSDRIV 4 /VCPS
XWDRIV 1 /XWINDOW
XWDRIV 2 /XSERVE
@end example
@noindent
Don't choose GIF or VGIF, there is a problem in their codes.

Open the @file{PGPLOT/sys_linux/g77_gcc.conf} file:
@example
$ gedit PGPLOT/sys_linux/g77_gcc.conf
@end example
@noindent
change the line saying: @code{FCOMPL="g77"} to
@code{FCOMPL="gfortran"}, and save it. This is a very important step
during the compilation of the code if you are in GNU/Linux. You now
have to create a folder in @file{/usr/local}, don't forget to replace
@file{PGPLOT} with your unpacked address:
@example
$ su
# mkdir /usr/local/pgplot
# cd /usr/local/pgplot
# cp PGPLOT/drivers.list ./
@end example
To make the Makefile, type the following command:
@example
# PGPLOT/makemake PGPLOT linux g77_gcc
@end example
@noindent
It should finish by saying: @command{Determining object file
dependencies}. You have done the hard part! The rest is easy: run
these three commands in order:
@example
# make
# make clean
# make cpg
@end example

Finally you have to place the position of this directory you just made
into the @command{LD_LIBRARY_PATH} environment variable and define the
environment variable @command{PGPLOT_DIR}. To do that, you have to
edit your @file{.bashrc} file:
@example
$ cd ~
$ gedit .bashrc
@end example
@noindent
Copy these lines into the text editor and save it:
@cindex @file{LD_LIBRARY_PATH}
@example
PGPLOT_DIR="/usr/local/pgplot/"; export PGPLOT_DIR
LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/pgplot/
export LD_LIBRARY_PATH
@end example
@noindent
You need to log out and log back in again so these definitions take
effect. After you logged back in, you want to see the result of all
this labor, right? Tim Pearson has done that for you, create a
temporary folder in your home directory and copy all the demonstration
files in it:
@example
$ cd ~
$ mkdir temp
$ cd temp
$ cp /usr/local/pgplot/pgdemo* ./
$ ls
@end example
You will see a lot of pgdemoXX files, where XX is a number. In order
to execute them type the following command and drink your coffee while
looking at all the beautiful plots! You are now ready to create your
own.
@example
$ ./pgdemoXX
@end example




















@node GNU Free Documentation License, Index, Other useful software, Top
@appendix GNU Free Documentation License

@cindex GNU Free Documentation License
@include fdl.texi





@c Print the index and finish:
@node Index,  , GNU Free Documentation License, Top
@unnumbered Index
@printindex cp


@bye
