\input texinfo @c -*-texinfo-*-
@c %**start of header
@setfilename gnuastro.info
@settitle GNU Astronomy Utilities
@documentencoding UTF-8
@allowcodebreaks false
@c@afourpaper

@c %**end of header
@include version.texi
@include formath.texi
@include subpackageversions.texi

@c Use section titles in cross references, not node titles.
@xrefautomaticsectiontitle on

@c For the indexes:
@syncodeindex fn cp
@syncodeindex vr cp
@syncodeindex pg cp

@c Copyright information:
@copying
This manual documents version @value{VERSION} of the GNU Astronomy
Utilities, providing various individual tools with similar user
interface for astronomical data manipulation and  analysis.

Copyright @copyright{} 2015 Free Software Foundation, Inc.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with no
Invariant Sections, with no Front-Cover Texts, and with no Back-Cover
Texts.  A copy of the license is included in the section entitled
``GNU Free Documentation License''.
@end quotation
@end copying

@c To include in the info directory.
@dircategory Astronomy
@direntry
* gnuastro: (gnuastro).       GNU Astronomy Utilities.

* ConvertType: (gnuastro)ConvertType. Convert different file types.
* astconvertt: (gnuastro)Invoking astconvertt. Options to ConvertType.

* ImageCrop: (gnuastro)ImageCrop. Crop region(s) from image(s).
* astimgcrop: (gnuastro)Invoking astimgcrop. Options to ImageCrop.

* MakeProfiles: (gnuastro)MakeProfiles. Make mock profiles.
* astmkprof: (gnuastro)Invoking astmkprof. Options to MakeProfiles.

@end direntry

@c Version of all the subpackages:
@macro printversions
@noindent
@*ConvertType (@command{astconvertt}) @value{CONVERTT_VERSION}
@*ImageCrop (@command{astimgcrop}) @value{IMGCROP_VERSION}
@*MakeProfiles (@command{astmkprof}) @value{MKPROF_VERSION}
@end macro




















@c Print title information:
@titlepage
@title GNU Astronomy Utilities
@subtitle Astronomical data manipulation and analysis
@subtitle for version @value{VERSION}, @value{UPDATED}
@author Mohammad Akhlaghi

@page
@printversions
@vskip 0pt plus 1filll
@insertcopying

@page
@quotation
What in operation is most useful, that in knowledge is most true.
@author Francis Bacon, New organon, 1620.
@end quotation
@quotation
@*
@*
@*
@*
@*
@*
@*
@*
@*
For myself, I am interested in science and in philosophy only because
I want to learn something about the riddle of the world in which we
live, and the riddle of man’s knowledge of that world. And I believe
that only a revival of interest in these riddles can save the sciences
and philosophy from narrow specialization and from an obscurantist
faith in the expert’s special skill, and in his personal knowledge and
authority; a faith that so well fits our ‘post-rationalist’ and
‘post-critical’ age, proudly dedicated to the destruction of the
tradition of rational philosophy, and of rational thought itself.
@author Karl Popper. The logic of scientific discovery. 1959.
@end quotation

@end titlepage
@shortcontents
@contents











@c Online version top information.
@ifnottex
@node Top, Introduction, (dir), (dir)
@top GNU Astronomy Utilities

@insertcopying

@ifhtml
To navigate easily in this web page, you can use the @code{Next},
@code{Previous}, @code{Up} and @code{Contents} links in the top and
bottom of each page. @code{Next} and @code{Previous} will take you to
the next or previous topic in the same level, for example from chapter
1 to chapter 2 or vice versa. To go to the sections or subsections,
you have to click on the menu entries that are there when ever a
sub-component to a title is present.
@end ifhtml

@printversions

@end ifnottex

@menu
* Introduction::                General introduction.
* Installation::                Requirements and installation.
* Common behavior::             Common behaviour in all programs.
* Files::                       File information and type conversion.
* Header manipulation::         Tools to Read/Write Headers.
* Image manipulation::          Tools for basic image manipulation.
* Image analysis::              Analyze images.
* Modeling and fittings::       Make and fit models.
* Table manipulation::          Read/Write tables.
* Developing::                  The development environment.
* GNU Free Documentation License::  Full FDL text.
* Index::                       Index of terms

@detailmenu
 --- The Detailed Node Listing ---

Introduction

* Quick start::                 A quick start to installation.
* Science and software::        The importance of software in science.
* Why C::                       Why we chose the C?
* Your rights::                 User rights.
* Design philosophy::           How we have designed gnuastro.
* Version numbering::           Understanding version numbers.
* New to GNU/Linux?::           Suggested GNU/Linux distribution.

Version numbering

* GNU Astronomy Utilities 1.0::  Plans for version 1.0 release

Installation

* Requirements::                gnuastro requirements
* Installing gnuastro::         Installing gnuastro

Requirements

* GNU Scientific Library::      Installing GSL.
* CFITSIO::                     Standard library for FITS I/O.
* WCSLIB::                      Library for world coordinate systems.
* libjpeg::                     Library for JPEG image manipulation.
* FFTW::                        Fast Fourier transform library.
* SAO ds9::                     SAO ds9 for viewing FITS images.

WCSLIB

* PGPLOT::                      Installing PGPLOT (can be needed by WCSLIB).

SAO ds9

* Viewing multiextension FITS::  Configure SAO ds9 for multiextension images.

Installing GNU Astronomy Utilities

* Configuring::                 Configure gnuastro
* Tests::                       Run tests to see if it is working.
* Print manual::                Customize the print manual.

Configuring

* gnuastro configure options::  Configure options particular to gnuastro.
* Installation directory::      Specify the directory to install.
* Executable names::            Changing executable names.

Common behavior

* Command line::                How to use the command line.
* Configuration files::         Values for unspecified variables.
* Threads in gnuastro::         How threads are managed in gnuastro.
* Final parameter values::      The final set of used parameters.
* Automatic output::            About automatic output names.
* Getting help::                Getting more information on the go.
* Output headers::              Common headers to all FITS outputs.

Command line

* Arguments and options::       Basics of options and arguments.
* Arguments::                   Treatment of arguments.
* Option basics::               How to use GNU style options.
* Common options::              Common options to all gnuastro programs.

Common options

* Input output::                Common input/output options.
* Operating modes::             Common operating mode options.

Configuration files

* Configuration file format::   ASCII format of configuration file.
* Configuration file precedence::  Precedence of configuration files.
* Current directory and User wide::  Local and user configuration files.
* System wide::                 System wide configuration files.

Threads in gnuastro

* A note on threads::           Caution and suggestion on using threads.

Getting help

* --usage::                     Only view option names and value formats.
* --help::                      List all options with description.
* Man pages::                   Man pages generated from --help.
* Info::                        View complete manual in terminal.

Files

* FileInfo::                    List all the extensions in a file.
* ConvertType::                 Convert data to various formats.

ConvertType

* Recognized file types::       Recognized file types
* Color::                       Some explanations on color.
* Invoking astconvertt::        Options and arguments to ConvertType.
* ConvertType future updates::  Plans for future updates.

Image manipulation

* ImageCrop::                   Crop region(s) from FITS image(s).
* ImageTransform::              Transform (flip, rotate) an image.
* ImageArith::                  Apply arithmetics on image(s).
* EllipMask::                   Place elliptical masks on an image.

ImageCrop

* ImageCrop modes::             Basic ImageCrop modes.
* Crop section syntax::         How to define a section to crop.
* Blank pixels::                Pixels with no value.
* Invoking astimgcrop::         Calling ImageCrop on the command line
* ImageCrop future::            Future updates to ImageCrop.

Invoking ImageCrop

* astimgcrop options::          A list of all the options with explanation.
* astimgcrop output::           The outputs of ImageCrop.

Image analysis

* ImageStat::                   Basic statstics of image pixels
* SubtractSky::                 Subtract the sky level from the image.
* NoiseChisel::                 Detect and segment objects in noise.

Modeling and fitting

* Modeling basics::             Astronomical modeling basics.
* MakeProfiles::                Making mock galaxies and stars.

Modeling basics

* Defining an ellipse::         Defining an ellipse in 2D.
* PSF::                         Radial profiles for the PSF.
* Stars::                       Making mock star profiles.
* Galaxies::                    Radial profiles for galaxies.
* Sampling from a function::    Sample a function on a pixelated canvas.
* Oversampling::                Oversampling the model.
* Noise::                       The basics of noise.

Noise

* Photon counting noise::       Poisson noise
* Instrumental noise::          Readout, dark current and other sources.
* Final noised pixel value::    How the final noised value is calculated.

MakeProfiles

* If convolving afterwards::    Considerations for convolving afterwards.
* Profile total magnitude::     Definition of total profile magnitude.
* Invoking astmkprof::          Inputs and Options for MakeProfiles.
* MakeProfiles future updates::  Plans for the future of MakeProfiles.

Invoking MakeProfiles

* MakeProfiles catalog::        Required catalog properties.
* MakeProfiles options::        Full list of MakeProfiles options.
* MakeProfiles output::         The generated outputs.

Developing

* Version controlled source::   How to get and prepare the VCSed code.
* Internal libraries::          Internal static (not installed) libraries.
* Headers::                     Library and common headers.
* Program source::              Conventions for the code.
* Test scripts::                Understanding the test scripts.
* Building::                    Explanations on building.
* After making changes::        Run `make distcheck` after making changes.

Version controlled source

* Standards::

Program source

* Coding conventions::          Conventions used for coding
* Multithreaded programming::

@end detailmenu
@end menu

@node Introduction, Installation, Top, Top
@chapter Introduction

The GNU Astronomy Utilities (gnuastro) are a set of separate programs
to facilitate the manipulation and analysis of astronomical data. All
the various utilities share the same basic command line user interface
for the comfort of both the users and developers. GNU Astronomy
Utilities is written to comply fully with the GNU coding standards so
it integrates finely with the GNU/Linux operating system. This also
enables astronomers to expect a fully familiar experience in the
source code, building, installing and command line user interaction
that they have seen in all the other GNU software that they use.

For users who are new to the GNU/Linux environment, we would like to
mention that unless otherwise specified most of the topics in chapters
2 and 3 are common to all GNU software, for example installation,
managing command line options or getting help. So if you are new to
this environment, we encourage you to go through these chapters
carefully. They can be a starting point from which you can continue to
learn more from each program's own manual and fully enjoy this
wonderful environment. We have tried our best to write this manual so
someone who is completely new to GNU/Linux can get going very soon.

Finally it must be mentioned that in gnuastro, no change to any
program will be released before it has been fully documented in this
manual first. As discussed in @ref{Science and software} this is the
founding basis of the GNU Astronomy Utilities.

@menu
* Quick start::                 A quick start to installation.
* Science and software::        The importance of software in science.
* Why C::                       Why we chose the C?
* Your rights::                 User rights.
* Design philosophy::           How we have designed gnuastro.
* Version numbering::           Understanding version numbers.
* New to GNU/Linux?::           Suggested GNU/Linux distribution.
@end menu

@node Quick start, Science and software, Introduction, Introduction
@section Quick start

@cindex Uncompress source
@cindex Source, uncompress
@cindex Build
@cindex Compile
@cindex Check
@cindex Test
Lets assume you have just downloaded the
@file{gnuastro-@value{VERSION}.tar.gz} in the @file{DOWLD}
directory. Running the following commands will unpack, compile, check
and install all the GNU Astronomy Utilities so you can use them
anywhere in your system.

@example
$ cd DOWLD
$ tar -zxvf gnuastro-@value{VERSION}.tar.gz
$ cd gnuastro-@value{VERSION}
$ ./configure
$ make
$ make check
$ sudo make install
$ cd ../
$ rm -rf gnuastro-@value{VERSION} gnuastro-@value{VERSION}.tar.gz
@end example

@noindent
If @command{$ ./configure} complains about a requirement, see
@ref{Requirements}. After running @command{$ make check}, a few tests
will be done on the built product. They shouldn't fail, if they do
please file a bug report. You can also make lots of customizations,
for example installing when you don't have root access, building and
installing only a subset of the utilities or modifying their names,
see @ref{Configuring}.

In this manual we have tried to explain concepts thoroughly for a new
GNU/Linux user or astronomy data analyzer. In case you are already
familiar with both, you just have to check the ``Invoking
ProgramName'' section for the program you want to use by running
@command{info astprogname} on the command line. The commands above
will delete the source code after installing the programs,
configuration files and documentation. In case you want to study the
code, we recommend getting the version controlled source code, see
@ref{Version controlled source}.

@node Science and software, Why C, Quick start, Introduction
@section Science and its software
@cindex Transparent software
@cindex Approximations in science
@cindex Simplifications in science
@cindex Software in Science
@cindex Science and software
History of science is evidence that no interpretation, model or
technique is perfect. There are always inevitably unseen faults,
hidden assumptions, simplifications and approximations in all our
theoretical models and data aquisition and analysis techniques. It is
precisely these that will ultimately allow future generations to
advance the existing experimental and theoretical knowledge through
their new solutions and corrections. Therefore for the advance of
science, it is imperative that we be as explicit as possible about
such approximations and simplifications.

Both theoretical modeling and experimental methods are today becoming
more and more dependent on software. Therefore, by keeping software
free and transparent for all scientists, through readable code and an
up to date manual, we can most accurately convey our experiences to
other scientists who can build on those or find their shortcomings,
hence facilitating the progress of science. In the past, scientists
would gather data and process them individually to achieve an
analysis, today scientists mainly leave the first two steps to
pre-written software libraries, therefore distancing themselves from
the intracacies of reducing raw observational data in experimentation
or of bringing the theoretical models to life in simulations.

@cindex Anscombe, F.J
@quotation
Unfortunately, most persons who have recourse to a computer for
statistical analysis of data are not much interested either in
computer programming or in statistical method, being primarily
concerned with their own proper business. Hence the common use of
library programs and various statistical packages. Most of these
originated in the pre-visual era. The user is not showered with
graphical displays. He can get them only with trouble, cunning and a
fighting spirit. It's time that was changed.
@author F. J. Anscombe. The American Statistician, Vol. 27, No. 1. 1973
@end quotation

@cindex Good statistical analysis
@cindex Anscombe quartet
@cindex Obscure software
Anscombe argues that ``Good statistical analysis is not a purely
routine matter, and generally calls for more than one pass through the
computer''. Through the Anscombe's
quartet@footnote{@url{http://en.wikipedia.org/wiki/Anscombe%27s_quartet}}
he demonstrated how four data sets with widely different shapes (when
plotted) give nearly identical output from standard regression
techniques. Thus he showed how wrong it is to only rely on outputs of
standard methods to interpret the data. Although we have much better
graphic displays today, unfortunately the general situation has not
changed too much from Anscombe's time.  Obscure software is certainly
one of the main culprits. By obscure (not transparent) software we
mean:

@itemize

@item
Proprietary software that is only distributed in a compiled
format. The users of such software are forced to view it as a black
box.

@item
Software with restrictive licenses. For example when no license is
specified, also "Academic-use Only" licenses. In such software, the
users cannot modify the code.

@item
Software with its source code available, but with complex programming
constructs that require a lot of time to learn for correct usage and
understanding.

@item
Software with an outdated or weakly written manual.

@end itemize

Even if a software is released under the GNU public license (GPL), the
latter two issues force an interested scientist to think twice before
trying to understand the inner workings of the software she uses. When
the audience admits ignorance to the inner workings of a software
(most non-scientific software), this is fine. But no scientist, using
a scientific software for their scientific research would want to be
considered ignorant.

The users of a software cannot claim to understand how it works only
based on the experience they have gained by frequently using it. This
kind of subjective experience is prone to very serious
mis-understandings about what it really does behind the scenes. It
only helps in producing dogmas and an ``obscurantist faith in the
expert's special skill''.  Unfortunately in the commonly used
astronomical software packages at least, most are not transparent as
defined above. The scientific results that are deduced from such
software are thus not objective, because scientists have to, or are
forced to, look at it as a black box and trust its results on faith or
their subjective experience.

The wide use of free and transparent software is the clear solution to
these problems. A software package that uses a sufficiently low-level
programming paradigm (which is easier for the human to inquire into
and for the computer to run) and comes with an up-to-date and
accessible manual and a standard user interface may be one step in a
larger scheme to save the sciences from the ``obscurantist faith in
the expert’s special skill, and in his personal knowledge and
authority'' (quote from Karl Popper, for full quote see the beginning
of the PDF version of this manual).

It is certainly time consuming for the author of a software to write
clean codes and keep an updated manual. But if our greater common
experience is considered, that time, is a time very well
invested. Through sharing of these fundamental ideas and
techniques, that define all our scientific results, and keeping them
open to criticism, we can make them more robust and thus take larger
steps in our common goal to tackle the riddles of nature.

There are lots of separate software currently avaiable that do the
majority of what the astronomical community desires separately. Most
of them are also distributed under the GPL. Added with the mostly free
raw data from major telescopes, this seems like a scientist's
Utopia. However, as described above, a free distribution with the GPL
is not enough. In Richard Stallman's words, the software should be
``free as in free speech not free beer''. No matter how much a society
values ``free speech'', if the people do not use that freedom, they
are not free. They only live in its illusion.

Bjarne Stroustrup (creator of the C++ language) says: ``Without
understanding software, you are reduced to believing in magic''.  Ken
Thomson (the designer or the Unix operating system) says ``I abhor a
system designed for the ``user'' if that word is a coded pejorative
meaning ``stupid and unsophisticated''.'' No scientist would want to
be considered as ``stupid and unsophisticated'', so both these cases
naturally apply much more seriously to programs written for scientific
applications and as scientists we should be loyal to such principles
if we want to remain critical and be objective.




@node Why C, Your rights, Science and software, Introduction
@section Why C programming language?
Currently the programming language that is most commonly used in
scientific applications is C++, and more recently Python. One of the
main reasons behind this choice is that through the Object oriented
programming paradigm, they offer a much higher level of
abstraction. However, we have chosen the C programming language to
write gnuastro. The reasons can be summarized with simplicity and
speed. Both are extremely important in a scientific software.

A simple comparison of the main books of C++ and C can act as a
guide. The ``C programming language'' book, written by the authors of
C, is only 286 pages and covers a very good fraction of the language,
it has also remained unchanged from 1988 and there is no plan of any
significant update. The most recent ``C++ programming language'' book,
also written by its author, on the other hand has 1366 pages and its
fourth edition came out in 2013! As discussed in @ref{Science and
software}, it is very important for other scientists to be able to
readily read the code of a program at their will with minimum
requirements.

In C++, inheriting objects and their internal functions make the code
very easy to write for the programmer who is deeply invested in those
objects and understands all their relations well. But it
simultaneously makes reading the program for a first time reader (a
curious scientist who wants to know only how a small step was done)
extremely hard. Before understanding the methods, the scientist has to
invest a lot of time in understanding those objects and their
relations. But in C, if only simple structures are used, as we have
here, all variables can be given as the basic language types for
example @code{int}s or @code{float}s and their pointers to define
arrays. So when an outside reader is only interested in one part of
the program, that part is all they have to understand.

Recently it is also becoming common to write scientific software in
Python, or a combination of it with C or C++. Python is a high level
scripting language which doesn't need compilation. It is very useful
when you want to do something on the go and don't want to be halted by
the troubles of compiling, linking, memory checking, etc. When the
data sets are small and the job is temporary, this ability of Python
is great and is highly encouraged. A very good example might be
plotting, in which Python is undoubtably one of the best.

But as the data sets increase in size and the processing becomes very
complicated, the speed of Python scripts significantly decrease. So
when the program doesn't change too often and is widely used in a
large community mostly on large data sets (like astronomical images),
using Python will waste a lot of valuable research-hours.

Like C++, python is object oriented, so as explained above, it needs a
high level of experience with that particular program to fully
understand its inner workings. To make things worse, since it is
mainly for fast and on the go programming, it constantly undergoes
significant changes, such that Python 2.x and Python 3.x are not
compatible. Lots of research teams that invested heavily in Python 2.x
cannot benefit from Python 3.x or future versions any more. Some
converters are available, but since they are automatic, lots of
complications might arise in the conversion. Thus, re-writing all the
changes would be the only truely reliable option. This is why most
teams that made that choice are forced to remain with Python 2.x. If a
research project begins using Python 3.x today, there is no telling
how compatible their investments will be when Python 4.x or 5.x will
come out. This stems from the core principles of Python, which are
very useful when you look in the ``on the go'' basis as described
before and not future usage.

@cindex Low level programming
@cindex Programming, low level
Being a very low level (closer to the hardware) language, C is much
less complex for both the human reader and the computer. It thus
allows for closer relation between the programmer (program) and the
actual data we have in our disposal. This is contrary to the illusion
of abstractions that the higher level languages provide. The GNU
coding standards@footnote{@url{http://www.gnu.org/prep/standards/}}
also encourage the use of C over all other languages when generality
of usage and ``high speed'' is desired.





@node Your rights, Design philosophy, Why C, Introduction
@section Your rights

The paragraphs below, in this section, belong to the GNU Texinfo
manual and are not written by us! We have just changed the name
``Texinfo'' to ``GNU Astronomy Utilities'' or ``gnuastro'' because
they are released under the same licenses and it is beautifully
written to inform you of your rights.

@cindex Free software
GNU Astronomy Utilities is ``free software''; this means that everyone
is free to use it and free to redistribute it on certain
conditions. GNU Astronomy Utilities is not in the public domain; it is
copyrighted and there are restrictions on its distribution, but these
restrictions are designed to permit everything that a good cooperating
citizen would want to do.  What is not allowed is to try to prevent
others from further sharing any version of gnuastro that they might
get from you.

Specifically, we want to make sure that you have the right to give
away copies of the programs that relate to gnuastro, that you receive
the source code or else can get it if you want it, that you can change these
programs or use pieces of them in new free programs, and that you know
you can do these things.

To make sure that everyone has such rights, we have to forbid you to
deprive anyone else of these rights.  For example, if you distribute
copies of the gnuastro related programs, you must give the recipients
all the rights that you have.  You must make sure that they, too,
receive or can get the source code.  And you must tell them their
rights.

Also, for our own protection, we must make certain that everyone finds
out that there is no warranty for the programs that relate to gnuastro.
If these programs are modified by someone else and passed on, we want
their recipients to know that what they have is not what we distributed,
so that any problems introduced by others will not reflect on our
reputation.

The precise conditions of the licenses for the programs currently
being distributed that relate to gnuastro are found in the
@url{http://www.gnu.org/copyleft/gpl.html, GNU General Public license}
that accompany them.  This manual is covered by the
@url{http://www.gnu.org/copyleft/fdl.html, GNU Free Documentation
License}.





@node Design philosophy, Version numbering, Your rights, Introduction
@section Design philosophy

Based on the ideas in the above three sections, gnuastro is desiged
such that the only basic requirement for a scientist to understand the
most intricate detail of any step in gnuastro is a knowledge of the C
programming language as defied in Kernighan and Ritchie's 1989 book,
which is commonly known as K&R and is the definition book for the ISO
C standard of 1990. As explained above, with less than 300 pages, this
book is very concize and basic. Even within the confines of K&R, the
code can become quite complex, therefore all gnuastro programs are
written with code readibility (particularly though lots of comments
within the code) as the primary goal.

We do make lots of use of the GNU additions to the C language in the
GNU C library, but they are mainly in the user interface functions
(reading your inputs and preparing them prior to or after the
analysis). The actual algorithms, which most scientists would be more
interested in, are much more closer to ISO C90. For this reason, the
source files containing user interface code and those containing
actual processing code are clearly separated. If any thing particular
to the GNU C library is used, in those functions, it is explained in
the comments in the code.

In @ref{Developing} we have explained all the details of the core
programming ideas behind gnuastro. Reading that chapter should be
enough for you to begin going through the codes of an existing package
or creating a new one for your needs using the infra-structure
provided. We hope that with this infra-structure we can extend what
GNU did for the software community in the early 1980s to the
Astronomical community.

Similar to GNU Coreutils, all the programs provided with gnuastro,
provide very low level operations. This enables you to use the GNU
Bash scripting language (which is the default in most GNU/Linux
operating systems) or any other shell you might be using to operate on
a large number of files or do very complex things through the creative
combinations of these tools that the authors had never dreamed of.

For example all the analysis output is provided as ASCII tables which
you can feed into your favorite plotting program to inspect
visually. Python's Matplotlib is very useful for fast plotting of the
tables to immediately check your results. If you want to include the
plots in a document, you can use the PGFplots package within
@LaTeX{}. We make no attempt to include such operations in
gnuastro. In short, Bash can act as a glue to connect the inputs and
outputs of all these various programs in any fashion you please. If
you are not already familiar with the command line or don't fully feel
comfortable with it please see @ref{New to GNU/Linux?}.



@node Version numbering, New to GNU/Linux?, Design philosophy, Introduction
@section Version numbering

The general gnuastro package has a version number. It contains
various programs and each of those also has its own version
number. The version numbers for both are two numbers with a point
(@file{.}) between them. The left number is the major version number
while the right one is the minor version number. Note that the numbers
are not decimals, so version 2.34 of a program is much more recent
than version 2.5, which is not equal to 2.50!

The current version of gnuastro is @value{VERSION} and the version
numbers of its various components are shown on the second page in the
PDF manual and on the top node or page in the other formats (Info and
HTML for example). To see the version of a program you are using, you
can use the @option{--version} option, see @ref{Common options}.

GNU Astronomy Utilities and all programs within it start with version
number 0.1. For the programs, the minor version number is increased
with any few bug fixes or small improvements which the developers
decide is significant for a public release. So minor releases can be
viewed as ad-hoc improvements. The major version number is set by a
major goal which is defined by the developers of that particular
program before hand.

For gnuastro, its minor version number increases by 1 on every
release (which contains an arbitary number of updated version numbers
for the programs). So you can tell that at least one package has been
updated at least once. You can see the details from the @file{NEWS}
file that comes with that distribution and is also available online to
view before you download.

@menu
* GNU Astronomy Utilities 1.0::  Plans for version 1.0 release
@end menu

@node GNU Astronomy Utilities 1.0,  , Version numbering, Version numbering
@subsection GNU Astronomy Utilities 1.0

The major version number of gnuastro is increased similar to that of
each program. Currently (prior to gnuastro 1.0), the aim is to have a
complete system for data manipulation and analysis at least similar to
IRAF@footnote{@url{http://iraf.noao.edu/}}. So an astronomer can take
all the standard data analysis steps (starting from raw data to the
final reduced product and standard post-reduction tools) with the
various programs in gnuastro.

The maintainers of each camera or detector on a telescope can provide
a completely transparent shell script to the observer for data
analysis. This script can set configuration files for all the required
programs to work with that particular camera. The script can then run
the proper programs in the proper sequence. The user/observer can
easily follow the standard shell script to understand (and modify)
each step and the parameters used easily. Bash (or other modern
GNU/Linux shell scripts) are very powerful and made for this gluing
job. This will simultaneously improve preformance and transparency.

In order to achieve this and allow maximal creativity with the shell,
the various programs have to be very low level programs and completely
independent. Something like the GNU Coreutils.





@node New to GNU/Linux?,  , Version numbering, Introduction
@section New to GNU/Linux?

Some astronomers initially install and use the GNU/Linux operating
systems because their research software can only be run in this
environment. This is how the founder of gnuastro started using
GNU/Linux at least! If this is not the case for you, you can skip the
following.

You might have already noticed that we are not using the name
``Linux'', but ``GNU/Linux''. Please take the time to have a look at
the following essays and FAQs for a complete understanding of this
very important distinction.

@itemize

@item
@url{https://www.gnu.org/gnu/gnu-users-never-heard-of-gnu.html}

@item
@url{https://www.gnu.org/gnu/linux-and-gnu.html}

@item
@url{https://www.gnu.org/gnu/why-gnu-linux.html}

@item
@url{https://www.gnu.org/gnu/gnu-linux-faq.html}

@end itemize

Another thing you will notice is that gnuastro only has a command line
user interface (CLI). This might be contrary to your mosly graphical
user interface (GUI) experience with proprietary operating systems. To
a first time user, the command line does appear much more complicated
and adapting to it might not be easy. So in the following we give a
brief introduction and comparison of these two major types of user
interaction in a program and which are best for what kind of
operations.

Although with GNOME 3@footnote{@url{http://www.gnome.org/}}, most
GNU/Linux based operating systems now have a very advanced and useful
GUI, still most of the work of any GNU/Linux user will be on the CLI
or in the ``shell'' as it is better known in the Unix-like
systems. Since the GUI was created long after the command line, some
wrongly consider the command line to be obsolete. Both interfaces are
very useful for different tasks (for example you can't view an image,
video or webpage on the command line!). Therefore they should not be
regarded as rivals but as complementary, here we will outline how the
CLI can be useful in scientific programs.

You can think of the GUI as a veneer over the CLI to facilitate a
small subset of all the possible CLI operations. Each click you do on
the GUI, can be thought of as internally running a different
command. So assymptotically (if a good designer can design a GUI which
is able to show you all the possibilites to click on) the GUI is only
as powerful as the command line. In practice, such designers are very
hard to come by for every program, so the GUI operations are always a
subset of the internal CLI commands. For programs that are only made
for the GUI, this results in not including lots of potentially useful
operations. It also reasults in ``interface design'' to be a crutially
important part of any GUI program. Scientists don't usually have
enough resources to hire a graphical designer, also the complexity of
the GUI code is far more than CLI code, which is harmful for a
scientific software, see @ref{Science and software}.

For those operations with a GUI, one action on the GUI might be more
efficient. However, if you have to repeat that same action more than
once, it will soon become very frustrating and prone to errors. Unless
the designers of a particular program decided to design such a system
for a particular GUI action, there is no general way to run everything
automatically on the GUI.

On the command line, with one command you can run numerous actions
which can come from various CLI capable programs you have decided your
self in any possible permutation with one command@footnote{By writing
a shell script and running it.}. This allows for much more creativity
than that offered to a GUI user. For technical and scientific
operations, where the same operation (using various programs) has to
be done on a large set of data files, this is crucially important. It
also allows exact reproducability which is a foundation principle for
scientific results. The most common CLI (which is also known as a
shell) in GNU/Linux is GNU Bash, we strongly encourage you to put
aside several hours and go through this beautifully explained webpage:
@url{https://flossmanuals.net/command-line/}. You don't need to read
the whole thing, only the first few chapters are enough to get you
going.

Since the operations in the GUI are very limited and they are visible,
reading a manual is not that important in the GUI (most programs don't
even have any!). However, to give you the creative power explained
above, with a CLI program, it is best if you first read the manual of
any program you are using. You don't need to memorize any details,
only an understanding of the generalities is needed. Once you start
working, there are more easier ways to remember a particular option or
operation detail, see @ref{Getting help}.

To experience the command line in its full glory and not in the GUI
terminal emulator, press the following keys together:
@key{CTRL+ALT+F4}@footnote{Instead of @key{F4}, you can use any of the
keys from @key{F2} to @key{F6} for different virtual consoles. You can
also run a separate GUI from within this console.} to access the
virtual console. To return back to your GUI, press the same keys above
replacing @key{F4} with @key{F1}. In the virtual console, the GUI,
with all its distracting colors and information, is gone. Enabling you
to focus more accurately on your actual work.

For operations that use a lot of your system's resources (processing a
large number of large astronomical images for example), the virtual
console is the place to run them. This is because the GUI is not
competing with your research work for your system's RAM and CPU. Since
the virtual consoles are completely independent, you can even log out
of your GUI environment to give even more of your hardware resources
to the programs you are running and thus reduce the operating time.

Since it uses far less system resources, the CLI is also very
convenient for remote access to your computer. Using secure shell
(SSH) you can login securely to your system (similar to the virtual
console) from anywhere even if the connection speeds are slow. There
are apps for smartphones and tablets which allow you to do this.























@node Installation, Common behavior, Introduction, Top
@chapter Installation

To successfully install gnuastro you have to have the requirements
already installed on your system. They are very basic for most
astronomical programs and you might already have them installed. To
check try running the @command{$ ./configure} script. If you get no
errors, then you already have them and you can skip
@ref{Requirements}. You can heavily customize your install of
gnuastro, to learn more about them, see @ref{Installing gnuastro}.



@menu
* Requirements::                gnuastro requirements
* Installing gnuastro::         Installing gnuastro
@end menu

@node Requirements, Installing gnuastro, Installation, Installation
@section Requirements

@cindex Dependencies, gnuastro
GNU Astronomy Utilities @value{VERSION} have several dependencies,
they all follow the same basic GNU based build system, so even if you
don't have them, installing them should be pretty streightforward. In
this section we explain each program and any specific note that might
be necessary in the installation.

These packages might already be available by your distribution's
package management system. But as explained for each package,
gnuastro might require certain configuration options that the your
distribution's package managers didn't add for you. The most basic
choice is to build the packages from source your self instead of
relying on your distribution's pre-built packages.

The problem with building from souce manually is that the package will
be left out of the list of installed packages in your package
manager. So for example when you want to do a system-wide update, it
will not check for the packages you manually built. However, if your
distribution has a configurable build system (for example the Arch
Build
System@footnote{@url{https://wiki.archlinux.org/index.php/Arch_Build_System}}
in the Parabola or Arch GNU/Linux distributions), you can configure
the build options of specific packages your self. When an update
comes, it will only warn you instead of installing the pre-built
package so you can build it with your own particular options.


@menu
* GNU Scientific Library::      Installing GSL.
* CFITSIO::                     Standard library for FITS I/O.
* WCSLIB::                      Library for world coordinate systems.
* libjpeg::                     Library for JPEG image manipulation.
* FFTW::                        Fast Fourier transform library.
* SAO ds9::                     SAO ds9 for viewing FITS images.
@end menu

@node GNU Scientific Library, CFITSIO, Requirements, Requirements
@subsection GNU Scientific library

The GNU Scientific library is probably already present in your
distribution's package management system. To install it from source,
you can run the following commands after you have
downloaded@footnote{@url{http://www.gnu.org/software/gsl/}}
@file{gsl-X.X.tar.gz}:

@example
$ tar -zxvf gsl-X.X.tar.gz
$ cd gsl-X.X
$ ./configure
$ make
$ make check
$ sudo make install
@end example

@node CFITSIO, WCSLIB, GNU Scientific Library, Requirements
@subsection CFITSIO

@cindex CFITSIO
CFITSIO is the closest you can get to the pixels in a FITS image while
remaining faithful to the FITS standard
@footnote{@url{http://fits.gsfc.nasa.gov/fits_standard.html}}. It is
written by William Pence, the author of the FITS
standard@footnote{Pence, W.D. et al. Definition of the Flexible Image
Transport System (FITS), version 3.0. (2010) Astronomy and
Astrophysics, Volume 524, id.A42, 40 pp.}, and is regularly
updated. Setting the definitions for all other software packages using
FITS images.

Some GNU/Linux distributions have CFITSIO in their package managers,
if it is available and updated, you can use it. One problem that might
occur is that CFITSIO might not be configured with the
@option{--enable-reentrant} option by the distribution. This option
allows CFITSIO to open a file in multiple threads. If so, upon
running, any program which needs this capability will warn you and
abort if you ask for multiple threads. In such cases you can take the
following step.

The best way is that you can install it from source. You can download
the latest version of the source code and manual from its
webpage@footnote{@url{http://heasarc.gsfc.nasa.gov/fitsio/fitsio.html}}.
We strongly recommend that you have a look through Chapter 2 (Creating
the CFITSIO library) of the the CFITSIO manual and understand the
options you can pass to @command{$ ./configure} (they aren't too
much). This is a very basic package for most astronomical software and
it is best that you configure it nicely with your system. Once you
download the source and unpack it, the following configure script
should be enough for most purposes. Don't forget to read chapter two
of the manual though, for example the second option is only for 64bit
systems. The manual also explains how to check if it has been
installed correctly.
@example
$ tar -vxzf cfitsio_latest.tar.gz
$ cd cfitsio
$ ./configure --prefix=/usr/local --enable-sse2 --enable-reentrant
$ make
$ sudo make install
@end example





@node WCSLIB, libjpeg, CFITSIO, Requirements
@subsection WCSLIB
WCSLIB is also written and maintained by one of the authors of the
World Coordiante System (WCS) definition in the FITS
standard@footnote{Greisen E.W., Calabretta M.R. (2002) Representation
of world coordinates in FITS. Astronomy and Astrophysics, 395,
1061-1075.}, Mark Calabretta. It might be already built and ready in
your distribution's package management system. Here we explain how to
install from source.

To install WCSLIB you will need to have the CFITSIO already
installed. WCSLIB also has plotting capabilities which use PGPLOT (a
plotting library for C). However, if you will not be using its
plotting functions, you can configure it such that pgplot is not
required.

If you do want to make plots with WCSLIB, there is an explanation on
the following, see @ref{PGPLOT}. To disable the dependency on PGPLOT,
you have to add the @option{--without-pgplot} option to the configure
script as you can see below. You can get the most recent source code
from its
webpage@footnote{@url{http://www.atnf.csiro.au/people/mcalabre/WCS/}}.
In the directory where you have downloaded the compressed file, you
can take the following steps (the @code{x.xx} represents the version
number):
@example
$ tar -jxvf wcslib.tar.bz2
$ cd wcslib-x.xx
$ ./configure --without-pgplot
$ make
$ make check
$ sudo make install
@end example





@menu
* PGPLOT::                      Installing PGPLOT (can be needed by WCSLIB).
@end menu

@node PGPLOT,  , WCSLIB, WCSLIB
@subsubsection PGPLOT
PGPLOT is a package for making plots in C. It is not directly needed
by gnuastro, but can be used by WCSLIB, see @ref{WCSLIB}. As
explained in @ref{WCSLIB}, you can install WCSLIB without it too. It
is very old (the most recent version was released early 2001!), but
remains one of the main packages for plotting directly in C. WCSLIB
uses this package to make plots if you want it to make plots. If you
are interested you can also use it for your own purposes.

If you want your plotting codes in between your C program, PGPLOT is
currently one of your best options. The recommended alternative to
this method is to get the raw data for the plots in text files and
input them into any of the various more modern and capable plotting
tools separtely, for example the matplotlib library in Python. Lets
get back to PGPLOT for the sake of WCSLIB. Installing it is a little
tricky (mainly because it is so old!).

You can download the most recent version from the FTP link in its
webpage@footnote{@url{http://www.astro.caltech.edu/~tjp/pgplot/}}. You
can unpack it with the @command{tar -vxzf} command. Lets assume the
directory you have unpacked it to is @file{PGPLOT}, most probably it
is: @file{/home/username/Downloads/pgplot/}.  open the
@file{drivers.list} file:
@example
$ gedit drivers.list
@end example
@noindent
Remove the @code{!} for the following lines and save the file in the
end:
@example
PSDRIV 1 /PS
PSDRIV 2 /VPS
PSDRIV 3 /CPS
PSDRIV 4 /VCPS
XWDRIV 1 /XWINDOW
XWDRIV 2 /XSERVE
@end example
@noindent
Don't choose GIF or VGIF, there is a problem in their codes.

Open the @file{PGPLOT/sys_linux/g77_gcc.conf} file:
@example
$ gedit PGPLOT/sys_linux/g77_gcc.conf
@end example
@noindent
change the line saying: @code{FCOMPL="g77"} to
@code{FCOMPL="gfortran"}, and save it. This is a very important step
during the compilation of the code if you are in GNU/Linux. You now
have to create a folder in @file{/usr/local}, don't forget to replace
@file{PGPLOT} with your unpacked address:
@example
$ su
# mkdir /usr/local/pgplot
# cd /usr/local/pgplot
# cp PGPLOT/drivers.list ./
@end example
To make the Makefile, type the following command:
@example
# PGPLOT/makemake PGPLOT linux g77_gcc
@end example
@noindent
It should finish by saying: @command{Determining object file
dependencies}. You have done the hard part! The rest is easy: run
these three commands in order:
@example
# make
# make clean
# make cpg
@end example

Finally you have to place the position of this directory you just made
into the @command{LD_LIBRARY_PATH} environment variable and define the
environment variable @command{PGPLOT_DIR}. To do that, you have to
edit your @file{.bashrc} file:
@example
$ cd ~
$ gedit .bashrc
@end example
@noindent
Copy these lines into the text editor and save it:
@example
PGPLOT_DIR="/usr/local/pgplot/"; export PGPLOT_DIR
LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/pgplot/
export LD_LIBRARY_PATH
@end example
@noindent
You need to log out and log back in again so these definitions take
effect. After you logged back in, you want to see the result of all
this labor, right? Tim Pearson has done that for you, create a
temporary folder in your home directory and copy all the demonstration
files in it:
@example
$ cd ~
$ mkdir temp
$ cd temp
$ cp /usr/local/pgplot/pgdemo* ./
$ ls
@end example
You will see a lot of pgdemoXX files, where XX is a number. In order
to execute them type the following command and drink your coffee while
looking at all the beautiful plots! You are now ready to create your
own.
@example
$ ./pgdemoXX
@end example





@node libjpeg, FFTW, WCSLIB, Requirements
@subsection libjpeg

As its name suggests, libjpeg is needed for reading and writing JPEG
images. @url{http://www.ijg.org/, libjpeg} is a very basic library
that provides tools to read and write JPEG images, most of the
GNU/Linux graphic programs and libraries use it. Therefore you most
probably already have it installed.
@url{http://libjpeg-turbo.virtualgl.org/, libjpeg-turbo} is an
alternative to libjpeg. It uses SIMD instructions for ARM based
systems that significantly decreases the processing time of JPEG
compression and decompression algorithms.

If @command{$ ./configure} fails to find libjpeg, then you have to
install one of the two libraries above. It should be available within
your distribution's package management tools as @command{libjpeg}..





@node FFTW, SAO ds9, libjpeg, Requirements
@subsection FFTW

The ``Fastest Fourier Transform in the West'' or
FFTW@footnote{@url{http://www.fftw.org/}}, is used for convoling the
actual profiles of the stars and galaxies with the PSF in the
production of mock galaxies in MakeProfiles. Like other packages above, it
is probably already available on your distribution's package
management system. But there are some configuration options which can
be helpful to gnuastro.

The options are to enable multi-threaded operation and also to enable
operation on @code{float} data (by default only the @code{double} type
is supported). Both of these can significantly reduce the running
time. You can download the source code from its webpage and run the
following commands in the directory you saved the compressed file
(@code{X.X.X} stands for the version number):
@example
$ tar -vxzf fftw-X.X.X.tar.gz
$ cd fftw.X.X.X
$ ./configure --enable-threads --enable-float
$ make
$ sudo make install
@end example





@node SAO ds9,  , FFTW, Requirements
@subsection SAO ds9

SAO ds9@footnote{@url{http://ds9.si.edu/}} is not a requirement of
gnuastro, it is a FITS image viewer. So to check your inputs and
outputs, it is one of the best options. Like the other packages, it
might already be available in your distribution's repositories. It is
already pre-compiled in the download section of its webpage. Once you
download it you can unpack and install (move it to a system recognized
directory) with the following commands (@code{x.x.x} is the version
number):

@example
$ tar -zxvf ds9.linux64.x.x.x.tar.gz
$ sudo mv ds9 /usr/local/bin
@end example

Once you run it, there might be a complaint about the Xss library,
which you can find in your distribution package management system. You
might also get an @command{XPA} related error. In this case, you have
to add the following line to your @file{~/.bashrc} and
@file{~/.profile} file (you will have to log out and back in again for
the latter):

@example
export XPA_METHOD=local
@end example


@menu
* Viewing multiextension FITS::  Configure SAO ds9 for multiextension images.
@end menu

@node Viewing multiextension FITS,  , SAO ds9, SAO ds9
@subsubsection Viewing multiextension FITS images

@cindex Multiextention FITS
@pindex ds9
@cindex Opening multiextention FITS
The FITS definition allows for multiple extensions inside a FITS file,
each extension can have a completely independent data set inside of
it. If you ordinarily open a multi-extension FITS file with SOA ds9,
for example by double clicking on the file or running @command{$ds9
foo.fits}, SAO ds9 will only show you the first extension. To be able
to switch between the extensions you have to follow these menus in the
SAO ds9 window: @clicksequence{File@click{}Open Other@click{}Open
Multi Ext Cube} and then choose the Multi extension FITS file in your
computer's file structure.

@findex ds9 -mecube
The method above is a little tedious to do every time you want view a
multi-extension FITS file. Fortunately SAO ds9 also provides options
that you can use to specify a particular behavior. One of those
options is @option{-mecube} which opens a FITS image as a
multi-extension data cube. So on the command line, if you run
@command{$ds9 -mecube foo.fits} a small window will also be opened,
which allows you to switch between the image extensions that
@file{foo.fits} might have. If @file{foo.fits} only consists of one
extension, then SAO ds9 will open as usual.

Just to avoid confusion, note that SAO ds9 does not follow the GNU
style of separating long and short options as explained in
@ref{Arguments and options}. In the GNU style, this ``long'' option
should have been called like @option{--mecube}, but SAO ds9 does
follow those conventions and has its own.

It is really convenient if you set ds9 to always run with the
@option{-mecube} option on your graphical display. On GNOME 3 (the
most popular graphic user interface for GNU/Linux systems) you can do
this by taking the following steps:

@itemize

@item
Open your favorite text editor and put the following text in a file
that ends with @file{.desktop}, for example @file{saods9.desktop}. The
file is very descriptive.
@example
[Desktop Entry]
Type=Application
Version=1.0
Name=SAO ds9
Comment=View FITS images
Exec=ds9 -mecube %f
Terminal=false
Categories=Graphic;FITS;
@end example

@item
Copy this file into your local (user) applications directory:
@example
$ cp saods9.desktop ~/.local/share/applications/
@end example
In case you don't have the directory, you can make it your self:

@example
$ mkdir -p ~/.local/share/applications/
@end example

@item
The steps above will add SAO ds9 as one of your applications. To make
it default for every time you click on a FITS file. Right click on a
FITS file and select ``Open With'', then go into ``Other
Application...'' and choose ``SAO ds9''.
@end itemize

In case you are using GNOME 2 you can take the following steps: right
click on a FITS file and choose @clicksequence{Properties@click{}Open
With@click{}Add} button. A list of applications will show up, ds9
might already be present in the list, but don't choose it because it
will run with no options. Below the list is an option ``Use a custom
command''. Click on it and write the following command: @command{ds9
-mecube} in the box and click ``Add''. Then finally choose the command
you just added as the default and click the ``Close'' button.





@node Installing gnuastro,  , Requirements, Installation
@section Installing GNU Astronomy Utilities

This section is basically a longer explanation to the sequence of
commands given in @ref{Quick start}. If you want to have all the
programs of gnuastro installed in your system, you don't want to
change the executable names during or after installation, you have
root access to install the programs in a system wide directory, the
Letter paper size of the print manual is fine for you or as a summary
you don't feel like going into the details when everything is working
seamlessly, you can safely skip this section. If you have any of the
above problems or you want to understand the the details for a better
control over your build and install, read along.

In the following we will assume that you have downloaded the
compressed source file, @file{gnuastro-@value{VERSION}.tar.gz}, to
the @file{DOWLD} (short for download) directory, replace this name
with the directory that you want to run the installation in. Note that
after installation, if you don't plan to re-install you no longer need
this file or the uncompressed directory, so you can safely delete
both. The first three steps in @ref{Quick start} need no extra
explanation so in the following we also assume they are done. Once you
uncompress the source file the directory
@file{DOWLD/gnuastro-@value{VERSION}} will be created.


@menu
* Configuring::                 Configure gnuastro
* Tests::                       Run tests to see if it is working.
* Print manual::                Customize the print manual.
@end menu





@node Configuring, Tests, Installing gnuastro, Installing gnuastro
@subsection Configuring

The @command{$ ./configure} step is the most important step in the
build process. All the required packages, libraries, headers and
environment variables are checked in this step. The behaviors of make
and make install can also be set through command line options to this
command.

The configure script accepts various arguments and options which
enable the final user to highly customize whatever she is
building. The options to configure are generally very similar to
normal program options explained in @ref{Arguments and
options}. Similar to all GNU programs, you can get a full list of the
options along with a short explantion by running

@example
$ ./configure --help
@end example

@noindent
A complete explanation is also included in the
@file{gnuastro-@value{VERSION}/INSTALL} file in plain text that comes
with the gnuastro source. Note that this file was written by the
authors of GNU Autoconf and is common for all programs which use the
@command{$ ./configure} script for building and installing. Here we
will try to review the most common general usages (not only
gnuastro): when you don't have super-user access to the system and
changing the executbale names. But before that we will first review
the options to contigure that are particular to gnuastro.

@menu
* gnuastro configure options::  Configure options particular to gnuastro.
* Installation directory::      Specify the directory to install.
* Executable names::            Changing executable names.
@end menu

@node gnuastro configure options, Installation directory, Configuring, Configuring
@subsubsection gnuastro configure options

Most of the options to configure (which are to do with building) are
similar for every program which uses this script. Here we will discuss
the options that are particular to gnuastro, the next topics explain
the usage of other configure options which can be applied to any
program using the GNU build system (through the configure script).

@vtable @option

@item --with-numthreads
(=@code{INT}) If this option is given an integer value, that value
will be used for the default number of threads to use. If it is not
given, then the total number of threads will be read from the system,
see @ref{Threads in gnuastro}. Specifying
@option{--with-numthreads=no} or @option{--without-numthreads} is
equivalent to not calling this option it at all.

@item --enable-progname
Only build and install @file{progname} along with any other program
that is enabled in this fashion. @file{progname} is the name of the
executable without the @file{ast}, for example @file{imgcrop} for
ImageCrop (with the executable name of @file{astimgcrop}). If this
option is called for any of the programs in gnuastro, any program
which is not explicitly enabled will not be built or installed.

@item --disable-progname
@itemx --enable-progname=no
Do not build or install the program named @file{progname}. This is
very similar to the @option{--enable-progname}, but will build and
install all the other programs except this one.

@end vtable

@cartouche
@noindent
@strong{Note:} If some programs are enabled and some are disabled, it
is equivalent to simply enabling those that were enabled. Listing the
disabled programs is redundant.
@end cartouche

Note that the tests of some programs might require other programs to
have been installed and tested. For example MakeProfiles is the first
program to be tested when you run @command{$ make check}, it provides
the inputs to all the other tests. So if you don't install
MakeProfiles, then the tests for all the other programs will be
skipped or fail. To avoid this, in one run, you can install all the
packages and run the tests but not install. If everything is working
correctly, you can run configure again with only the packages you want
but not run the tests and directly install after building.



@node Installation directory, Executable names, gnuastro configure options, Configuring
@subsubsection Installation directory
@cindex root, not possible
@cindex Superuser, not possible

One of the most commonly used options to configure is the directory
that will host all the files which require installing, for example the
actual executable files for the program, the documentation,
configuration files. This is done through the @option{--prefix}
option. Here we will use the scenrio where you don't have root access
to the computer you are using to demonstrate its applicability.

In case you do not have super user or root access to the system, you
can't take the installation steps of the command sequence in
@ref{Quick start}. To be able to access the gnuastro executable files
from anywhere, you have to specify a special directory in the
directories you have write access in. Note that this explanation can
apply to all the requirements in @ref{Requirements} in case the system
lacks them or the system wide install was not built with the proper
configuration options.

The standard directory where you can keep such files for your own user
is the @file{$HOME/.local/}. You can check the value of the
@command{HOME} environment variable by running

@example
$ echo $HOME
@end example

@noindent
You can use this directory for installing all the programs, libraries,
manuals and shared data that you need. Lets call the directory you
have chosen with @file{USRDIR} since the standard is just a
suggestion. Please replace it with any directory name you choose. To
install any program without root privileges, you can add the following
option to the configure script. You can then run @command{$ make
install} without any root access.

@cindex Install directory
@cindex Directory, install
@example
$ ./configure --prefix=USRDIR
@end example

Ofcourse, to be able to run the program executables in your chosen
directory from anywhere, you also need to include @file{USRDIR/bin}
(the subdirectory where the executables are installed) in your
@command{PATH} environment variable by placing the following command
in your @file{$HOME/.bashrc} file. The directories listed in
@command{$PATH} specifies the locations that the system will check to
find the executable name you have asked for.

@example
export PATH=$PATH:USRDIR/bin
@end example

In case you install libraries (like the requirements of gnuastro)
with this method locally, you also have to notify the system to search
for libraries in your installed directory. To do that add
@file{USRDIR/lib} to your @command{LDPATH} environment variable
similar to the example above for @command{PATH}. If you also want to
access the Info and man pages documentations add the
@file{USRDIR/share/info} and @file{USRDIR/share/man} to your
@command{INFODIR} and @command{MANPATH} environment variables.

A final note is that order matters in the directores that are
searched. In the example above, we added the new directory after the
system specified directories. So if the program, library or manuals
are found in the system wide directories, the user directory is no
longer searched. If you want to search your local installation first,
put the new directory before the already existing list like the
example below.

@example
export PATH=USRDIR/bin:$PATH
@end example

@noindent
This is good when a library for example CFITSIO is already present on
the system but wasn't installed with the correct configuration flags
discussed above. Since you can't re-install, with this order, the
system will first find the one you installed with the correct
configuration flags. However there are security problems, because all
system wide programs and libraries can be replaced by non-secure
versions if they also exist in @file{USRDIR}. So if you choose this
order, be sure to keep it clean from executables with the same names
as important system programs.





@node Executable names,  , Installation directory, Configuring
@subsubsection Executable names

At first sight, the names of the executables for each program might
seem to be uncommonly long, for example @command{astnoisechisel} or
@command{astimgcrop}. We could have chosen terse (and cryptic) names
like most programs do. We chose this complete naming convention
(something like the commands in @TeX{}) so you don't have to spend too
much time remembering what the name of a specific program was. Such
complete names also enable you to easily search for the programs.

To facilitate typing the names in, we suggest using the shell
autocomplete. With this facility you can find the executable you want
very easily. It is very similar to file name completion in the
shell. For example, simply by typing the letters bellow (where
@key{[TAB]} stands for the Tab key on your keyboard)

@example
$ ast[TAB][TAB]
@end example

@noindent
you will get the list of all the available executables that start with
@command{ast} in your @command{PATH} environment variable
directories. So, all the gnuastro executables installed on your system
will be listed. Typing the next letter for the specific program you
want along with a Tab, will limit this list until you get to your
desired program.

In case all of this does not convince you and you still want to type
short names, some suggestions are given below. You should have in mind
though, that if you are writing a shell script that you might want to
pass on to others, it is best to use the standard name because other
users might not have adopted the same customizations. The long names
also serve as a form of documentation in such scripts. A similar
reasoning can be given for option names in scripts: it is good
practice to always use the long formats of the options in shell
scripts, see @ref{Option basics}.

The simplest solution is making a symbolic link to the actual
executable. For example lets assume you want to type @file{ic} to run
ImageCrop instead of @file{astimgcrop}. Assuming you installed
gnuastro executables in @file{/usr/local/bin} (default) you can do
this simply by running the following command as root:

@example
# ln -s /usr/local/bin/astimgcrop /usr/local/bin/ic
@end example

@noindent
In case you update gnuastro and a new version of ImageCrop is
installed, the default executable name is the same, so your custom
symbolic link still works.

The installed executable names can also be set using options to
@command{$ ./configure}, see @ref{Configuring}. GNU Autoconf (which
configures gnuastro for your particular system), allows the builder
to change the name of programs with the three options
@option{--program-prefix}, @option{--program-suffix} and
@option{--program-transform-name}. The first two are for adding a
fixed prefix or suffix to all the programs that will be installed.
This will actually make all the names longer!  You can use it to add
versions of program names to the programs in order to simulataneously
have two executable versions of a program.

The third configure option allows you to set the executable name at
install time using the SED utility. SED is a very useful ``stream
editor''. There are various resources on the internet to use it
effectively. However, we should caution that using configure options
will change the actual executable name of the installed program and on
every re-install (an update for example), you have to also add this
option to keep the old executable name updated. Also note that the
documentation or configuration files do not change from their standard
names either.

For example, lets assume that typing @file{ast} on every invokation
of every program is really annoying you! You can remove this prefix
from all the executables at configure time by adding this option:

@example
$ configure --program-transform-name='s/astr/ /'
@end example



@node Tests, Print manual, Configuring, Installing gnuastro
@subsection Tests

@cindex @command{make check}
@cindex @file{mock.fits}
@cindex Tests, running
@cindex Checking tests
After successfully building (compiling) the programs with the
@command{$ make} command you can check the installation before
installing. To run the tests on your newly build utilities, run

@example
$ make check
@end example

For every program we have designed some tests to check nearly all the
possible operations. Running the command above will run those tests
and give you a final report. If everything is ok and you have built
all the programs, all the tests should pass. In case any of the tests
fail, please contact us because it is a bug. Note that the tests of
some programs depend on the outputs of other program's tests, so if
you have not installed them they might be skipped or fail. Prior to
releasing every distribution all these tests are checked. If you have
a reasonably modern terminal, the outputs of the successful tests will
be colored green and the failed ones will be colored red.

These scripts can also act as a good set of examples for you to see
how the programs are run. All the tests are in the
@file{gnuastro-@value{VERSION}/tests} directory. The tests for each
program are shell scripts (ending with @file{.sh}) in a subdirectory
of this directory with the same name as the program. See @ref{Test
scripts} for more detailed information about these scripts incase you
want to inspect them.






@node Print manual,  , Tests, Installing gnuastro
@subsection Print manual

@cindex Print manual
@cindex Modifying print manual
@cindex A4 paper size
@cindex US letter paper size
@cindex Paper size, A4
@cindex Paper size, US letter
The default print manual is provided in the letter paper size. If you
would like to have the print version of this manual on paper and you
are living in a country which uses A4, then you can rebuild the
manual. The great thing about the GNU build system is that the manual
source code which is in Texinfo is also distributed with the program
source code, enabling you to do such customizations (hacking).

In order to change the paper size, you will need to have @TeX{}
installed. For simplicity, lets assume @file{SRCdir} is equivalent to
@file{DOWLD/gnuastro-@value{VERSION}}. Open
@file{SRCdir/doc/gnuastro.texi} with any text editor. This is the
source file that created this manual. In the first few lines you will
see this line:

@example
@@c@@afourpaper
@end example

@noindent
In Texinfo, a line is commented with @code{@@c}. Therefore, uncomment
this line by deleting the first two characters such that it changes
to:

@example
@@afourpaper
@end example

@noindent
Save the file and close it. You can now run

@example
$ make pdf
@end example

@noindent
and the new PDF manual will be available in
@file{SRCdir/doc/gnuastro.pdf}. By changing the @command{pdf} in
@command{$ make pdf} to @command{ps} or @command{dvi} you can have the
manual in those formats. Note that you can do this for any manual that
is in Texinfo format, they might not have @code{@@afourpaper} line, so
you can add it close to the top of the Texinfo source file.




















@node Common behavior, Files, Installation, Top
@chapter Common behavior

There are some facts that are common to all the programs in gnuastro
which are mainly to do with user interaction. In this chapter we will
review all these aspects. The most basic are the command line options
which are common in all the programs for a unified user
experience. All gnuastro programs can use configuration files so you
don't have to specify all the parameters on the command line each time
you run a program. The manner of setting, checking and using the these
files at various levels are also explained. Finally we discuss how you
can get immediate and distraction-free (without taking your hands off
the keyboard!) help on the command line.

@menu
* Command line::                How to use the command line.
* Configuration files::         Values for unspecified variables.
* Threads in gnuastro::         How threads are managed in gnuastro.
* Final parameter values::      The final set of used parameters.
* Automatic output::            About automatic output names.
* Getting help::                Getting more information on the go.
* Output headers::              Common headers to all FITS outputs.
@end menu

@node Command line, Configuration files, Common behavior, Common behavior
@section Command line

All the programs in gnuastro are customized through the standard GNU
style command line options. In this section we first provide a general
outline of how to make best use of these options and finally we list
the options that are common to all the programs in gnuastro.

Your full command line text is passed onto the shell as a string of
characters. That string is then broken up into separate ``words'' by
any ``metacharacters'' (like space, tab, @command{|}, @command{>} or
@command{;}) that might exist in the text. @xref{Definitions,
``metacharacters'' and ``words'', Definitions, bash.info, the Bash
manual}, for the complete list of meta-characters and other Bash
definitions. @xref{Shell Operation, ,Shell Operation, bash.info, the
Bash manual}, for a short summary of the steps the shell takes before
passing the commands to the program you called.

@menu
* Arguments and options::       Basics of options and arguments.
* Arguments::                   Treatment of arguments.
* Option basics::               How to use GNU style options.
* Common options::              Common options to all gnuastro programs.
@end menu

@node Arguments and options, Arguments, Command line, Command line
@subsection Arguments and options
On the command line, the first thing you enter is the name of the
program you want to run. After that you can specify two types of
input: @emph{arguments} and @emph{options}.  Arguments are those
tokens that are not preceded by any hyphens (@command{-}), the program
is suppose to understand what they are without any help from the
user.

Arguments can be both mandatory and optional and since there is no
help from you, their order might also matter (for example in
@command{cp} which is used for copying). The outputs of
@option{--usage} and @option{--help} shows which arguments are
optional and which are mandatory, see @ref{--usage}. As their name
suggests, @emph{options} are only optional and most of the time you
don't have to worry about what order you specify them in.

In case your arguments or option values contain any of the shell's
meta-characters, you have to quote them. If there is only one such
character, you can use a backslash (@command{\}) before it. If there
are multiple, it might be easier to simply put your whole argument or
option value inside of double quotes (@command{"}). In such cases,
everything inside the double quotes will be seen as one ``word''.

For example lets say you want to specify the Header data unit (HDU) of
your FITS file using a complex expression like @command{3;
images(exposure > 100)}. If you simply add these after the
@option{--hdu} (@option{-h}) option, the programs in gnuastro will
read the value to the HDU option as @command{3} and run. Then, Bash
will attempt to run a separate command @command{images(exposure >
100)} and complain about a syntax error. This is because the semicolon
(@command{;}) is an ``end of command'' character in Bash. To solve
this problem you can simply put double quotes around the whole string
you want to pass as seen below:
@example
$ astimgcrop --hdu="3; images(exposure > 100)" FITSimage.fits
@end example
Alternatively you can put a @command{\} before every metacharacter in
this string, but probably you will agree with us that the double
quotes are much more easier, elegant and readable.




@node Arguments, Option basics, Arguments and options, Command line
@subsection Arguments
In GNU Astronomy Utilities, the names of the input data files and
ASCII tables are mostly specified as arguments, you can generally
specify them in any order unless otherwise stated for a particular
program. Everything particular about the how a program treats
arguments, is explained under the ``Invoking ProgramName'' section for
that program.

Generally, if there is a standard file name extension for a particular
format, that filename extension is used to separate the kinds of
arguments. The list below shows what astronomical data formats are
recognized based on their file name endings. If the program doesn't
accept any other data format, any other argument that doesn't end with
the specified extentions below is considered to be a text file
(usually catalogs). For example @ref{ConvertType} accepts other data
formats.

@itemize

@item
@file{.fits}: The standard file name ending of a FITS image.

@item
@file{.fits.Z}: A FITS image compressed with @command{compress}.

@item
@file{.fits.gz}: A FITS image compressed with GNU zip (gzip).

@item
@file{.imh}: IRAF format image file.

@end itemize

Through out this manual and in the command line outputs, whenever we
want to generalize all such astronomical data formats in a text place
holder, we will use @file{ASTRdata}, we will assume that the extension
is also part of this name. Any file ending with these names is
directly passed on to CFITSIO to read. Therefore you don't necessarily
have to have these files on your computer, they can also be located on
an FTP or HTTP server too, see the CFITSIO manual for more
information.

CFITSIO has its own error reporting techniques, if your input file(s)
cannot be opened, or read, those errors will be printed prior to the
final error by gnuastro.



@node Option basics, Common options, Arguments, Command line
@subsection Options

The following conventions are used to configure the behaviour of a
program in all GNU/Linux applications each time you run it. Each
option can be called in two ways: @emph{short} or @emph{long}. In the
list of options provided in @ref{Common options} or those for each
program, both formats are shown for those which support both. First
the short is shown then the long. Short options are only one character
and only have one hyphen (for example @option{-h}) while long options
have two hyphens an can have many characters (for example
@option{--hdu}).

Usually, the short options are for when you are writing on the command
line and want to save keystrokes and time. The long options are good
for shell scripts, where you don't usually have a rush and they
provide a level of documentation, since they are less cryptic. Usually
after a few months of not running a program, the short options will be
forgotten and reading your previously written script will not be easy.

Some options need to be given a value if they are called and some
don't. You can think of the latter type of options as an on/off
option. These two types of options can be distinguished using the
output of the @option{--help} and @option{--usage} options, which are
common to all GNU software, see @ref{Getting help}. In gnuastro, we
have the following convention for the formats of the values:

@vtable @option

@item INT
The value is read as an integer. If a float or a string is provided
the program will warn you and abort. In most cases, integers are used
for counting variables, so if they are negative the program will also
abort.

@item 4or8
Either the value 4 or 8, any other integer will give a
warning and abort.

@item FLT
The value is read as a float. There are generally two types, depending
on the context. If they are for fractions, they will have to be less
than or equal to unity.

@item STR
The value is read as a string of characters (for example a file name)
or other paritcular settings (for example color space in the JPEG
format).

@end vtable

@noindent
To specify a value in the short format, simply put the value after the
option. Note that since the short options are only one character long,
you don't have to type anything between the option and its value. For
the long option you either need white space or an @option{=} sign, for
example @option{-h2}, @option{-h 2}, @option{--hdu 2} or
@option{--hdu=2} are all equivalent.

Short options with no values can be concatenated for example these two
hypothetical sequences of options are equivalent: @option{-a -b -c4}
and @option{-abc4}. In the long format, you don't have to write the
full option name, only long enough for the option to be unambiguously
identified. If it is ambiguous, the program will warn you and provide
you with suggestions.  As an example, consider the following command
to run ImageCrop:
@example
$ astimgcrop -Dr3 --wwidth 3 catalog.txt --deccol=4 ASTRdata
@end example
@noindent
The @command{$} is the shell prompt, @command{astimgcrop} is the
program name. There are two arguments (@command{catalog.txt} and
@command{ASTRdata}) and four options, two of them given in short
format (@option{-D}, @option{-r}) and two in long format
(@option{--width} and @option{--deccol}). Three of them require a
value and one (@option{-D}) is an on/off option.

If an abbreviation is unique between all the options of a program, the
long option names can be abbreviated. For example, instead of typing
@option{--printparams}, typing @option{--print} or maybe even
@option{--pri} will be enough, if there are conflicts, the program
will warn you and show you the alternatives. Finally, if you want the
argument parser to stop parsing arguments beyond a certain point, you
can use two dashes: @option{--}. No text on the commandline beyond
these two dashes will be parsed.

When you don't call an option that requires a value, all the programs
in gnuastro will check configuration files to find a value for that
parameter. To learn more about how folder, user and system wide
configuration files can be set, please see @ref{Configuration
files}. Another factor that is particular to gnuastro is that it will
check the value you have given for each option to see if it is
reasonable. For example you might mistakenly give a negative, float or
string value for a FITS image extension or column number. As another
example, you might give a value larger than unity for an option that
only accepts fractions (which are always less than unity and
positive).

@cartouche
@noindent
@strong{CAUTION:} In specifying a file address, if you want to use the
shell's tilde expansion (@command{~}) to specify your home directory,
leave at least one space between the option name and your value. For
example use @command{-o ~/test}, @command{--output ~/test} or
@command{--output= ~/test}. Calling them with @command{-o~/test} or
@command{--output=~/test} will disable shell expansion.
@end cartouche
@cartouche
@noindent
@strong{CAUTION:} If you forget to specify a value for an option which
requires one, and that option is the last one, gnuastro will warn
you. But if it is in the middle of the command, it will take the text
of the next option or argument as the value which can cause undefined
behaviour.
@end cartouche
@cartouche
@noindent
@strong{NOTE:} All counting in gnuastro starts from 0 not 1. So for
example the first FITS image extension or column in a table are noted
by 0, not 1. This is the standard in C and all languages that are
based on it (for example C++, Java and Python).
@end cartouche

@node Common options,  , Option basics, Command line
@subsection Common options

To facilitate the job of the users and developers, all the programs in
gnuastro share some basic command line options for the same
operations where they are relevant. The list of options is provided
below. It is noteworthy that these similar options are hard-wired into
the programming of all of gnuastro programs using GNU C library's
argument parser merging ability.

For some programs, some of the options, might be irrelevant for
example MakeProfiles creates FITS images based on a given
catalog. Therefore no input images (and thus HDUs) are necessary for
it. In such cases, the option is still listed and if a value is given
for it, it is completely ignored.

@menu
* Input output::                Common input/output options.
* Operating modes::             Common operating mode options.
@end menu

@node Input output, Operating modes, Common options, Common options
@subsubsection Input/Output options

These options are to do with the input and outputs of the various
programs.

@vtable @option

@item -h
@itemx --hdu
(@option{=STR}) The number or name of the desired Header Data Unit or
HDU in the input FITS image or images. A FITS file can store multiple
HDUs or extensions, each with either an image or a table or nothing at
all (only a header). Note that counting of the extensions starts from
0(zero), not 1(one). When specifying the name, case is not important
so @command{IMAGE}, @command{image} or @command{ImAgE} are equivalent.

A @code{#} is appended to the string you specify for the
HDU@footnote{With the @code{#} character, CFITSIO will only read the
desired HDU into your memory, not all the existing HDUs in the fits
file.} and the result is put in square brackets and appended to the
FITS file name before calling CFITSIO to read the contents of the HDU
for all the programs in gnuastro. CFITSIO has many capabilities to
help you find the extension you want, far beyond the simple extension
number and name. See CFITSIO manual's ``HDU Location Specification''
section for a very complete explanation with several examples.

@item -o
@itemx --output
(@option{=STR}) The name of the output file or directory. With this
option the automatic output names explained in @ref{Automatic output}
are ignored.

@item -D
@itemx --dontdelete
By default, if the output file already exists, it will be silently
replaced with the output of this run of all gnuastro programs. By
calling this option, if the output file already exists, the programs
will warn you and abort.

@item -K
@itemx --keepinputdir
In automatic output names, don't remove the directory information of
the input file names. As explained in @ref{Automatic output}, if no
output name is specified, then the output name will be made in the
existing directory based on your input. If you call this option, the
directory information of the input will be kept and the output will be
in the same directory as the input. Note that his is only relevant if
you are running the program from another directory!

@end vtable

@node Operating modes,  , Input output, Common options
@subsubsection Operating modes

Another group of options that are common to all the programs in
gnuastro are those to do with the general operation of the
programs. The explanation for those that are not only limited to
gnuastro but can be called in all GNU programs start with (GNU
option).

@vtable @option

@item --
(GNU option) Stop parsing the command line. This option can be useful
in scripts or when using the shell history. Assume you have a long
list options, and want to see if removing some of them (and using the
default values) can give a better result. If the ones you want to
remove are the last ones on the command line, you don't have to delete
them, you can just add @option{--} before them and if you don't get
what you want, you can remove the @option{--} and get the same initial
result.

@item --usage
(GNU option) Only print the options and arguments. This is very useful
for when you know the what the options do, you have just forgot their
names. See @ref{--usage}.

@item -?
@itemx --help
(GNU option) Print all options and an explanation. Adding this option
will print all the options in their short and long formats, also
displaying which ones need a value if they are called (with an
@option{=} after the long format). A short explanation is also given
for what the option is for. The program will quit immediately after
the message is printed and will not do any form of processing. See
@ref{--help}.

@item -V
@itemx --version
(GNU option) Print a short message, showing the full name, version,
copyright information and program authors. On the first line it will
print the official name (not executable name) and version number of
the program. It will also print the version of the gnuastro that the
program was built with. Following this is a blank line and a copyright
information. The program will not run.

@item -q
@itemx --quiet
Don't report steps. All the programs in gnuastro that have multiple
major steps will report their steps for you to follow while they are
operating. If you do not want to see these reports, you can call this
option and only error messages will be printed if the program is
aborted. If the steps are done very fast (depending on the properties
of your input) disabling these reports will also decrease running
time.

@item --cite
Print the Bib@TeX{} entry for gnuastro and the particular program (if
that program comes with a separate paper) and abort. Citations are
vital for the continued work on gnuastro. gnuastro started and is
continued based on separate research projects. So if you find any of
the tools offered in gnuastro to be useful in your research, please
use the output of this command to cite the program and gnuastro in
your research paper. Thank you.

gnuastro is still new, there is no separate paper only devoted to
gnuastro yet. Therefore currently the paper to cite for gnuastro is
the paper for NoiseChisel which is the first published paper
introducing gnuastro to the astronomical community. Upon reaching a
certain point, we will publish a paper completely devoted to
gnuastro, see @ref{GNU Astronomy Utilities 1.0}.

@item -P
@itemx --printparams
Print the final values used for all the parameters and abort. See
@ref{Final parameter values} for more details.

@item -S
@itemx --setdirconf
Update the current directory configuration file from the given command
line options and quit, see @ref{Configuration files}. The values of
your options are added to the configuration file in the current
directory. If the configuration file or folder doesn't exist, it will
be created. If it exists but has different values for those options,
they will be given the new values. In any case, the program will not
run, but the contents of its updated configuration file are printed
for you to inspect.

This is the recommended method to fill the configuration file for all
future calls to one of the gnuastro programs in a folder. It will
internally check if your values are in the correct range and type and
save them according to the configuration file format, see
@ref{Configuration file format}.

When this option is called, the otherwise mandatory arguments, for
example input image or catalog file(s), are no longer mandatory (since
the program will not run).

@item -U
@itemx --setusrconf
Update the user configuration file from the command line options and
quit. See explanation under @option{--setdirconf} for more details.

@item -N
@itemx --numthreads
(@option{=INT}) Set the number of CPU threads to use. See @ref{Threads
in gnuastro}.

@end vtable






@node Configuration files, Threads in gnuastro, Command line, Common behavior
@section Configuration files

Each program needs a certain number of parameters to run. Supplying
all the necessary parameters each time you run the program is very
frustrating and prone to errors. Therefore all the programs read the
values for the necessary options you have not given in the command
line from one of several plain text files (which you can view and edit
with any text editor). These files are known as configuration files
and are usually kept in a directory named @file{etc/} according to the
filesystem hierarchy
standard@footnote{@url{http://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard}}.

The thing to have in mind is that none of the programs in gnuastro
keep any internal default value. All the values must either be stored
in one of the configuration files or explicitly called in the command
line. In case the necessary parameters are not given through any of
these methods, the program will list the missing necessay parameters
and abort. As explained in @ref{Operating modes}, the only exception
to this is @option{--numthreads}, whose default value is set at
@command{$ ./configure} time internally, see @ref{gnuastro configure
options}. Ofcourse, you can still provide a default value for the
number of threads at any of the levels below, but if you don't, the
program will not abort.



@menu
* Configuration file format::   ASCII format of configuration file.
* Configuration file precedence::  Precedence of configuration files.
* Current directory and User wide::  Local and user configuration files.
* System wide::                 System wide configuration files.
@end menu

@node Configuration file format, Configuration file precedence, Configuration files, Configuration files
@subsection Configuration file format

The configuration files for each program have the standard program
executable name with a @file{.conf} suffix. When you download the
source code, you can find them in the same directory as the source
code of each program, see @ref{Program source}.

Any line in the configuration file whose first non-white character is
a @key{#} is considered to be a comment and is ignored. The same goes
for an empty line. The name of the parameter is the same as the long
format of the command line option for that parameter. The parameter
name and parameter value have to be separated by any number of
``whitespace'' characters: space, tab or vertical tab. By default
several space characters are used. If the value of an option has space
characters (most commonly for the @option{hdu} option), then double
quotes can be used to specify the full value.

Any text after the first two words (separated by the above delimiters)
in a line is ignored. If it is an option without a value in the
@option{--help} output (on/off option), then the value should be
@option{1} if it is to be ``on'' and @option{0} otherwise. If an
option is not recognized in the configuration file, the name of the
file and unrecognized option will be reported and the program will
abort.  If a parameter is repeated more more than once in the
configuration files and it is not set on the command line, then only
the first value will be used, the rest will be ignored.

You can build any of the directories and the configuration files your
self using any text editor.  However, it is recommended to use the
@option{--setdirconf} and @option{--setusrconf} options to set default
values for the current directory or this user, see @ref{Operating
modes}. With these options, the values you give will be checked as
explained in @ref{Option basics} before writing in the current
directory's configuration file. They will also print a set of
commented lines guiding the reader and will also classify the options
based on their context and write them in their logical order to be
more understandable.


@node Configuration file precedence, Current directory and User wide, Configuration file format, Configuration files
@subsection Configuration file precedence
The parameter values in all the programs of gnuastro will be filled
in the following order. Such that if a parameter is assigned a value
in an earlier step, any value for that parameter in a later step will
be ignored.

@enumerate
@item
Command line options, for this paricular execution.

@item
Current directory, for all executions in this directory
(@file{./.gnuastro/}).

@item
The user's home directory, for all the executions of a particular
user:@*(@file{$HOME/.local/etc/}, see below).

@item
In a system wide directory for any user on that computer
(@file{prefix/etc/}, see @ref{Installation directory} for
the value of @file{prefix}).
@end enumerate
@noindent

The basic idea behind setting this progressive state of checking for
parameter values is that separate users of a computer or separate
folders in a user's file system might need different values for some
parameters and the same values for others. For example raw telescope
images usually have their main image extension in the second FITS
extension, while processed FITS images usually only have one
extension. If your system wide default input extension is 0 (the
first), then when you want to work with the former group of data you
have to explicitly mention it to the programs every time. With this
progressive state of default values to check, you can set different
default values for the different directories that you would like to
run gnuastro in for your different purposes, so you won't have to
worry about this issue any more.


@node Current directory and User wide, System wide, Configuration file precedence, Configuration files
@subsection Current directory and User wide

For these two directories, the configuration files are stored in a
hidden sub-directory named @file{./.gnuastro/} and
@file{$HOME/.local/etc/} respectively. Unless you have changed it, the
@file{HOME} environment variable should point to your home
directory. You can check it by running @command{$ echo $HOME}. Each
time you run any of the programs in gnuastro, this environment
variable is read and placed in the above address. So if you suddenly
see that your home configuration files are not being read, probably
you (or some other program) has changed the value of this environment
variable.

Although it might cause confusions like above, this dependence on the
@file{HOME} environment variable enables you to temporarily use a
different directory as your home directory. This can come in handy in
complicated situations. To set the user or current directory
configuration files based on your command line input, you can use the
@option{--setdirconf} or @option{--setusrconf}, see @ref{Operating
modes}



@node System wide,  , Current directory and User wide, Configuration files
@subsection System wide
When gnuastro is installed, the configuration files that are shipped
with the distribution are copied into the (possibly system wide)
@file{prefix/etc/} directory. See @ref{Configuring} for more details
on @file{prefix} (by default it is: @file{/usr/local}). This directory
is the final place (with the lowest priority) that the programs in
gnuastro will check to retrieve parameter values.

If you remove a parameter and its value from the files in this system
wide directory, you either have to specify it in more immediate
configuration files or set it each time in the command line. Recall
that none of the programs in gnuastro keep any internal default
values and will abort if they don't find a value for the necessary
parameters (except the number of threads). So even though you might
never use a parameter, it still has to be at least available in this
system-wide configuration file.

In case you install gnuastro from your destribution's repositories,
@file{prefix} will either be set to @file{/} (the root directory) or
@file{/usr}, so you can find the system wide configuration variables
in @file{/etc/} or @file{/usr/etc/}. The prefix of @file{/usr/local/}
is conventionally used for programs you install from source by your
self.





@node Threads in gnuastro, Final parameter values, Configuration files, Common behavior
@section Threads in gnuastro
Some of the programs benefit significantly when you use all the cores
your computer's CPU has to offer. In general, when you run an
application, the whole process is done only on one core. gnuastro
uses the POSIX threads library (pthreads) for spinning off threads
when the user asks for it.

You can find the number of cores available to your system with the
command @command{$ nproc}, which is part of GNU Coreutils and is most
probably already available on your system. If not specified as an
option at configure time, gnuastro finds the number of cores
available to your system (and reports it along with all those other
things it checks!). It is saved internally for all the programs to use
by default. To specify the number of threads at configure time, use
the @option{--with-numthreads} option, see @ref{gnuastro configure
options}.

The number of threads is the only parameter in gnuastro, which is
stored internally at configure time. The implication is that the only
option with a value that doesn't have to be in any of the
configuration files (see @ref{Configuration files}) is this. Note that
if you do specify it, the value you provided in the most immediate
configuration file will be used, not the internal value.

@menu
* A note on threads::           Caution and suggestion on using threads.
@end menu

@node A note on threads,  , Threads in gnuastro, Threads in gnuastro
@subsection A note on threads

Spinning off threads internally is not necessarily always the most
efficient way to run an application. It is most useful when the input
data are fixed and you want the same operation to be done on parts of
it. For example one input image to ImageCrop and multiple crops from
various parts of it. In this fashion, the image is loaded into memory
once, all the crops are divided between the number of threads
internally and each thread cuts out those parts which are assigned to
it from the same image. On the other hand, if you have multiple images
and you want to crop the same region out of all of them, it is much
more efficient to set @option{--numthreads=1} (so no threads will be
spinned off) and run ImageCrop multiple times simultaneously.

The best method to run multiple instances of a command on different
threads is to use GNU parallel. Supprizingly GNU Parallel is one of
the few GNU packages that has no Info documentation but only a Man
page, see @ref{Info}. So to see the documentation after installing it
please run

@example
$ man parallel
@end example

As an example, lets assume we want to crop a region fixed on the
pixels (500, 600) with the default width from all the FITS images in
the @file{./data} directory ending with @file{sci.fits} to the current
directory. To do this, you can run:

@example
$ parallel astimgcrop --numthreads=1 --xc=500 --yc=600 ::: \
  ./data/*sci.fits
@end example

@noindent
GNU Parallel can help in many more conditions, this is one of the
simplest, see the man page for lots of other examples. For absolute
beginners: the backslash (@command{\}) is only a line breaker to fit
nicely in the page. If you type the whole command in one line, you
should remove it.





@node Final parameter values, Automatic output, Threads in gnuastro, Common behavior
@section Final parameter values, reproduce previous results

The input parameters can be specified in many places, either on the
command line or in at least one of several configuration files, see
@ref{Configuration files}. Therefore, it often happens that before
running a program on a certain data set, you want to see the values
for the parameters that the program will use after it has read your
command line options and all the configuration files in their correct
order. You might also want to save the list with the output so you can
reproduce the same results at a later time, this is very important
when you want to use your results in a report or paper.

If you call the @option{--printparams} option, all gnuastro programs
will read your command line parameters and all the configuration
files. If there is no problem (like a missing parameter or a value in
the wrong format) and immediately before actually running, the
programs will print the full list of paramter names and values sorted
and grouped by context and quit. They will also report their version
number, the date they were configured on your system and the time they
were reported.

As an example, you can give your full command line options and even
the input and output file names and finally just add @option{-P} to
check if all the parameters are finely set. If everything is ok, you
can just run the same command (easily retrieved from the bash history,
with the top arrow key) and simply remove the last two characters that
showed this option.

Since no program will actually start its processing when this option
is called, the otherwise mandatory arguments for each program (for
example input image or catalog files) are no longer required when you
call this option.

In case you want to store the list of parameters for later
reproduction of the same results, you can do so with the GNU Bash
re-direction tool. For example after you have produced the results you
want to store, you can save all the parameters that were used in a
file named @file{parameters.txt} in the following manner. Using the
bash history you can retrieve the last command you entered and simply
add @command{-P > parameters.txt} to it, for example:

@example
$ astimgcrop --racol=2 --deccol=3 IN.fits cat.txt -P > parameters.txt
@end example

@noindent
All the parameters along with the extra data explained before will be
stored in the plain text @file{parameters.txt} file. The output of
@option{--printparams} conforms with the configuration file
formats@footnote{They are both written by the same function.}. By
taking the following steps, you can use this file as a configuration
file to reproduce your results at a later time.

@enumerate
@item
Set the file name based on the standard configuration file names, see
@ref{Configuration file format}.

@item
Later on (when ever you want to re-produce your results), copy the
file in the @file{./.gnuastro/} directory of your current
directory.
@end enumerate

@noindent
In this manner, this file will be read as a current directory
configuration file and since all the parameters are defined in it, no
other configuration file value will be used.






@node Automatic output, Getting help, Final parameter values, Common behavior
@section Automatic output

All the programs in gnuastro are designed such that specifying an
output file or directory (based on the program context) is optional.
The outputs of most programs are automatically found based on the
input and what the program does. For example when you are converting a
FITS image named @file{FITSimage.fits} to a JPEG image, the JPEG image
will be saved in @file{FITSimage.jpg}.

Another very important part of the automatic output generation is that
all the directory information of the input file name is stripped off
of it. This feature can be disabled with the @option{--keepinputdir}
option, see @ref{Common options}. It is the default because
astronomical data are usually very large and organized specially with
special file names. In some cases, the user might not have write
permissions in those directories. Infact, even if the data is stored
on your own computer, it is advised to only grant write permissions to
the super user or root. This way, you won't accidentally delete or
modify your valuable data!

Lets assume that we are working on a report and want to process the
FITS images from two projects (ABC and DEF), which are stored in the
sub-directories named @file{ABCproject/} and @file{DEFproject/} of our
top data directory (@file{/mnt/data}). The following shell commands
show how one image from the former is first converted to a JPEG image
through ConvertType and then the objects from an image in the latter
project are detected using NoiseChisel (which by default has two text
catalog files and one multi-extension FITS detection map file). The
text after the @command{#} sign are comments (not typed!).

@example
$ pwd                                               # Current location
/home/usrname/research/report
$ ls                                         # List directory contents
ABC01.jpg
$ ls /mnt/data/ABCproject                                  # Archive 1
ABC01.fits ABC02.fits ABC03.fits
$ ls /mnt/data/DEFproject                                  # Archive 2
DEF01.fits DEF02.fits DEF03.fits
$ astconvertt /mnt/data/ABCproject/ABC02.fits --output=jpg    # Prog 1
$ ls
ABC01.jpg ABC02.jpg
$ astnoisechisel /mnt/data/DEFproject/DEF01.fits              # Prog 2
$ ls
ABC01.jpg ABC02.jpg DEF01_c.txt DEF01_map.fits DEF01_o.txt
@end example




@node Getting help, Output headers, Automatic output, Common behavior
@section Getting help

Probably the first time you read this manual, it is either in the PDF
or HTML formats. These two formats are very convenient for when you
are not actually working, but when you are only reading. Later on,
when you start to use the programs and you are deep in the middle of
your work, some of the details will inevitably be forgotten. Going to
find the PDF file (printed or digital) or the HTML webpage is a major
distraction.

GNU software have a very unique set of tools for aiding your memory on
the command line, where you are working, depending how much of it you
need to remember. In the past, such command line help was known as
``online'' help, because they were literally provided to you ``on''
the command ``line''. However, nowadays the word ``online'' refers to
something on the internet, so we will not use that term. With this
type of help, you can resume your exciting research without taking
your hands off the keyboard.

Another major advantage of such command line based help routines is
that they are installed with the software in your computer, therefore
they are always in sync with the executable you are actually
running. Three of them are actually part of the executable. You don't
have to worry about the version of the manual or program. If you rely
on external help (a PDF in your personal print or digital archive or
HTML from the official webpage) you have to check to see if their
versions fit with your installed program.

If you only need to remember the short or long names of the options,
@option{--usage} is advised. If it is what the options do, then
@option{--help} is a great tool. Man pages are also provided for those
who are use to this older system of documentation. This full manual is
also available to you on the command line in Info format. In the
subsections below each of these methods are reviewed.


@menu
* --usage::                     Only view option names and value formats.
* --help::                      List all options with description.
* Man pages::                   Man pages generated from --help.
* Info::                        View complete manual in terminal.
@end menu

@node --usage, --help, Getting help, Getting help
@subsection @option{--usage}
If you give this option, the program will not run. It will only print
a very concize message showing the options and arguments. Everything
within square brackets (@option{[]}) is optional. For example here are
the first and last two lines when we run ImageCrop with
@option{--usage}:

@example
$ astimgcrop --usage
Usage: astimgcrop [-Do?IPqSVW] [-d INT] [-h INT] [-r INT] [-w INT]
            [-x INT] [-y INT] [-c INT] [-p STR] [-N INT] [--deccol=INT]
            ....
            [--setusrconf] [--usage] [--version] [--wcsmode]
            [ASCIIcatalog] FITSimage(s).fits
@end example

There are no explanations on the options, just their short and long
names shown separately. After the program name, the short format of
all the options that don't require a value (on/off options) is
displayed. Those that do require a value then follow in separate
brackets, each displaying the format of the input they want, see
@ref{Option basics}. Since all options are optional, they are shown in
square brackets, but arguments can also be optional. For example in
this example, a catalog name is optional and is only required in some
modes. This is a standard method of displaying optional arguements for
all GNU software.

@node --help, Man pages, --usage, Getting help
@subsection @option{--help}

If the command line includes this option, the program will not be
run. It will print a complete list of all available options along with
a short explanation. The options are also grouped by their
context. Within each context, the options are sorted
alphabetically. Since the options are shown in detail afterwards, the
first line of the @option{--help} output shows the arguments and if
they are optional or not, similar to @ref{--usage}.

In the @option{--help} output of all programs in gnuastro, the
options for each program are classified based on context. The first
two contexts are always options to do with the input and output
respectively. For example input image extensions or supplimentary
input files for the inputs. The last class of options is also fixed in
all of gnuastro, it shows operating mode options. Most of these
options are already explained in @ref{Operating modes}.

The help message will sometimes be longer than the vertical size of
your terminal. If you are using a graphical user interface terminal
emulator, you can scroll the terminal with your mouse, but we promised
no mice distractions! So here are our suggestions:

@itemize
@item
@key{Shift + PageUP} to scroll up and @key{Shift + PageDown} to scroll
down. For most help output this should be enough. The problem is that
it is limited by the number of lines that your terminal keeps in
memory and that you can't scroll by lines, only by whole screens.

@item
Pipe to @command{less}. The @command{less} tool in Unix-like systems
was made exactly for such outputs of any length. You can pipe
(@command{|}) the output of any program that is longer than the screen
to it and then you can scroll through (up and down) with its many
tools. For example:
@example
$ astnoisechisel --help | less
@end example
@noindent
Once you have gone through the text, you can quit @command{less} by
pressing the @key{q} key.


@item
Save to file. This is a less convenient way, because you will then
have to open the file in a text editor! You can do this with the shell
redirection tool (@command{>}):
@example
$ astnoisechisel --help > filename.txt
@end example
@end itemize

In case you have a special keyword you are looking for in the help,
you don't have to go through the full list. GNU Grep is made for this
job. For example if you only want the list of options whose
@option{--help} output contains the word ``axis'' in ImageCrop, you
can run the following command:

@example
$ astimgcrop --help | grep axis
@end example

If the output of this option does not fit nicely within the confines
of your terminal, GNU does enable you to customize its output through
the environment variable @code{ARGP_HELP_FMT}, you can set various
parameters which specify the formatting of the help messages. For
example if your terminals are wider than 70 spaces (say 100) and you
feel there is too much empty space between the long options and the
short explanation, you can change these formattings by giving values
to this environment variable before running the program with the
@option{--help} output. You can define this environment variable in
this manner:
@example
$ export ARGP_HELP_FMT=rmargin=100,opt-doc-col=20
@end example
This will affect all GNU programs using GNU C library's @file{argp.h}
facilities as long as the environment variable is in memory. You can
see the full list of these formatting parameters in the ``Argp User
Customization'' part of the GNU C library manual. If you are more
comfortable to read the @option{--help} outputs of all GNU software in
your customized format, you can add your customizations (similar to
the line above, without the @command{$} sign) to your
@file{/home/username/.bashrc} file. This is a standard option for all
GNU software.

@node Man pages, Info, --help, Getting help
@subsection Man pages
Man pages were the Unix method of providing command line documentation
to a program. With GNU Info, see @ref{Info} the usage of this method
of documentation is highly discouraged. This is because Info provides
a much more easier to navigate and read environment.

However, some operating systems require a man page for packages that
are installed and some people are still used to this method of command
line help. So the programs in gnuastro also have Man pages which are
automatically generated from the outputs of @option{--version} and
@option{--help} using the GNU help2man program. So if you run
@example
$ man programname
@end example
@noindent
You will be provided with a man page listing the options in the
standard manner.





@node Info,  , Man pages, Getting help
@subsection Info

Info is the standard documentation format for all GNU software. It is
a very useful command line document viewing format, fully equipted
with links between the various pages and menus and search
capabilities. As explained before, the best thing about it is that it
is available for you the moment you need to refresh your memory on any
command line tool in the middle of your work without having to take
your hands off the keyboard. This complete manual is available in Info
format and can be accessed from anywhere on the command line.

To open the Info format of any installed programs or library on your
system which has an Info format manual, you can simply run the command
below (change @command{executablename} to the executable name of the
program or library):

@example
$ info executablename
@end example

@noindent
In case you are not already familiar with it, go and fill your cup of
coffee or green tea and and run @command{$ info info}. It does a
fantastic job in explaining all its capabilities its self. It is very
short and you will become sufficiently fluent in about half an
hour. Since all GNU software documentation is also provided in Info,
your whole GNU/Linux life will significantly improve.

Once you've become an efficient navigator in Info, you can go to any
part of this manual or any other GNU software or library manual, no
matter how long it is, in a matter of seconds. It also blends nicely
with GNU Emacs (a text editor) and you can search manuals while you
are writing your document or programs without taking your hands off
the keyboard, this is most useful for libraries like the GNU C
library. To be able to access all the Info manuals installed in your
GNU/Linux within Emacs, type @key{Ctrl-H + i}.

To see this whole manual from the beginning in Info, you can run

@example
$ info gnuastro
@end example

@noindent
If you run Info with the particular program executable name, for
example @file{astimgcrop} or @file{astnoisechisel}:

@example
$ info astprogramname
@end example

@noindent
you will be taken to the section titled ``Invoking ProgramName'' which
explains the inputs and outputs along with the command line options
for that program. Finally, if you run Info with the official program
name, for exmaple ImageCrop or NoiseChisel:

@example
$ info ProgramName
@end example

@noindent
you will be taken to the top section which introduces the
program. Note that in all cases, Info is not case sensitive.

@node Output headers,  , Getting help, Common behavior
@section Output headers

The output FITS files created by gnuastro will have the following two
keywords: @command{DATE} and @command{CFITSIO}. The first specifies
the time in UT of the file being created and the second specifies the
version of CFITSIO that was used to make the file. Some basic
information about gnuastro is also printed. The example below shows
the last few keywords of one of the outputs of ImageCrop.

@example
        / ImageCrop (GNU Astronomy Utilities 0.1) 0.1:
DATE    = ' ... '       / file creation date (YYYY-MM-DDThh:mm:ss UT)
CFITSIO = '3.37    '    / Version of CFITSIO used.
COMMENT GNU Astronomy Utilities 0.1
COMMENT http://www.gnu.org/software/gnuastro/
COMMENT Copyright (C) 2013 - 2015, Free Software Foundation.
COMMENT License GPLv3+: GNU General public license version 3 or later.
END
@end example














@node Files, Header manipulation, Common behavior, Top
@chapter Files

This chapter documents the programs in gnuastro that are provided for
getting information on the contents of a data file or converting a
file format. Before working on a FITS file, it is commonly the case
that you are not sure how many extensions it has within it and also
what each extension is (image, table or blank). In other cases you
want to use the data in a FITS file in other programs (for example in
reports) that don't recognize the FITS format.

@menu
* FileInfo::                    List all the extensions in a file.
* ConvertType::                 Convert data to various formats.
@end menu

@node FileInfo, ConvertType, Files, Files
@section FileInfo

The FITS file format allows for multiple extensions and each can have
a completely indepent header that possibly contains data, which is
either in the form of a table or image. FileInfo will list all the
extensions in the given FITS file and also give some basic information
about the form of data that is in that extension, for example image
size and data type.





@node ConvertType,  , FileInfo, Files
@section ConvertType

The formats of astronomical data were defined mainly for archiving and
processing. In other situations, the data might be useful in other
formats. For example, when you are writing a paper or report or if you
are making slides for a talk, you can't use a FITS image. Other image
formats should be used. In other cases you might want your pixel
values in a table format as plain text for input to other programs
that don't recognize FITS, or to include as a table in your
report. ConvertType is created for such situations. The various types
will increase with future updates and based on need.

The conversion is not only one way (from FITS to other formats), but
two ways (except for EPS format). So you can convert a JPEG image or
text file into a FITS image. Basically, other than EPS, you can use
any of the recognized formats as different color channel inputs to get
any of the recognized outputs. So before explaining the options and
arguments, first a short description of the recognized files types
will be given followed a short introduction to digital color.

@menu
* Recognized file types::       Recognized file types
* Color::                       Some explanations on color.
* Invoking astconvertt::        Options and arguments to ConvertType.
* ConvertType future updates::  Plans for future updates.
@end menu

@node Recognized file types, Color, ConvertType, ConvertType
@subsection Recognized file types

The various standards and the file name extensions recognized by
ConvertType are listed below.

@table @asis
@item FITS or IMH
Astronomical data are commonly stored in the FITS format (and in older
data sets in IRAF @file{.imh} format), a list of file name suffixes
which indicate that the file is in this format is given in
@ref{Arguments}.

Each extension of a FITS image only has one value per pixel, so when
used as input, each input FITS image contributes as one color
channel. If you want multiple extensions in one FITS file for
different color channels, you have to repeat the file name multiple
times and use the @option{--hdu}, @option{--h2}, @option{--h3} or
@option{--h4} options to specify the different extensions.

@item JPEG
The JPEG standard was created by the ``joint photographic experts
group''. It is currently one of the most commonly used image
formats. Its major advantage is the compression algorithm that is
defined by the standard. Like the FITS standard, this is a raster
graphics format, which means that it is pixelated.

A JPEG file can have 1 (for grayscale), 3 (for RGB) and 4 (for CMYK)
color channels. If you only want to convert one JPEG image into other
formats, there is no problem, however, if you want to use it in
combination with other input files, make sure that the final number of
color channels does not exceed four. If it does, then ConvertType will
abort and notify you.

The file name endings that are recognized as a JPEG file for input
are: @file{.jpg}, @file{.JPG}, @file{.jpeg}, @file{.JPEG},
@file{.jpe}, @file{.jif}, @file{.jfif} and @file{.jfi}.

@item EPS
The Encapsulated PostScript (EPS) format is essentially a one page
PostScript file which has a specified size. PostScript also includes
non-image data, for example lines and texts. It is a fully functional
programming language to describe a document. Therefore in ConvertType,
EPS is only an output format and cannot be used as input. Contrary to
the FITS or JPEG formats, PostScript is not a raster format, but is
categorized as vector graphics.

The Portable Document Format (PDF) is currently the most common format
for documents. Some believe that PDF has replaced PostScript and that
PostScript is now obsolete. This view is wrong, a PostScript file is
an actual plain text file that can be edited like any program source
with any text editor. To be able to display its programmed content or
print, it needs to pass through a processor known as Raster image
processor. A PDF file can be thought of as the processed output of the
Raster image processor on an input PostScript file. PostScript, EPS
and PDF were created by Adobe Systems.

With these features in mind, you can see that when you are compiling a
document with @TeX{} or @LaTeX{}, using an EPS file is much more low
level than a JPEG and thus you have much greater control and thus
quality. Since it also includes vector graphic lines we also use such
lines to make a thin border around the image to make its appearence in
the document much better. No matter the resolution of the display or
printer, these lines will always be clear and not pixelated. In the
future we might include addition of text (for example labels or object
IDs) on the EPS output, although this can be done better with tools
within @TeX{} or @LaTeX{} such as
PGF/Tikz@footnote{@url{http://sourceforge.net/projects/pgf/}}.

The standard formats for an EPS file are @file{.eps}, @file{.EPS},
@file{.epsf} and @file{.epsi}. The EPS outputs of ConvertType have the
@file{.eps} suffix.

@item @option{blank}
This is not actually a file type! But can be used to fill one color
channel with a blank value. If this argument is given for any color
channel, that channel will not be used in the output.

@item Plain text
Plain text files have the advantage that they can be viewed with any
text editor or on the command line. Most programs also support input
as plain text files. In ConvertType, if the input arguments do not
have any of the extensions listed above for other formats, the input
is assumed to be a text file. Each plain text file is considered to
contain one color channel.

If converting an image to plain text, consider the fact that if the
image is large the number of columns in each line and the number of
lines will become very large making it very hard to open in a text
editor.

@end table

@node Color, Invoking astconvertt, Recognized file types, ConvertType
@subsection Color

@cindex RGB
@cindex CMYK
@cindex Image
@cindex Grayscale
@cindex Colorspace
@cindex Primary colors
@cindex Colorspace, grayscale
An image is a two dimensional array of 2 dimensional elements called
pixels. If each pixel only has one value, the image is known as a
grayscale image and no color is defined. The range of values in the
image can be interpreted as shades of any color, it is customary to
use shades of black or grayscale. However, to produce the color
spectrum in the digital world, we need to mix several primary
colors. Therefore in a color image, each pixel has several values
depending on how many primary colors we choose. For example on the
digital monitor or color digital cameras, all colors are built by
mixing the three colors of Red-Green-Blue (RGB) with various
proportions. However, for printing on paper, standard printers use the
Cyan-Magenta-Yellow-Key (CMYK, Key=black) color space. Therefore when
printing an RGB image, usually a transformation of color spaces will
be necessary.

In a colored digital camera, a color image is produced by dividing the
pixel's area between three colors (filters). However in astronomy due
to the intrinsic faintness of most of our targets, the collecting area
of the pixel is very important for us. Hence the full area of the
pixel is used and one value is stored for that pixel in the end. One
color filter is used for the whole image. Thus a FITS image is
inherently a grayscale image and no color can be defined for it.

@cindex Colorspace, transformation
One way to represent a grayscale image in different color spaces is to
use the same proportions of the primary colors in each pixel. This is
the common way most FITS image converters work: they fill all the
channels with the same values. The downside is two fold:

@itemize

@item
Three (for RGB) or four (for CMYK) values have to be stored for every
pixel, this makes the output file very heavy (in terms of bytes).

@item
If printing, the printing errors of each color channel can make the
printed image slightly more blurred than it actually is.

@end itemize

@cindex Single channel CMYK
To solve both these problems, the best way is to save the FITS image
into the black channel of the CMYK color space. In the RGB color space
all three channels have to be used. The JPEG standard is the only
common standard that accepts CMYK color space, that is why currently
only the JPEG standard is included and not the PNG standard for
example.

@cindex 8-bit
@cindex 12-bit
The JPEG and EPS standards set two sizes for the number of bits in
each channel: 8-bit and 12-bit. The former is by far the most common
and is what we use in ConvertType. Therefore, each channel should have
values between 0 to @math{2^8-1=255}. From this we see how each pixel
in a grayscale image is one byte (8 bits) long, in an RGB image, it is
3bytes long and in CMYK it is 4bytes long. But thanks to the JPEG
compression algorithms, when all the pixels of one channel have the
same value, that channel is compressed to one pixel. Therefore a
Grayscale image and a CMYK image that has only the K-channel filled
are approximately the same file size.


@node Invoking astconvertt, ConvertType future updates, Color, ConvertType
@subsection Invoking ConvertType

CovertType can be used with the following general template:

@example
astconvertt [OPTION...] InputFile [InputFile2] ... [InputFile4]
@end example

@noindent
The file type of the output will be specified with the (possibly
complete) file name given to the @option{--output} option, which can
either be given on the command line or in any of the configuration
files (see @ref{Configuration files}). Note that if the output suffix
is not recognized, it will default to plain text format, see
@ref{Recognized file types}.

The order of multiple input files is important. After reading the
input file(s) the number of color channels will be used to define
which color space is being used and how each color channel is
interpretted. Note that one file might have more than one color
channel (for example in the JPEG format). If there are three input
color channels they are respectively considered to be the red, green
and blue color channels and if there are four color channels they are
respectively considered to be cyan, magenta, yellow and black.

The value to @option{--output} can be either a full file name or just
the suffix of the desired output format. In the former case, that same
name will be used for the output. In the latter case, the name of the
output file will be set based on the automatic output guidelines, see
@ref{Automatic output}. Note that the suffix name can optionally start
a @file{.} (dot), so for example @option{--output=.jpg} and
@option{--output=jpg} are equivalent. Be careful that if you want your
output in plain text, you have to give the full file name. So if
@option{-otxt} or @option{--output=.txt} are given, the output file
will be named @file{txt} or @file{.txt} (the latter will be a hidden
file!).

Besides the common set of options explained in @ref{Common options},
the options to ConvertType can be classified into input, output and
flux related options. The majority of the options are to do with the
flux range. Astronomical data usually have a very large dynamic range
(difference between maximum and minimum value) and different subjects
might be better demonstrated with a limited flux range.

@noindent
Input and output:
@table @option
@item --hdu2
If the second input file is a FITS file, the value to this option will
be used to specify which HDU will be used. Note that for the first
file, the (@option{--hdu} or @option{-h} in the common options is
used)

@item --hdu3
The HDU of the third input FITS file.

@item --hdu4
The HDU of the fourth input FITS file.

@item -u
@itemx --quality
(@option{=INT}) The quality (compression) of the output JPEG file with
values from 0 to 100 (inclusive). For other formats the value to this
option is ignored. Note that only in grayscale (when one input color
channel is given) will this actually be the exact quality (each pixel
will correspond to one input value). If it is in color mode, some
degradation will occur. While the JPEG standard does support lossless
graphics, it is not commonly supported.

@end table

@noindent
Flux range:

@table @option

@item -c
@itemx --change
(@option{=STR}) Change pixel values with the following format
@option{"from1:to1, from2:to2,..."}. This option is very useful in
displaing labeled pixels (not actual data images which have noise)
like segmentation maps. In labeled images, usually a group of pixels
have a fixed integer value. With this option, you can manipulate the
labels before the image is displayed to get a better output for print
or to emphasize on a particular set of labels and ignore the rest. The
labels in the images will be changed in the same order given. By
default first the pixel values will be converted then the pixel values
will be truncated (see @option{--fluxlow} and @option{--fluxhigh}).

You can use any number for the values irrespective of your final
output, your given values are stored and used in the double precision
floating point format. So for example if your input image has labels
from 1 to 20000 and you only want to display those with labels 957 and
11342 then you can run ConvertType with these options:

@example
$ astconvertt --change=957:50000,11342:50001 \\
  --fluxlow=50000 segmentationmap.fits --output=jpg
@end example

@noindent
While the output JPEG format is only 8 bit, this operation is done in
an intermediate step which is stored in double precision floating
point. The pixel values are converted to 8-bit after all operations on
the input fluxs have been complete. By placing the value in double
quotes you can use as many spaces as you like for better readability.

@item -C
@itemx --convaftertrunc
Change pixel values (with @option{--change}) after truncation of the
flux values, by default it is the opposite.

@item -L
@itemx --fluxlow
(@option{=FLT}) The minimum flux (pixel value) to display in the
output image, any pixel value below this value will be set to this
value in the output. If the value to this option is the same as
@option{--fluxmax}, then no flux truncation will be applied. Note that
when multiple channels are given, this value is used for all the color
channels.

@item -H
@itemx --fluxhigh
(@option{=FLT}) The maximum flux (pixel value) to display in the
output image, see @option{--fluxlow}.

@item -m
@itemx --maxbyte
(@option{=INT}) This is only used for the JPEG and EPS output formats
which have an 8-bit space for each channel of each pixel. The maximum
value in each pixel can therefore be @mymath{2^8-1=255}. With this
option you can change (decrease) the maximum value. By doing so you
will decrease the dynamic range. It can be useful if you plan to use
those values for other purposes.

@item -i
@itemx --flminbyte
(@option{=INT}) If the lowest pixel value in the input channels is
larger than the value to @option{--fluxlow}, then that input value
will be redundant. In some situations it might be necessary to set the
minimum byte value (0) to correspond to that flux even if the data do
not reach that value. With this option you can do this. Note that if
the minimum pixel value is smaller than @option{--fluxlow}, then this
option is redundant.

@item -a
@itemx --fhmaxbyte
(@option{=INT}) See @option{--flminbyte}.

@item -l
@itemx --log
Display the logarithm of the input data. This is done after the
conversion and flux truncation steps, see above.

@item -n
@itemx --noinvert
For 8-bit output types (JPEG and EPS for example) the final value that
is stored is inverted so white becomes black and vice versa. The
reason for this is that astronomical images usually have a very large
area of blank sky in them. The result will be that a large are of the
image will be black. Therefore, by default the 8-bit values are
inverted so the images blend in better with the text in a document.

Note that this behaviour is ideal for grayscale images, if you want a
color image, the colors are going to be mixed up. For color images it
is best to call this option so the image is not inverted.

@end table



@node ConvertType future updates,  , Invoking astconvertt, ConvertType
@subsection ConvertType future updates

@itemize

@item
Currently ConvertType only operates on a FITS image, not table. Add
functionality for tables too.

@item
Use image statistics for flux threshold instead of absolute values,
for example quantiles or a multiple of the average and standard
deviation.

@item
Invert color images with meaningful colors.

@end itemize

















@node Header manipulation, Image manipulation, Files, Top
@chapter Header manipulation

The FITS standard requires each extension of a FITS file to have a
header, giving basic information about what is in that extension. Each
line in the header is for one keyword, specifying its name, value and
a short comment string. Besides the basic information, the headers
also contain vital information about the data, how they were
processed, the instrument specifications that took the image and also
the World Coordinate System that is used to translate pixel
coordinates to sky or spectrum coordinates on the image or table.

With the set of tools in this section you can view the contents of any
extension in a FITS file. You can also add keywords and values and
comments to a FITS header or remove them if you like.

Programs for this section will soon be added....




















@node Image manipulation, Image analysis, Header manipulation, Top
@chapter Image manipulation

One of the data formats that can be contained in a FITS file extension
is an image with one value per pixel (or grey scale). The programs
specified in this chapter provide the tools to manipulate those
images, for example to crop a small region of them or to convert them
to other formats.

@menu
* ImageCrop::                   Crop region(s) from FITS image(s).
* ImageTransform::              Transform (flip, rotate) an image.
* ImageArith::                  Apply arithmetics on image(s).
* EllipMask::                   Place elliptical masks on an image.
@end menu

@node ImageCrop, ImageTransform, Image manipulation, Image manipulation
@section ImageCrop

Astronomical images are often very large, filled with thousands of
galaxies. It often happens that you only want a section of the image,
or you have a catalog of sources and you want to visualy analyze them
in small postage stamps. ImageCrop is made to do all these
things. When more than one crop is required, ImageCrop will divide the
crops between multiple threads to significantly reduce the run time.

One of the main problems in achieving this goal is that astronomical
surveys are usually extermely large. So large infact, that the whole
survey will not fit into a reasonably sized file. Because of this
surveys usually cut the final image into separate tiles and store each
tile in a file. For example the COSMOS survey's Hubble space
telescope, ACS F814W image consists of 81 separate FITS images, with
each one having a volume of 1.7 Giga bytes.

Even though the tile sizes are chosen to be large enough that too many
galaxies don't fall on the edges of the tiles, inevitably some do and
if you simply crop the image of the galaxy from that one tile, you
will miss a large area of the surrouding sky (which is essential in
estimating the noise). Therefore in its WCS mode, ImageCrop will
stitch parts of the tiles that are relevant for a target (with the
given width) from all the input images that cover that region into the
output. Ofcourse, the tiles have to be present in the list of input
files.

@menu
* ImageCrop modes::             Basic ImageCrop modes.
* Crop section syntax::         How to define a section to crop.
* Blank pixels::                Pixels with no value.
* Invoking astimgcrop::         Calling ImageCrop on the command line
* ImageCrop future::            Future updates to ImageCrop.
@end menu

@node ImageCrop modes, Crop section syntax, ImageCrop, ImageCrop
@subsection ImageCrop modes
In order to be as comprehensive as possible, ImageCrop has two major
modes of operation listed below.

@table @asis
@item Image
The image mode uses the pixel coordinates. Depending on your command
line options, this mode consists of three sub-modes. In image mode,
only one image may be input.
@itemize

@item
Catalog (multiple crops). Coordinates are read from a text file. The
@option{--xcol} and @option{--ycol} columns in the catalog are
interpretted as the center of a square crop box whose width is
specified with the @option{--iwidth} option in pixels. Since the given
pixel has to be on the center, the width has to be an odd number, so
if you give an even number for the width, it will be added by one. If
a catalog file name is provided (with @option{--imagemode} activated
ofcourse) this mode will be used.

@item
Center (one crop). The box center is given on the command line with
the @option{--xc} and @option{--yc} parameters. The image width is
similar to above.

@item
Section (one crop). You can specify the section of pixels along each
axis in the image which you want to be cropped with the
@option{--section} option. See @ref{Crop section syntax} for a full
explanation on the syntax of specifying the desired region.
@end itemize

The latter two cases will only have one crop box. In both cases,
ImageCrop will go into the image mode, irrespective of calling
@option{--wcsmode} or the default mode. In the first two cases, since
you specify a central pixel, the crop box will be a square with an odd
number of pixels on the side, so your desired pixel sits right in the
center, see @ref{Blank pixels} on how to disable this for cases when
the box exceeds the image size.

@item WCS
The Right ascension (RA) and Declination (Dec) of the objects in a
catalog is used to define the central position of each postage
stamp. In this mode, the width (@option{--wwidth}) is read in units of
arc seconds and multiple images (tiles in a survey) can be input. If
the objects are closer to the edge of the image than half the required
width, other tiles (if they are present in the input files) are used
to fill the empty space. The square output cropped box will have an
odd number of pixels on the side.

In this mode, the input images do not necessarily have to be the same
size, each individual tile can even be smaller than the final crop. In
any case, any part of any of the input images which overlaps with the
desired region will be used in the crop. Note that if there is an over
lap, the pixels from the last input image read are going to be
used. The input images all just have to be aligned with the celestial
coordinates, see the caution note below.

Similar to the image mode, there are two sub-modes:

@itemize

@item
Catalog (multiple crops). Similar to catalog mode in image mode. The
RA and Dec column should be specified in the catalog (@option{--racol}
and @option{--deccol}).

@item
Center (one crop). You can specify the center of only one crop box (no
matter how many input images there are) with the options @option{--ra}
and @option{--dec}. If it exists in the input images, it will be
cropped similar to the catalog mode. If automatic output is triggered
(you don't specify a file name for @option{--output}) and several of
the input images are used to stitch and crop the region around the
central point, the name of the first input will be used in automatic
output, see @ref{Automatic output}.

@end itemize

@cartouche
@noindent
@strong{CAUTION:} In WCS mode, the image has to be aligned with the
celestial coordinates, such that the first FITS axis is parallel
(opposite direction) to the Right Ascension (RA) while the second FITS
axis is parallel to the declination. If these conditions aren't met
for an image, ImageCrop will warn you and abort. You have to use other
tools to transform the image to the correct directions.
@end cartouche

@end table

In short, if you don't specify a catalog, you have to specify box
coordinates manually on the command line. When you do specify a
catalog, ImageCrop has to be in one of the two major modes
(@option{--imgmode} or @option{--wcsmode}). Note that the single crop
box parameters specified in the sub-modes will not be written to or
read from the configuration file, they have to be specified on each
execution.


@node Crop section syntax, Blank pixels, ImageCrop modes, ImageCrop
@subsection Crop section sytax
When in image mode, one of the methods to crop only one box from the
input image is to define a section. Instead of defining four
parameters for you to specify the corners of your section, ImageCrop
has a powerful syntax to read the box parameters from a string of
characters. If you leave certain parts of the string to be empty,
ImageCrop can fill them for you based on the input image sizes.

To define a box, you need the coordinates of two points: the first
pixel in the box at (@code{X1}, @code{Y1}) and the pixel which is
immediately outside of the box (@code{X2, @code{Y2}}), for coordiantes
in total. The four coordinates can be specified with one string:
@command{X1:X2,Y1:Y2} which is given to the @option{--section}
option. Therefore, the pixels along the first axis that are
@math{\geq}@command{X1} and <@command{X2} will be included in the
cropped image. The same goes for the second axis. Note that each
different term will be read as an integer, not a float (we don't have
sub-pixels). Also, following the FITS standard, pixel indexs along
each axis starts from unity(1) not zero(0).

You can omit any of the values and they will be filled automatically.
The left hand side of the colon (@command{:}) will be filled with
@command{1}, and the right side with the image size. So, @command{2:,:}
will include the full range of pixels along the second axis and only
those with a first axis index larger than @command{2} in the first
axis. If the colon is ommited for a dimension, then the full range is
automatically used. So the same string is also equal to @command{2:,}
or @command{2:} or even @command{2}. If you want such a case for the
second axis, you should set it to: @command{,2}.

If you specify a negative value, it will be seen as before the indexes
of the image which are outside the image along the bottom or left
sides when viewed in SAO ds9. In case you want to count from the top
or right sides of the image, you can use a star (@option{*}). When
confronted with a @option{*}, ImageCrop will replace it with the
maximum length of the image in that dimention. So
@command{*-10:*+10,*-20:*+20} will mean that the crop box will be
@math{20\times40} pixels in size and only include the top corner of
the input image with 3/4 of the image being covered by blank pixels,
see @ref{Blank pixels}.

If you feel more comfortable with space characters between the values,
you can use as many space characters as you wish, just be careful to
put your value in double quotes, for example @command{-s"5:200,
123:854"}. If you forget, anything after the first space will not be
seen by @option{--section}, because the unquoted space character is
one of the characters that separates options on the command line.



@node Blank pixels, Invoking astimgcrop, Crop section syntax, ImageCrop
@subsection Blank pixels
The cropped box can potentially include pixels that are beyond the
image range. For example when a target in the input catalog was very
near the edge of the input image. The parts of the cropped image that
were not in the input image will be filled with the following two
values depending on the data type of the image. In both cases, SAO ds9
will not color code those pixels.
@itemize
@item
If the data type of the image is a floating point type (float or
double), IEEE NaN (Not a number) will be used.
@item
For integer types, pixels out of the image will be filled with the
value of the @command{BLANK} keyword in the cropped image header. The
value assigned to it is the lowest value possible for that type, so
you will probably never need it any way. Only for the unsigned
character type (@command{BITPIX=8} in the FITS header), the maximum
value is used because it is unsigned, the smallest value is zero which
is often meaningful.
@end itemize
You can ask for such blank regions to not be included in the output
crop image using the @option{--noblank} option. In such cases, there
is no guarantee that the image size of your outputs are what you asked
for.

In some survey images, unfortunately they do not use the
@command{BLANK} FITS keyword. Instead they just give all pixels
outside of the survey area a value of zero. So by default, when
dealing with float or double image types, any values that are 0.0 are
also regarded as blank regions. This can be turned off with the
@option{--zeroisnotblank} option.


@node Invoking astimgcrop, ImageCrop future, Blank pixels, ImageCrop
@subsection Invoking ImageCrop

ImageCrop is run with the following general template:

@example
astimgcrop [OPTION...] [ASCIIcatalog] ASTRdata ...
@end example

@noindent
ImageCrop has one mandatory argument which is the input image name(s),
shown above with @file{ASTRdata ...}. You can use shell expansions,
for example @command{*} for this if you have lots of images in WCS
mode. If the crop box centers are in a catalog, you also have to
provide the catalog name as an argument. Alternatively, you have to
provide the crop box parameters with command line options.

When in catalog mode, ImageCrop will run using any number of threads
that you have specified with the @option{--numthreads} option, see
@ref{Common options}. Note that when multiple threads are being used,
in verbose mode, the outputs will not be in order. This is because the
threads asynchronous and are not started in order. When the box
coordinates are given on the command line, no threads will be created.

@menu
* astimgcrop options::          A list of all the options with explanation.
* astimgcrop output::           The outputs of ImageCrop.
@end menu

@node astimgcrop options, astimgcrop output, Invoking astimgcrop, Invoking astimgcrop
@subsubsection ImageCrop options

The options can be classified into the following contexts: Input,
Output and operating mode options. Options that are common to all
gnuastro program are listed in @ref{Common options} and will not be
repeated here.

@cartouche
@noindent
@strong{NOTE:} The coordinates are in the FITS format. So the first
axis is the horizontal axis when viewed in SAO ds9 and the second axis
is the vertical. Also in the FITS standard, counting begins from 1
(one) not 0 (zero).
@end cartouche

@noindent
Crop box parameters:
@table @option

@item -x
@itemx --xc
(@option{=FLT}) The first FITS axis value of central position of the
crop box in single image mode.

@item -y
@itemx --yc
(@option{=FLT}) The second FITS axis value of the central position of
the crop box in single image mode.

@item -s
@itemx --section
(@option{=STR}) Section of the input image which you want to be
cropped. See @ref{Crop section syntax} for a complete explanation on
the syntax required for this input.

@item -r
@itemx --ra
(@option{=FLT}) The first FITS axis value of central position of the
crop box in single image mode.

@item -d
@itemx --dec
(@option{=FLT}) The second FITS axis value of the central position of
the crop box in single image mode.

@item -i
@itemx --xcol
(@option{=INT}) Column number of the first FITS axis position of the
box center, starting from zero. In SAO ds9, the first FITS axis is the
horizontal axis.

@item -j
@itemx --ycol
(@option{=INT}) Column number of the second FITS axis position of the
box center, starting from zero. In SAO ds9, the second FITS axis is
the vertical axis.

@item -a
@itemx --iwidth
(@option{=INT}) Width the square box to crop in image mode in units of
pixels. In order for the chosen central pixel to be in the center of
the cropped image, the final width has to be an odd number, therefore
if the width

@item -f
@itemx --racol
(@option{=INT}) Column number of Right Ascension (RA) in the input
catalog, starting from zero.

@item -g
@itemx --deccol
(@option{=INT}) Column number of declination in the input catalog,
starting from zero.

@item -w
@itemx --wwidth
(@option{=FLT}) The width of the crop box in WCS mode in units of
arc-seconds.

@end table

@noindent
Output options:
@table @option

@item -c
@itemx --checkcenter
(@option{=INT}) Box size of region in the center of the image to check
in units of pixels. This is only used in WCS mode. Because surveys
don't often have a clean square or rectangle shape, some of the pixles
on the sides of the surveys don't have any data and are commonly
filled with zero valued pixels.

If the RA and Dec of any of the targets specified in the catalog fall
in such regions, that cropped image will be useless! Therefore with
this option, you can specify a width of a small box (3 pixels is often
good enough) around the central pixel of the cropped image. If all the
pixels in this small box have the value of zero, no cropped image will
be created and this object will be flagged in the final log file.

@item -p
@itemx --suffix
(@option{=STR}) The suffix (or postfix) of the output files for when
you want all the cropped images to have a special ending. One case
where this might be helpful is when besides the science images, you
want the weight images (or exposure maps, which are also distributed
with survey images) of the cropped regions too. So in one run, you can
set the input images to the science images and
@option{--suffix=_s.fits}. In the next run you can set the weight
images as input and @option{--suffix=_w.fits}.

@item -b
@itemx --noblank
Pixels outside of the input image that are in the crop box will not be
used. By default they are filled with blank values (depending on
type), see @ref{Blank pixels}.

@item -z
@itemx --zeroisnotblank
In float or double images, it is common to give the value of zero to
blank pixels. If the input image type is one of these two types, such
pixels will also be considered as blank. You can disable this behavior
with this option, see @ref{Blank pixels}.

@end table

@noindent
Operating mode options:
@table @option

@item -I
@itemx --imgmode
Operate in Image mode as described above. This option is only useful
when catalog is being provided. If coordinates are given on the
command line, the mode is automatically set based on them.

@item -W
@itemx --wcsmode
Operate in WCS mode. See explanations for @option{--imgmode}.

@end table





@node astimgcrop output,  , astimgcrop options, Invoking astimgcrop
@subsubsection ImageCrop output
When a catalog is given, the value of @option{--output} (see
@ref{Common options}) will be seen as the directory to store the
output cropped images. In such cases, the outputs will consist of two
parts: a variable part (the row number of each target starting from 1)
along with a fixed string which you can set with the @option{--suffix}
option. Note that in catalog mode, only one image can be input.

When the crop box is specified on the command line, the value to
@option{--output} will be used as a file name. If no output is
specified or if it is a directory, the output file name will follow
the automatic output names of gnuastro, see @ref{Automatic output}
for the input image.

The header of each output cropped image will contain the names of the
input image(s) it was cut from. If a name is longer than the 70
character space that the FITS standard allows for header keyword
values, the name will be cut into several keywords from the nearest
slash (@key{/}). The keywords have the following format:
@command{ICFn_m}. Where @command{n} is the number of the image used in
this crop and @command{m} is the part of the name. Following the name
is another keyword named @command{ICFnPIX} which shows the pixel range
from that input image in the same syntax as @ref{Crop section syntax}.

Once done, a log file will be created in the current directory named
@file{astimgcrop.log}. This file will keep the names of all the
outputs along with the number of images that were used in them and
also whether the central pixels of the cropped image are full. There
are also comments on the top explaining basic information about the
run. If the log file cannot be created (for example you don't have
write permission in the directory you are running ImageCrop in) it
will not be created (unless @option{--individual} is called). You can
see the same results in verbose mode on the command line in such
cases.

@node ImageCrop future,  , Invoking astimgcrop, ImageCrop
@subsection ImageCrop future updates
Currently we have these updated in mind for ImageCrop:

@itemize
@item
Add an option to save/read the required meta-data of each input image
in an ASCII (or maybe but hopefully not a binary) file. Such that all
the information in the @code{inputimgs} structure (in @file{main.h})
is included in it. Such a file can become important when the images
are always the same and there are lots of requests. The reason a
binary might be necessary is that it includes the @code{wcsprm}
structure of WCSLIB. We certainly don't want to run the WCSLIB
settings each time (they are not thread safe and can be slow). The
good thing with an ASCII file is that it is transparent.

@item
Add checks and conditions so if the input image or crop box cover the
celestial poles, the overlaps can still be found. Currently if either
the crop box or input image pass the equator, there is no problem.

@item
Find a better search method in WCS mode. Currently, for each target,
the region of every image is checked, which makes the job a little
slow when there are a lot of input images. If a specific organization
is defined for the @code{inputimgs} array where the images are ordered
some how so images far from a crop are not searched it would make it
much more efficient. There are also much faster search strategies.
@end itemize
















@node ImageTransform, ImageArith, ImageCrop, Image manipulation
@section ImageTransform
Sometimes it is required that the image be trasformed (flipped,
rotated, sheared or ...) This program will do that.




@node ImageArith, EllipMask, ImageTransform, Image manipulation
@section ImageArith
By arithmetic on images, we mean applying various arithmetic
operations on all the pixels of several images, for example adding all
the pixels in one image with another.













@node EllipMask,  , ImageArith, Image manipulation
@section EllipMask

EllipMask will mask some of the pixels in the image based on
elliptical parameters that are specified through an ASCII catalog.


















@node Image analysis, Modeling and fittings, Image manipulation, Top
@chapter Image analysis

Astronomical images contain very valuable information, the tools in
this section can help in extracting and quantifying that information.

@menu
* ImageStat::                   Basic statstics of image pixels
* SubtractSky::                 Subtract the sky level from the image.
* NoiseChisel::                 Detect and segment objects in noise.
@end menu

@node ImageStat, SubtractSky, Image analysis, Image analysis
@section ImageStat
Image stat is a tool to extract basic pixel statistics from an image
or part of it. It will also output the histogram, cumultiave frequency
and sigma-clipping results.

@node SubtractSky, NoiseChisel, ImageStat, Image analysis
@section SubtractSky

In any noisy image, the level that noise fluctuates around is the most
vital statistic. Since it directly determins all subsequent
measurements on the data. Subtract Sky will find that level in an
image which might potentially have strong gradients and subtract it.

@node NoiseChisel,  , SubtractSky, Image analysis
@section NoiseChisel

NoiseChisel is the tool that started gnuastro! It is a new noise
based algorithm to detect extremely faint and amorphous objects in
noise. Galaxies apparently have a very rich dynamic history and we
cannot image them in their full 3D glory, these resulting in a
multitude of shapes when they are imaged.

Using a noise based approach to detect signal and its substructure in
noise, NoiseChisel will detect and catalog all the galaxies and their
substructure in an image irrespective of their shape.




















@node Modeling and fittings, Table manipulation, Image analysis, Top
@chapter Modeling and fitting

In order to fully understand our observations after initial analysis
on the image, it is very important to compare them with the existing
models to be able to further understand both our models and the
data. The tools in this chapter create model galaxies and will provide
2D fittings to be able to understand our detections.

@menu
* Modeling basics::             Astronomical modeling basics.
* MakeProfiles::                Making mock galaxies and stars.
@end menu


@node Modeling basics, MakeProfiles, Modeling and fittings, Modeling and fittings
@section Modeling basics

In the subsections below we will first review some very basic
information and the basic concepts behind modeling a real astronomical
image. You can skip this subsection if you are already sufficiently
familiar with these concepts.

@menu
* Defining an ellipse::         Defining an ellipse in 2D.
* PSF::                         Radial profiles for the PSF.
* Stars::                       Making mock star profiles.
* Galaxies::                    Radial profiles for galaxies.
* Sampling from a function::    Sample a function on a pixelated canvas.
* Oversampling::                Oversampling the model.
* Noise::                       The basics of noise.
@end menu

@node Defining an ellipse, PSF, Modeling basics, Modeling basics
@subsection Defining an ellipse

The PSF, see @ref{PSF}, and galaxy radial profiles are generally
defined on an ellipse so in this section we will first review how an
ellipse can be defined on a pixelated 2D surface. Labeling the major
axis of an ellipse @mymath{a}, and its minor axis with @mymath{b}, the
axis ratio is defined as: @mymath{q\equiv b/a}. The major axis of an
ellipse can be aligned in any direction, we therefore define the angle
of the major axis to the horizontal axis of the image as the position
angle of the ellipse and in this manual, we show it with
@mymath{\theta}.

Our aim is to put a radial profile of any functional form @mymath{f(r)}
over an ellipse. Lets define the radial distance @mymath{r_{el}} as the
distance on the major axis to the center of the ellipse which is
located at @mymath{x_c} and @mymath{y_c}. We want to find the elliptical
distance of a point located at @mymath{(i,j)}, in the image coordiate
system, from the center of the ellipse. First we rotate the coordinate
system by @mymath{\theta} to get the new rotated coordiantes of that point
@mymath{(i_r,j_r)}:

@dispmath{i_r(i,j)=(i_c-i)\cos(\theta)+(j_c-j)\sin(\theta)}
@dispmath{j_r(i,j)=(j_c-j)\cos(\theta)-(i_c-i)\sin(\theta)}

@noindent The elliptical distance of a point located at @mymath{(i,j)}
can now be defined as: @mymath{r_{el}^2=\sqrt{i_r^2+j_r^2/q^2} }. To
place the radial profiles explained below over an ellipse, we simply
calculate @mymath{f(r_{el}(i,j))} based on the functional radial profile
desired.

The way MakeProfiles builds the profile is that the nearest pixel in the
image to the given profile center is found and the profile value is
calcuated for it, see @ref{Sampling from a function}. The next pixel
which the profile value is calculated on is the next nearest neighbor
of the initial pixel to the profile center (as defined by
@mymath{r_{el}}). This is done fairly efficiently using a breadth
first parsing
strategy@footnote{@url{http://en.wikipedia.org/wiki/Breadth-first_search}}
which is implemented through an ordered linked list.

Using this approch, we only go over one layer of pixels on the
circumference of the profile to build the profile. Not one more extra
pixel has to be checked. Another consequence of this strategy is that
extending MakeProfiles to three dimensions becomes very simple: only the
neighbours of each pixel have to be changed. Everything else after
that (when the pixel index and its radial profile have entered the
linked list) is the same, not matter what number of dimensions we are
dealing with.



@node PSF, Stars, Defining an ellipse, Modeling basics
@subsection Point Spread function

Assume we have a ``point'' source. When we take an image of it, it
will ``spread'' over an area. To quantify that spread, we can define a
``function''. This is how we define the point spread function or the
PSF of the image. This ``spread'' can have various causes, for example
in ground based astronomy, due to the atmosphere. In practice we can
never surpass the ``spread'' due to the diffraction of our lens
aperture. Vairous other effects can also be quantified through a PSF.
For example, the simple fact that we are sampling in a discrete space,
namely the pixels, also produces a very small ``spread'' in the image
we take.

We want the total flux of an object to remain unchanged after applying
the ``spread'' by convolution. Therefore, it is important that the sum
of all the pixels of the PSF be unity. The image also has to have an
odd number of pixels on its sides so one pixel can be defined as the
center. In MakeProfiles, the PSF can be set by the two methods explained
below.

@table @asis

@item Parametric functions
A known mathematical function is used to make the PSF. In this case,
only the paramaters to define the functions are necessary and MakeProfiles
will make a PSF based on the given parameters for each function. In
both cases, the center of the profile has to be exactly in the middle
of the central pixel of the PSF (which is automatically done by
MakeProfiles). When talking about the PSF, usually, the full width at half
maximum or FWHM is used as a scale of the width of the PSF.

@table @cite
@item Gaussian
In the older papers, and to a lesser extent even today, some
researchers use the 2D gaussian function to approximate the PSF of
ground based images. In its most general form, a Gaussian function can
be written as:

@dispmath{f(r)=a \exp \left( -(x-\mu)^2 \over 2\sigma^2 \right)+d}

Since the center of the profile is pre-defined, @mymath{\mu} and
@mymath{d} are constrained. @mymath{a} can also be found because we want
the function to be normalized. So the only important parameter for
MakeProfiles is the @mymath{\sigma}. In the Gaussian function we have this
relation between the FWHM and @mymath{\sigma}:

@cindex Gaussian FWHM
@dispmath{\rm{FWHM}_g=2\sqrt{2\ln{2}}\sigma \approx 2.35482\sigma}

@cindex Moffat function
@item Moffat
The Gaussian profile is much sharper than the images taken from stars
on photographic plates or CCDs. Therefore in 1969, Moffat proposed
this functional form for the image of stars:

@dispmath{f(r)=a \left[ 1+\left( r\over \alpha \right)^2 \right]^{-\beta}}

@cindex Moffat @mymath{\beta}
Again, @mymath{a} is constrained by the normalization, therefore two
paramters define the shape of the Moffat function: @mymath{\alpha} and
@mymath{\beta}. The radial parameter is @mymath{\alpha} which is related
to the FWHM by

@cindex Moffat FWHM
@dispmath{\rm{FWHM}_m=2\alpha\sqrt{2^{1/\beta}-1}}

@noindent
Comparing with the PSF predicted from atmospheric turbulence theory
with a Moffat function, Trujillo et al.@footnote{Trujillo, I.,
J. A. L. Aguerri, J. Cepa, and C. M. Gutierrez (2001). ``The effects
of seeing on S@'ersic profiles - II. The Moffat PSF''. In: MNRAS 328,
pp. 977---985.} claim that @mymath{\beta} should be 4.765. They also
show how the Moffat PSF contains the Gaussian PSF as a limiting case
when @mymath{\beta\to\infty}.

@end table

@item An input FITS image
An input image can also be specified to be used as a PSF.
@end table


While the Gaussian is only dependent on the FWHM, the Moffat function
is also dependant on @mymath{\beta}. Comparing these two functions
with a fixed FWHM gives the following results:

@itemize
@item
Within the FWHM, the functions don't have significant differences.
@item
For a fixed FWHM, as @mymath{\beta} increases, the Moffat function
becomes sharper.
@item
The Gaussian function is much sharper than the Moffat functions, even
when @mymath{\beta} is large.
@end itemize




@node Stars, Galaxies, PSF, Modeling basics
@subsection Stars

In MakeProfiles, we generally consider stars to be a point source. This is
usually the case for extra galactic studies, were nearby stars are
also in the field. Since a star is only a point source, we assume that
it only fills one pixel prior to convolution. Infact, exactly for this
reason, in astronomical images the light profiles of stars are one of
the best methods to understand the shape of the PSF and a very large
fraction of scientific research is preformed by assuming the shapes of
stars to be the PSF of the image.





@node Galaxies, Sampling from a function, Stars, Modeling basics
@subsection Galaxies

Today, most practitioners agree that galaxy profiles can be modeled
with one or a few generalized de Vaucouleur's (or S@'ersic) profiles.

@dispmath{I(r) = I_e exp \left ( -b_n \left[ \left( r \over r_e \right)^{1/n} -1 \right] \right )}

G@'erard de Vaucouleurs (1918-1995) was first to show in 1948 that
this function best fits the galaxy light profiles, with the only
difference that he held @mymath{n} fixed to a value of 4. 20 years
later in 1968, J. L. S@'ersic showed that @mymath{n} can have a
variety of values and does not necessarily have to be 4.

This profile depends on the effective radius (@mymath{r_e}) which is
defined as the radius which contains half of the total brightness of
the object. The total brightness is defined as the integration of the
profile to infinity. @mymath{I_e} is the surface brightness at the
effective radius.  The S@'ersic index @mymath{n} is used to define the
concentration of the profile within @mymath{r_e} and @mymath{b_n} is a
constant dependent on @mymath{n}. MacArthur et al.@footnote{MacArthur,
L. A., S. Courteau, and J. A. Holtzman (2003). ``Structure of
Disk-dominated Galaxies. I. Bulge/Disk Param- eters, Simulations, and
Secular Evolution''. In: ApJ 582, pp. 689---722.} show that for
@mymath{n>0.35}, @mymath{b_n} can be accurately approximated using
this equation:

@dispmath{b_n=2n - {1\over 3} + {4\over 405n} + {46\over 25515n^2} + {131\over 1148175n^3}-{2194697\over 30690717750n^4}}





@node Sampling from a function, Oversampling, Galaxies, Modeling basics
@subsection Sampling from a function

A pixel is the ultimate level of accuracy we have to gather data, we
can't get any more accurate in one image. We call this
sampling. However, the mathematical profiles which we describe our
models have infinite accuracy. Over a large fraction of the area of
astrophysically interesting profiles (for example galaxies or PSFs),
the variation of the profile over the area of one pixel is not too
significant. In such cases, we can simply use the elliptical radius
(@mymath{r_{el}}, see @ref{Defining an ellipse}), of the center of the
pixel and assign that as the final value of the pixel.

As you approach their center, some galaxies become very sharp (their
value significantly changes over one pixel's area). This sharpness
increases with smaller effective radius and larger S@'ersic values.
Thus rendering the central value extremely inaccruate. The first
method that comes to mind for solving this problem is integration, we
can integrate the functional form of the profile over the pixel area
in a 2D integration process. However, unfortunately numerical
integration techniques also have their limitations and when such sharp
profiles are needed they can become extremely inaccurate.

The most accurate method to try to sample a continuous profile on a
discrete space (sampling) is by choosing a large number of random
points within the boundaries of the pixel and taking their average
value (or Monte Carlo integration). This is also, generally speaking,
what happens in practice with the photons on the pixel. The number of
random points can be set with @option{--numrandom}.

Unfortunately, repeating this MonteCarlo process would be extremely
time and CPU consuming if it is to be applied to every pixel. In order
to not loose too much accuracy, in MakeProfiles, we build the profile
using both methods explained above. The building of the profile
begins from its central pixel and continues outwards. We try Monte
Carlo integration (which yields @mymath{F_r}) and central pixel value
(@mymath{F_c}) on the same pixel. If the fractional difference
(@mymath{|F_r-F_c|/F_r}) is lower than a given tolerance level we will
stop using random points and only use the central pixel value.

The ordering of the pixels in this inside-out construction is based on
@mymath{r=\sqrt{(i_c-i)^2+(j_c-j)^2}}, not @mymath{r_{el}}, see
@ref{Defining an ellipse}. When the axis ratios are large (near one)
this is fine. But when they are small and the object is highly
elliptical, it might seem more reasonable to follow @mymath{r_{el}}
not @mymath{r}. The problem is that the gradient is stronger in pixels
with smaller @mymath{r} (and larger @mymath{r_{el}}) than those with
smaller @mymath{r_{el}}. In other words, the gradient is strongest
along the minor axis. So if we follow the pixels based on
@mymath{r_{el}}, we will reach the tolerance level sooner and miss
lots of pixels with large difference between the more accurate and
less acurate sampling methods.






@node Oversampling, Noise, Sampling from a function, Modeling basics
@subsection Oversampling

The steps explained in @ref{Sampling from a function} do give an
accurate representation of a profile prior to convolution. However, we
should have in mind, that in an actual observation, the image is first
convolved with or blurred by the atmospheric and instrument PSF in a
continuous space and then it is sampled on the discrete pixels of the
camera.

In order to more accurately simulate this process, we can make the
unconvoved image and the PSF on a finer pixel grid. In other words,
the output image is a certain odd-integer multiple of the desired
size, we can call this ``oversampling''. The user can specify this
multiple as a command line option. The reason this has to be an odd
number is that the PSF has to be centered on the center of its
image. An image with an even number of pixels on each side does not
have a central pixel.

The image can then then be convolved with the PSF (which should also
be oversampled on the same scale). Finally, image can be subsampled to
get to the initial desired pixel size of the output image. After this,
mock noise can be added as explained in the next section. This is
because unlike the PSF, the noise occurs in each output pixel, not on
a continues space like all the prior steps.




@node Noise,  , Oversampling, Modeling basics
@subsection Noise
@cindex Image noise
@cindex Noise
Deep astronomical images, like those used in extra galactic studies
seriously suffer from noise in the data. Generally speaking, the
sources of noise in an astronomical image are:

@menu
* Photon counting noise::       Poisson noise
* Instrumental noise::          Readout, dark current and other sources.
* Final noised pixel value::    How the final noised value is calculated.
@end menu

@node Photon counting noise, Instrumental noise, Noise, Noise
@subsubsection Photon counting noise
Thanks to the very accurate electronics used in today's CCDs, this
type of noise is the main cause of concern for extra galactic studies.
It can generally be associate with the counting error that is known to
have a Poissonian distribution. The Poisson distribution is about
counting. But counting is a discrete operation with only positive
values, for examle we can't count @mymath{3.2} or @mymath{-2} of
anything. We only count @mymath{0}, @mymath{1}, @mymath{2}, @mymath{3}
and so on. Therefore the Poisson distribution is also a discrete
distribution, only applying to whole positive integers.

Lets assume that we know the mean value of counting something, in this
case, the number of electrons that are produced by photons in the CCD,
is @mymath{\lambda}.  Lets take @mymath{k} to represent the result of
counting in one particular time we attempt to count. The probability
denstity function of @mymath{k} can be written as:

@cindex Poisson distribution
@dispmath{f(k)={\lambda^k \over k!} e^{-\lambda},\quad k\in \{0, 1, 2,
3, \dots \}}

@cindex Skewed poisson distribution
Because the Poisson distribution is only applicable to positive
values, it is by nature very skewed when @mymath{\lambda} is near
zero. One qualitative way to imagine it is that there simply aren't
enough integers smaller than @mymath{\lambda}, than there are larger
integers. Therefore to accomodate all possibilities, it has to be
skewed when @mymath{\lambda} is small.

But as @mymath{\lambda} becomes larger and larger, the distribution
becomes more and more symmetric. One very useful property of the
Poisson distribution is that the mean value is also its variance.
When @mymath{\lambda} is very large, say @mymath{\lambda>1000}, then
the normal (Gaussian) distribution, see @ref{PSF}, is an excellent
approximation of the poisson distribution with mean
@mymath{\mu=\lambda} and standard deviation
@mymath{\sigma=\sqrt{\lambda}}.

We see that the variance or dispersion of the distribution depends on
the mean value, and when it is large we can approximate it with a
Gaussian that only has one free parameter (@mymath{\mu=\lambda} and
@mymath{\sigma=\sqrt{\lambda}}) instead of two that it originally
has.

The astronomical objects after convolution with the PSF of the
instrument, lie above a certain background flux. This background flux
is defined to be the average flux of a region in the image that has
absolutely no objects. The physical origin of this background value is
the brightness of the atmosphere. It is thus an ideal definition,
because in practice, we never know what lies deep in the noise far
lower than our detection criteria@footnote{See the section on sky in
Akhlaghi M. Ichikawa. T. 2015...}. However, in a real image, a
relatively large number of very faint objects can been fully buried in
the noise. These undetected objects will bias our background
measurement to slightly larger values. We therefore define the sky
value to be the average of the undetected regions in the image, so in
an ideal case where we have successfully detected all the objects, the
sky value and background value are the same.

As we go to longer wavelengths, the background value becomes more
significant and also varies over a wide image field. Such variations
are not currently implemented in MakeProfiles, but will be in the
future. In a mock image, we have the luxuary of setting the background
value.

In each pixel of the canvas of pixels we have made to build the
galaxies, we might have contributions from various sources. Also the
image has been convolved prior to adding noise. Lets name this flux of
the convolved sum of possibly overlapping objects, @mymath{I_{nn}}.
@mymath{nn} representing ``no noise''. For now, lets assume the
background is constant and represented by @mymath{B}. In practice the
background values are larger than @mymath{\sim1,000} counts. Then the
flux after adding noise is a radom value taken from a Gaussian
distribution with the following mean (@mymath{\mu}) and standard
deviation (@mymath{\sigma}):

@dispmath{\mu=B+I_{nn}, \quad \sigma=\sqrt{B+I_{nn}}}

@node Instrumental noise, Final noised pixel value, Photon counting noise, Noise
@subsubsection Instrumental noise
While taking images with a camera, a dark current is fed to the
pixels, the variation of the value of this dark current over the
pixels, also adds to the final image noise. Another source of noise is
the readout noise that is produced by the electronics in the CCD that
attempt to read the amount of flux that was recorded. In deep
extra-galactic studies these sources of noise are not as significant
as the noise of the background sky. Let @mymath{C} represent the
combined standard deviation of all these sources of noise. If we only
have this source of noise, the noised pixel value would be a random
value chosen from a Gaussian distribution with

@dispmath{\mu=I_{nn}, \quad \sigma=\sqrt{C^2+I_{nn}}}


@node Final noised pixel value,  , Instrumental noise, Noise
@subsubsection Final noised pixel value
Depending on the values you specify for @mymath{B} and @mymath{C} from
the above, the final noised value for each pixel is a random value
chosen from a Gaussian distribution with

@dispmath{\mu=B+I_{nn}, \quad \sigma=\sqrt{C^2+B+I_{nn}}}





@node MakeProfiles,  , Modeling basics, Modeling and fittings
@section MakeProfiles

MakeProfiles will create mock astronomical profiles from a catalog,
either individually or together in one output image. In data analysis,
making a mock image can act like a calibration tool, through which you
can test how successfully your detection technique is able to detect a
known set of objects. There are commonly two aspects to detecting: the
detection of the fainter parts of bright objects (which in the case of
galaxies fade into the noise very slowly) or the complete detection of
an over-all faint object. Making mock galaxies is the most accurate
(and idealistic) way these two aspects of a detection algorithm can be
tested. You also need mock profiles in fitting known functional
profiles with observations.

MakeProfiles was initially built for extra galactic studies, so
currently the only astronomical objects it can produce are stars and
galaxies. We welcome the simulation of any other astronomical
object. The general outline of the steps that MakeProfiles takes are
the following:

@enumerate

@item
Build the full profile out to its truncation radius in a possibly
oversampled array.

@item
Multiply all the elements by a fixed constant so its total magnitude
equals the desired total magnitude.

@item
If @option{--individual} is called, save the array for each profile to
a FITS file.

@item
If @option{--nomerged} is not called, add the overlapping pixels of
all the created profiles to the output image and abort.

@end enumerate

Using input values, MakeProfiles adds the World Coordinate System
(WCS) headers of the FITS standard to all its outputs (except PSF
images!). For a simple test on a set of mock galaxies in one image,
there is no need for the third step or the WCS information.

However in complicated simulations like weak lensing simulations,
where each galaxy undergoes various types of individual
transformations based on their position, those transformations can be
applied to the different individual images with other programs. After
all the transformations are applied, using the WCS information in each
individual profile image, they can be merged into one output image for
convolution and adding noise.

@menu
* If convolving afterwards::    Considerations for convolving afterwards.
* Profile total magnitude::     Definition of total profile magnitude.
* Invoking astmkprof::          Inputs and Options for MakeProfiles.
* MakeProfiles future updates::  Plans for the future of MakeProfiles.
@end menu



@node If convolving afterwards, Profile total magnitude, MakeProfiles, MakeProfiles
@subsection If convolving afterwards
In case you want to convolve the image later with a given point spread
function, make sure to use a larger image size. After convolution, the
profiles become larger and a profile that is normally completely
outside of the image might fall within it.

On one axis, if you want your final (convolved) image to be @mymath{m}
pixels and your PSF is @mymath{2n+1} pixels wide, then when calling
MockProfiles, set the axis size to @mymath{m+2n}, not @mymath{m}. You
also have to shift all the pixel positions of the profile centers on
the that axis by @mymath{n} pixels to the positive.

After convolution, you can crop the outer @mymath{n} pixels with the
section crop box specification of ImageCrop:
@option{--section=n:*-n,n:*-n} assuming your PSF is a square, see
@ref{Crop section syntax}. This will also remove all discrete Fourier
transform artifacts (blurred sides) from the final image. To
facilitate this shift, MakeProfiles has the options @option{--xshift},
@option{--yshift} and @option{--prepforconv}, see @ref{Invoking
astmkprof}.


@node Profile total magnitude, Invoking astmkprof, If convolving afterwards, MakeProfiles
@subsection Profile total magnitude
It is customary to use the 2D integration to infinity of a profile as
its total magnitude. However, in MakeProfile, we do not follow this
idealistic approach and apply a more realistic method to find the
total magnitude: the sum of all the pixels belonging to a profile
within its truncation radius. Note that if the truncation radius is
not large enough, this can be significantly different from the total
integrated light to infinity.

An integration to infinity is not a realistic condition because no
galaxy extends indefinitely (important for high S@'ersic index
profiles), pixelation can also cause a significant difference between
the actual total pixel sum value of the profile and that of
integration to infinity, especially in small and high S@'ersic index
profiles. To be safe, you can specify a large enough truncation radius
for such compact high S@'ersic index profiles.

If oversampling is used then the total flux is calculated using the
over-sampled image, see @ref{Oversampling} which is much more
accurate. We first build the profile in an array completely bounding
it with a normalization constant of unity. Taking @mymath{F} to be the
desired total flux and @mymath{S} to be the sum of the pixels in the
created profile, every pixel is then multiplied by @mymath{F/S} so the
sum is exactly @mymath{F}.

If the @option{--individual} option is called, this same array is
written to a FITS file. If not, only the overlaping pixels of this
array and the output image are kept and added to the output array.

The total brightness of the object is not specified in units of flux,
but in magnitudes. The magnitude scale is a relative measure of
brightness. When a reference object has magnitude @mymath{m_r} with
flux @mymath{F_r}, then the magnitude of an object with a flux of
@mymath{F} is calculated by:

@dispmath{m-m_r=-2.5\log_{10} \left( F \over F_r \right)}

We define the ``zeropoint'' magnitude (@mymath{m_z}) as the magnitude
in which @mymath{F_r=1}. So when you specify the magnitude of your
desired object in the @option{--mcol} of your input catalog, then it
will have a total flux of:

@dispmath{\log_{10}F={m_z-m \over 2.5} \rightarrow
          F=10^{m_z-m \over 2.5}}


@node Invoking astmkprof, MakeProfiles future updates, Profile total magnitude, MakeProfiles
@subsection Invoking MakeProfiles

The general template to run MakeProfiles is:

@example
astmkprof [OPTION ...] Catalog
@end example

@noindent
If mock galaxies are to be made, the catalog (which stores the
parameters for each mock profile) is the mandatory argument. The input
catalog has to be a text file formatted in a table with columns
separated by space, tab or comma (@key{,}) characters. See @ref{Common
behavior} for a complete explanation of some common behaviour and
options in all gnuastro programs including MakeProfiles.


@menu
* MakeProfiles catalog::        Required catalog properties.
* MakeProfiles options::        Full list of MakeProfiles options.
* MakeProfiles output::         The generated outputs.
@end menu

@node MakeProfiles catalog, MakeProfiles options, Invoking astmkprof, Invoking astmkprof
@subsubsection MakeProfiles catalog
The catalog is a text file table. Its columns can be ordered in any
desired manner, you can specify which columns belong to which
parameters using the set of options ending with @option{col}, for
example @option{--xcol} or @option{--rcol}, see @ref{MakeProfiles
options}.

The value for the profile center in the catalog (in the
@option{--xcol} and @option{--ycol} columns) can be a floating point
number so the profile center can be on any sub-pixel position. Note
that pixel positions in the FITS standard start from 1 and an integer
is the pixel center. So a 2D image actually starts from the position
(0.5, 0.5). In MakeProfiles profile centers do not have to be in the
image.  Even if only one pixel of the profile within the truncation
radius is within the output image, that pixel is included in the
image. Profiles that are completely out of the image will not be
created. You can use the output log file to see which profiles were
within the image.

If PSF profiles (Moffat or Gaussian) are in the catalog and the
profiles are to be built in one image (when @option{--individual} is
not used), it is assumed they are the PSF(s) you want to convolve your
created image with. So by default, they will not be built in the
output image but as seperate files. The total flux of these separate
files will also be set to unity (1) so you are ready to convolve. As a
summary, their position and magnitude will be ignored. This behaviour
can be disabled with the @option{--psfinimg} option. If you want to
create all the profiles separately (with @option{--individual}) and
you want the total flux of your PSF profiles to be unity, you have to
set their magnitudes in the catalog to the zeropoint magnitude and be
sure that the central positions of the profiles don't have any
fractional part (the PSF center has to be in the center of the pixel).


@node MakeProfiles options, MakeProfiles output, MakeProfiles catalog, Invoking astmkprof
@subsubsection MakeProfiles options
The common options that are shared by gnuastro progarms, are fully
explained in @ref{Common options} and are not repeated here. Since
there are no image inputs, the@option{--hdu} option is ignored. The
options can be classified into the following categories: Output,
Profiles, Catalog and WCS. Below we will review each one.

@noindent
Output:

@table @option

@item -x
@itemx --naxis1
(@option{=INT}) The number of pixels in the output image along the
first FITS axis (horizontal when viewed in SAO ds9). This is before
over-sampling. For example if you call MakeProfiles with
@option{--naxis1=100 --oversample=5} (assuming no shift due for later
convolution), then the final image size along the first axis will be
500.

@item -y
@itemx --naxis2
(@option{=INT}) The number of pixels in the output image along the
second FITS axis (vertical when viewed in SAO ds9), see the
explanation for @option{--naxis1}.

@item -s
@itemx --oversample
(@option{=INT}) The scale to over-sample the profiles and final
image. If not an odd number, will be added by one, see
@ref{Oversampling}.

@item --psfinimg
Build the possibly existing PSF profiles (Moffat or Gaussian) in the
catalog into the final image. By default they are built separately so
you can convolve your images with them, thus their magnitude and
positions are ignored. With this option, they will be built in the
final image like every other galaxy profile. To have a final PSF in
your image, make a point profile where you want the PSF and after
convolution it will be the PSF.

@item -i
@itemx --individual
If this option is called, each profile is created in a separate FITS
image named with the row number of the profile in the catalog. In this
case, only the subpixel position of the profile center is
important.

The output will have an odd number of pixels. If there is no
oversampling, the central pixel will contain the profile center. If
the value to @option{--oversample} is larger than unity, then the
profile center is on any of the central @option{--oversample}'d pixels
depending on the fractional value of the profile center.

If the fractional value is larger than half, it is on the bottom half
of the central region. This is due to the FITS definition of a real
number position: The center of a pixel has fractional value
@mymath{0.00} so each pixel contains these fractions: .5 -- .75 -- .00
(pixel center) -- .25 -- .5.

@item -m
@itemx --nomerged
Don't make a merged image. By default after making the profiles, they
are added to a final image with sides of @option{--naxis1} and
@option{--naxis2} if they overlap with it.

@end table

@noindent
Profiles:

@table @option

@item -r
@itemx --numrandom
The number of random points used in the centeral regions of the
profile, see @ref{Sampling from a function}.

@item -t
@itemx --tolerance
(@option{=FLT}) The tolerance to switch from Monte Carlo integration
to the central pixel value, see @ref{Sampling from a function}.

@item -p
@itemx --tunitinp
The truncation column of the catalog is in units of pixels. By
default, the truncation column is considered to be in units of the
radial paramters of the profile (@option{--rcol}). Read it as
``t-unit-in-p'' for ``truncation unit in pixels''.

@item -X
@itemx --xshift
(@option{=INT}) Shift all the profiles and enlarge the image along the
first FITS axis, see @mymath{n} in @ref{If convolving
afterwards}. This is useful when you want to convolve the image
afterwards. If you are using an external PSF, be sure to oversample it
to the same scale used for creating the mock images.

@item -Y
@itemx --yshift
(@option{=INT}) Similar to @option{--xshift} for the the second FITS
axis.

@item -c
@itemx --prepforconv
Shift all the profiles and enlarge the image based on half the width
of the first Moffat or Gaussian profile in the catalog, considering
any possible oversampling see @ref{If convolving
afterwards}. @option{--prepforconv} is only checked and possibly
activated if @option{--xshift} and @option{--yshift} are both zero
(after reading the command line and configuration files).

@item -z
@itemx --zeropoint
(@option{=FLT}) The zeropoint magnitude of the image.

@end table

@noindent
Catalog: The value to all of these options is considered to be a
column number, where counting starts from zero.

@table @option

@item --fcol
(@option{=INT}) The functional form of the profile with one of the
values below. Note that this value will be converted to an integer
before analysis using the internal type conversion of C. So for
example 2.80 will be converted to 2.

@itemize
@item
0: S@'ersic.
@item
1: Moffat.
@item
2: Gaussian.
@item
3: Point source (a star).
@end itemize

@item --xcol
(@option{=INT}) The center of the profiles along the first FITS axis
(horizontal when viewed in SAO ds9).

@item --ycol
(@option{=INT}) The center of the profiles along the second FITS axis
(vertical when viewed in SAO ds9).

@item --rcol
(@option{=INT}) The radius parameter of the profiles. Effective radius
(@mymath{r_e}) if S@'ersic, FWHM if Moffat or Gaussian.

@item --ncol
(@option{=INT}) The S@'ersic index (@mymath{n}) or Moffat
@mymath{\beta}.

@item --pcol
(@option{=INT}) The position angle (in degrees) of the profiles
relative to the first FITS axis (horizontal when viewed in SAO ds9).

@item --qcol
(@option{=INT}) The axis ratio of the profiles (minor axis divided by
the major axis).

@item --mcol
(@option{=INT}) The total pixelated magniude of the profile within the
truncation radius, see @ref{Profile total magnitude}.

@item --tcol
(@option{=INT}) The truncation radius of this profile. By default it
is in units of the radial parameter of the profile (the value in the
@option{--rcol} of the catalog). If @option{--tunitinp} is given, this
value is interpreted in units of pixels (prior to oversampling)
irrespective of the profile.

@end table

@noindent
WCS:

@table @option

@item --crpix1
(@option{=FLT}) The pixel coordinates of the WCS reference point on
the first (horizontal) FITS axis (counting from 1).

@item --crpix2
(@option{=FLT}) The pixel coordinates of the WCS reference point on
the second (vertical) FITS axis (counting from 1).

@item --crval1
(@option{=FLT}) The Right Ascension (RA) of the reference point.

@item --crval2
(@option{=FLT}) The Declination of the reference point.

@item --resolution
(@option{=FLT}) The resolution of the non-oversampled image in units
of arcseconds/pixel.

@end table

@node MakeProfiles output,  , MakeProfiles options, Invoking astmkprof
@subsubsection MakeProfiles output

Besides the final merged image of all the profiles or individual
profiles that can be built based on the input options, MakeProfiles
will also create a log file in the current directory (where you run
MockProfiles). The values for each column are explained in the first
few commented (starting with @command{#} character). The log file
includes the following information:

@itemize
@item
The total magnitude of the profile in the image. This will be
different from your input magnitude if the profile was not completely
in the image.

@item
The number of pixels (in the oversampled image) which used Monte Carlo
integration and not the central pixel value.

@item
The fraction of flux in the Monte Carlo integrated pixels.

@item
If an individual image was created or not.
@end itemize

@node MakeProfiles future updates,  , Invoking astmkprof, MakeProfiles
@subsection MakeProfiles future updates

@itemize

@item
Add options to read the RA and Dec of profiles from a catalog instead
of their central position in image coordiantes. In this manner one
catalog can be used to create several mock images.

@item
Currently the whole profile has to have only one mathematical
function, this can easily be extended such that each galaxy has
separate profiles or different ellipticities.

@item
Currently MakeProfiles makes mock profiles on a 2D surface, but due to
the particular way it builds the mock profiles, the infra-structure is
there to make the profiles on a 3D volume and find a real projection
of a real 3D object. Or more generally, make 3D profiles.

@item
Add more progressive states of accuracy: For example the user
specifies the most accurate, number of points, then each time it is
compared with 1/10th of that number and so on until a minimum number
is reached. You don't have to specify two random sets, only one set,
but stop adding to one sum earlier.

@end itemize














@node Table manipulation, Developing, Modeling and fittings, Top
@chapter Table manipulation

The FITS standard also specifies tables as a form of data that can be
stored in the extensions of a FITS file. These tabels can be ASCII
tables or binary tables. The utilities in this section provide the
tools to directly read and write to FITS tables.

The software for this section have to be added ....




















@node Developing, GNU Free Documentation License, Table manipulation, Top
@chapter Developing

The basic idea of GNU Astronomy Utilities is for an interested
astronomer to be able to easily understand the code of any of the
programs, be able to modify the code if she feels there is an
improvement and finally, to be able to add new programs to the
existing utilities for their own benefit, and the larger community if
they are willing to share it. In short, we hope that at least from the
software point of view, we can break the ``obscurantist faith in the
expert's special skill and in his personal knowledge and authority'',
see @ref{Science and software}. The following software architecture
can be one of the most basic and easy to understand for any interested
inquirer.

The source code for gnuastro, this manual and the tests are divided
in the following sub-directories of the top directory. Their names are
standard and descriptive enough, but we will give a short summary
here:

@table @file

@item doc
The Texinfo source files for this manual.

@item include
The header files of the internal static libraries and also some other
header files that are used by more than one program.

@item lib
The internal static libraries (only their @file{.c} files) are stored
here. These libraries hold functions that are used by more than one
program, they will not be installed.

@item src
This directory contains a subdirectory for every program in this
version of gnuastro. The source code for each program is placed
inside each of these subdirectories to be easily separable.

@item tests
This directory keeps all the tests (checks) which are executed when
@command{make check} is run.

@end table

Below, we will first review how to obtain the version controlled
source. The libraries and headers in their respective directories are
then explained. Later we will discuss the basic conventions for
managing the code in each program to facilitate reading the code by an
outside inquirer. Finally some notes on the building process are
given.


@menu
* Version controlled source::   How to get and prepare the VCSed code.
* Internal libraries::          Internal static (not installed) libraries.
* Headers::                     Library and common headers.
* Program source::              Conventions for the code.
* Test scripts::                Understanding the test scripts.
* Building::                    Explanations on building.
* After making changes::        Run `make distcheck` after making changes.
@end menu





@node Version controlled source, Internal libraries, Developing, Developing
@section Version controlled source

The source code that is publicly distributed does not contain the
revision history, it is only the final snapshot of a stable release,
ready to be configured and built. To be able to develop successfully,
the revision history of the code can be very useful, also some updates
that are not yet released might be in it.

We use Git for the verion control of gnuastro. For those who are not
familiar with it, we suggest the Pro Git
book@footnote{@url{http://git-scm.com/book/en/v2}}, it is publicly
available for online reading and downloading. To clone the latest
version of gnuastro you can run

@example
$ git clone git://git.sv.gnu.org/gnuastro
@end example

@noindent
This version of the source code lacks the files that are automatically
built (and included in the distributed
@file{gnuastro-@value{VERSION}.tar.gz}) for configuration and
building. To create those files you have to run the following command
in the cloned directory which will generate those automatic
files. @command{autoreconf} is part of GNU Autoconf and also requires
GNU Automake and GNU Texinfo to create all the necessary files, see
@ref{Building}.

@example
$ autoreconf --install
@end example

@noindent
Now you can easily configure, build and start hacking into the code
and you have the full revision history under your fingers.


@menu
* Standards::
@end menu

@node Standards,  , Version controlled source, Version controlled source
@subsection Standards

We strive to follow the version control guidelines of the Git project
as our base, until gnuastro grows large enough to define its own. You
can find it in the git project's submitting patches
guideline@footnote{@url{https://github.com/git/git/blob/master/Documentation/SubmittingPatches}}.





@node Internal libraries, Headers, Version controlled source, Developing
@section Internal libraries
Libraries are binary (compiled) files which are not executable them
selves, but once linked with other binary files, they form the
building blocks of larger programs. Several functions are commonly
used by all or several of the programs in gnuastro. Therefore they
are written as separate libraries so we don't have to keep duplicate
code. They are mosly to do with interaction with the outside world (of
the program), for example setting up the configuration files, reading
text catalogs or wrappers for CFITSIO and WCSLIB to facilitate reading
and writing of FITS files.

Below is a short description of some of these libraries. Note that the
headers of these libraries are in the @file{include} directory.

@table @code

@item arraymanip.c
As the name suggests, this library provdies functions with
manipulating an array. For example, there are functions here to copy
an array, initialize all its members to a fixed value or to convert
the values of an array.

@item astrthreads.c
Functions for dividing the jobs between various threads in
multi-threaded programs.

@item box.c
Functions that deal with regions (boxes) in an image, for example to
find the box surrounding an ellipse or to find the possible overlap of
two boxes.

@item checkset.c
The functions and macros in these two files do all the name and file
checkings of your inputs. For example to check if a given file is
actually a file name or a directory, or to build the automatic output,
see @ref{Automatic output}. These functions are used by all the
programs.

@item configfiles.c
The functions to find the configuration file for each program and
macros that help in reading and setting the default values in their
particular files are defined here.

@item fitsarrayvv.c
The functions in this library are essentially a wrapper for CFITSIO
and WCSLIB. Since the functions these two libraries provide are very
low level, we have defined wrapper functions in these source files to
faciliate the job.

@item linkedlist.c
The various programs in gnuastro will need linked lists for various
purposes, for example to keep the names of an unknown number of input
files (string linked lists) or to parse an initially unknown number of
neighbouring pixels within an image. The functions in these source
files provide various types of linked list and functions that are
necessary to easily manipulate them.

@item statistics.c
Statistical functions like finding the minimum and maximum or the
mean, median and standard deviation along with more complicated
functions like sigma clipping are defined in these source files.

@item timing.c
These source files are mainly for verbatim mode, where the time it
took for each step to operate is reported.

@item txtarrayvv.c
The functions in this file read and write an input text catalog to and
from a C array.

@end table

Currently these libraries are not installed along with gnuastro, they
are only staticlly linked to any program needing them in the build
directory and remain or are deleted from there. Note that in a static
link, the contents of the library are megered with the executable, so
they are no longer needed after the linking (you can safely delete
them after installing the executable).

In the future if need be, we can also make them installable so you can
use them in your own personal programs. But for the time being, if you
feel these libararies can be useful for your own programs, you can
simply copy the compiled version (@file{.a} files, which are created
after running @command{$ make}) along with the header of the library
(which is in @file{include}) inside your own source code and link to
it with the link flag of your compiler.

@node Headers, Program source, Internal libraries, Developing
@section Headers

Besides the headers for the libraries listed above, there are also
several header-only files in the @file{include} directory. Below is a
short explanation of thier purpose.

@table @code

@item commonargs.h
All the programs have a common set of options, see @ref{Common
options}. Instead of definding them and making sure they are identical
in the implementation of each program, we have used GNU C library's
ability to merge independent argument parsers with Argp. This ensures
that they are identical in all programs with only one file to work
on. The common options and the function to parse them are thus defined
in this header file. All the argument parsers in various programs are
merged with this argument parser to read your input.

@item commonparams.h
The structure that keeps the values of the common arguments and
whether they have been set or not is defined in this header file.

@item fixedstringmacros.h
Some strings are fixed in all the programs, only the relevant names of
the packages must be put in them. The various names for each package
are defined in their @file{main.h} source file with macros of fixed
names. For example the copyright notice, or parts of the top
information in the @option{--help} output.

@item neighbors.h
The macros in this header find the neighbors of a pixel index using
four or eight connectivity in a region of an image or the whole image.

@end table


@node Program source, Test scripts, Headers, Developing
@section Program source

Besides the fact that all the programs share some functions that were
explained in @ref{Internal libraries}, everything else about each
program is completely independent. Some programs might need lots of
source files and if there is no fixed convention, navigating them for
a specific function or to generally understand their programming steps
can become very hard for a new inquirer into the code. In this section
we have explained the conventions used in all the programs. To easily
understand the explainations in this section, it is good to open the
source files of one or several of the programs in gnuastro and
inspect them as you read along.

@vtable @file

@item main.c
Each executable has a @code{main()} function, which is located in
@file{main.c}. Therefore this file in any program's source code will
be the starting point. No actual processing functions are to be
defined in this file, the function(s) in this file are only meant to
connect the most high level steps of each program, most generally,
they will first call the top user interface function to read user
input and make all the preparations. Then they will pass control to
the top processing function for that program. The functions to do both
these jobs must be defined in other source files.

@item main.h
All the major parameters which will be used in the program must be
stored in a structure which is defined in @file{main.h}. The name of
this structure is usually @code{prognameparams}, for example
@code{imgcropparams}. So @code{#include "main.h"} will be a staple in
all the source codes of the program and most of the functions. Keeping
all the major parameters of a progam in this structure has the major
benefit that most functions will only need one argument: a pointer to
this structure. This will significantly facilitate the job of the
programmer, the inquirer and the computer. All the programs in
gnuastro are designed to be small and independent parts, so this
structure should not get too large.

With this basic root structure, source code of functions can
potentially become full of structure dereference operators
(@command{->}) which can make the code very un-readable. In order to
avoid this, whenever a parameter is used more than a couple of times
in a function, we suggest to define a parameter of the same type and
with the same name as the desired parameter and put the value of the
root structure inside of it in definition time.

The main root structure of a program contains atleast two other
structures: a structure only keeping parameters for user interface
functions, which is also defined in @file{main.h} and the
@code{commonparams} structure which is defined in
@file{commonparams.h}, see @ref{Headers}. The former can become very
large and since the programmer and inquirer often don't need to be
confused with these parameters mixed with the actual processing
parameters, they are conveniently defined in another structure which
is named @code{uiparams} and is also defined in @file{main.h}. It
could be defined in @file{ui.h} (see below) so the main functions
remain completely ignorant to it, but its parameters might be needed
for reporting input conditions, so we have included it as part of the
main program structure.

This top root structure is conveniently called @code{p} (short for
parameters) by all the programs. The @code{uiparams} structure is
called @code{up} (for user parameters) and the @code{commonparams}
structure is called @code{cp}. With this convention any reader can
immediately understand where to look for the definition of one
parameter.

@item args.h
The argument parser structures (which are used by GNU C library's
Argp) for each program are defined in @file{args.h}. They are separate
global variables and function definitions that will be used by
Argp. We recommend going through the appropriate section in GNU C
library to understand their exact meaning, although they should be
descriptive and understandable enough by looking at a few of the
programs.

@item ui.c, ui.h
The user interface functions are also a unique set of functions in all
the programs, so they are particularly named @file{ui.c} and
@file{ui.h} in all the programs. Everything related to reading the
user input arguments and options, checking the configuration files and
checking the consistency of the input parameters before the actual
program is run should be done in this file. Since most functions are
the same, with only the interal checks and structure parameters
differing, we recommend going through several of the examples and
structuring your @file{ui.c} in a similar fashion with the rest of the
programs.

The most high-level function in @file{ui.c} should be named
@code{setparams} which accepts @code{int argc, char *argv[]} and a
pointer to the root structure for that program, see below. This is the
function that @code{main} calls. The basic idea of the functions in
this file is that the processing functions should need a minimum
number of such checks. With this convention we facilitate reading by
an inquirer who only wants to understand one part (mostly the
processing part and not user input details) of the code. It also makes
all the errors related to input appear before the processing begins
which is more convenient for the user.

@item progname.c
The main processing functions in each program which keep the
function(s) that @code{main()} will call are in a file named
@file{progname.c}, for example @file{imgcrop.c} or
@file{noisechisel.c}. The function within these files which
@code{main()} calls is also named after the program, for example

@example
void
imgcrop(struct imgcropparams *p)
@end example

@noindent
or

@example
void
noisechisel(struct noisechiselparams *p)
@end example

@noindent
In this manner, if an inquirer is interested the processing steps,
they can immediately come and check this file for the first processing
step without having to go through @file{main.c} first. In most
situations, any failure in any step of the programs will result in an
informative error message and an immediate abort in the program. So
there is no need for return values. Under more complicated situations
where a return value might be necessary, @code{void} will be replaced
with an @code{int} in the examples above.

@item cite.h
This file keeps the function to be called if the user runs any of the
programs with @option{--cite}, see @ref{Operating modes}.

@end vtable

@menu
* Coding conventions::          Conventions used for coding
* Multithreaded programming::
@end menu

@node Coding conventions, Multithreaded programming, Program source, Program source
@subsection Coding conventions

Generally we try our best to follow the GNU coding standards, besides
those we have kept the following conventions until now. If new code is
also added in the same manner, it would be much more easily readable
by any interested astronomer (who will become familiar with it after
reading once).

@itemize

@item
There should be be no trailing white space in a line. To do this
automatically every time you save a file in Emacs, add the following
line to your @file{~/.emacs} file.
@example
(add-hook 'before-save-hook 'delete-trailing-whitespace)
@end example

@item
There should be no tabs in the indentation. Add the line below to your
@file{~/.emacs} file to do this automatically:
@example
(setq-default indent-tabs-mode nil)
@end example

@item
All similar functions should be are separated by 5 blank lines to be
easily seen to be related in a group when parsing the source code by
eye. In Emacs you can use @key{CTRL-u 5 CTRL-o}.

@item
One group of functions is separated from another with 20 blank
lines. In Emacs you can use @key{CTRL-u 20 CTRL-o}. Each group of
functions has short descriptive title of the functions in that group
in the form:

@example
/******************************************************/
/****************     Sample title     ****************/
/******************************************************/
@end example

@end itemize


@node Multithreaded programming,  , Coding conventions, Program source
@subsection Multithreaded programming

Most of the programs in gnuastro utilize multi-threaded programming
for the CPU intensive processing steps. This can potentially lead to a
significant decrease in the running time of a program, see @ref{A note
on threads}. In terms of reading the code, you don't need to know
anything about multithreaded programming. You can simply follow the
case where only one thread is to be used. In these cases, threads are
not used and can be completely ignored.

At the time K&R's book was written, using threads was not common. We
use POSIX threads for multithreaded programming, defined in the
@file{pthread.h} system wide header. There are various resources for
learning to use POSIX threads, we recommend the excellent tutorial
from Lawrence Livermore National
Laboratory@footnote{@url{https://computing.llnl.gov/tutorials/pthreads/}}.
The book ``Advanced programming in the unix environment'', by Richard
Stevens and Stephen Rago, Addison-Wesley, 2013 (Third edition) also
has two chapters explaining the POSIX thread constructs which can be
very helpful.

An alternative to POSIX threads was OpenMP, but POSIX threads are low
level, allowing much more control, while being easier to understand,
see @ref{Why C}. All the situations we use threads in are completely
independent with minimal need of coordination between the threads.
Such problems are known as ``embarrassingly parallel'' problems. They
are some of the simplest problems to solve with threads and also the
ones that benefit most from threads, see the LLNL
introduction@footnote{@url{https://computing.llnl.gov/tutorials/parallel_comp/}}.


@node Test scripts, Building, Program source, Developing
@section Test scripts

As explained in @ref{Tests}, for every program we have written some
simple tests checking the various independent features of the
program. All the tests are placed in the
@file{gnuastro-@value{VERSION}/tests} directory, lets call it
@file{TESTdir}. There is one script (@file{prepconf.sh}) in this
folder and several @file{Makefile}s. The script is the first ``test''
that will be run. It will copy all the configuration files from the
various directories to a @file{.gnuastro} directory which it will
make so the various tests can set the default values.

For each program, the tests are placed inside directories with the
program name. Each test is written as a shell script. The last line of
this script is the test which runs the program with certain
parameters. The return value of this script determines the fate of the
test, see the ``Support for test suites'' chapter of the Automake
manual for a very nice and complete explanation. In every script, two
variables are defined at first: @code{prog} and @code{execname}. The
first specifies the program name and the second the location of the
executable.

The most important thing to have in mind about all the test scripts is
that they are run from inside the @file{TESTdir} directory in the
``build tree''. Which can be different from the directory they are
stored in (known as the ``source tree''). This distinction is made by
GNU Autoconf and Automake (which configure, build and install
gnuastro) so that you can install the program even if you don't have
write access to the directory keeping the source files. See the
``Parallel build trees (a.k.a VPATH builds)'' in the Automake manual
for a nice explanation.

Because of this, any possible data that was not generated by other
tests (and is thus in the build tree), for example the catalogs in
ImageCrop tests, has a @command{$topsrc} prefix instead of
@command{../} for the build three. This @command{$topsrc} variable
points to the source tree where the script can find the source data
(it is defined in @file{TESTdir/Makefile.am}). The executables and
other test products were built in the build tree (where they are being
run), so they don't need to be prefixed with that variable. This is
also true for images or files that were produced by other tests.





@node Building, After making changes, Test scripts, Developing
@section Building
To build the various programs in gnuastro, we use GNU Autoconf and
GNU Automake. They provide a very portable system to check the
environment a program is to be installed on prior to compiling and set
the compilation conditions based on the particular user. They also
make installing everything in their standard places very easy for the
programmer. Most of the small caps files that you see in the top
@file{gnuastro-@value{VERSION}/} directory are created by these
tools.

By default all the programs are compiled with optimization flags for
increased speed. A side effect is that valuable debugging information
is lost. To compile with the debugging flag set on (and no
optimization) you can add the following options to configure:

@example
$ configure CFLAGS="-g -O0"
@end example

In order to understand the building process, you can go through the
Autoconf and Automake manuals, like all GNU manuals they provide both
a great tutorial and technical documentation. The ``A small Hello
World'' section in Automake's manual (in chapter 2) can be a good
starting guide after you have read the introductions of both.




@node After making changes,  , Building, Developing
@section After making changes
After you have saved your changes/additions, it is strongly
recommended to run

@example
$ make distcheck
@end example

@noindent
This command will create a distribution file (ending with
@file{.tar.gz}) and try to compile it in the most general cases, then
it will run the tests on what it has built in its own
mini-environment. If your change (and the added tests) passes this
check, then you are safe to send your changes to us to implement or
for your own purposes.

@cartouche
@noindent
@strong{CAUTION:} Documentation is an integral part of GNU Astronomy
Utilities, it is not considered a separate project. So, no change is
considered valid for implementation unless the respective parts of the
manual have been updated also. Also don't forget to update the
@file{ChangeLog} file too.

@end cartouche


















@node GNU Free Documentation License, Index, Developing, Top
@appendix GNU Free Documentation License

@include fdl.texi





@c Print the index and finish:
@node Index,  , GNU Free Documentation License, Top
@unnumbered Index
@printindex cp

@bye
